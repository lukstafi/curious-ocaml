<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Lukasz Stafiniak" />
  <title>Curious OCaml</title>
  <style>
    html {
      font-size: 11pt;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Curious OCaml</h1>
<p class="author">Lukasz Stafiniak</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#curious-ocaml" id="toc-curious-ocaml">Curious OCaml</a>
<ul>
<li><a href="#chapter-1-logic" id="toc-chapter-1-logic">Chapter 1:
Logic</a>
<ul>
<li><a href="#in-the-beginning-there-was-logos"
id="toc-in-the-beginning-there-was-logos">1.1 In the Beginning there was
Logos</a></li>
<li><a href="#rules-for-logical-connectives"
id="toc-rules-for-logical-connectives">1.2 Rules for Logical
Connectives</a></li>
<li><a href="#logos-was-programmed-in-ocaml"
id="toc-logos-was-programmed-in-ocaml">1.3 Logos was Programmed in
OCaml</a></li>
<li><a href="#exercises" id="toc-exercises">1.4 Exercises</a></li>
</ul></li>
<li><a href="#chapter-2-algebra" id="toc-chapter-2-algebra">Chapter 2:
Algebra</a>
<ul>
<li><a href="#a-glimpse-at-type-inference"
id="toc-a-glimpse-at-type-inference">2.1 A Glimpse at Type
Inference</a></li>
<li><a href="#algebraic-data-types" id="toc-algebraic-data-types">2.2
Algebraic Data Types</a></li>
<li><a href="#syntactic-bread-and-sugar"
id="toc-syntactic-bread-and-sugar">2.3 Syntactic Bread and
Sugar</a></li>
<li><a href="#pattern-matching" id="toc-pattern-matching">2.4 Pattern
Matching</a></li>
<li><a href="#interpreting-algebraic-data-types-as-polynomials"
id="toc-interpreting-algebraic-data-types-as-polynomials">2.5
Interpreting Algebraic Data Types as Polynomials</a></li>
<li><a href="#differentiating-algebraic-data-types"
id="toc-differentiating-algebraic-data-types">2.6 Differentiating
Algebraic Data Types</a></li>
<li><a href="#exercises-1" id="toc-exercises-1">2.7 Exercises</a></li>
</ul></li>
<li><a href="#chapter-3-computation"
id="toc-chapter-3-computation">Chapter 3: Computation</a>
<ul>
<li><a href="#function-composition" id="toc-function-composition">3.1
Function Composition</a></li>
<li><a href="#evaluation-rules-reduction-semantics"
id="toc-evaluation-rules-reduction-semantics">3.2 Evaluation Rules
(Reduction Semantics)</a></li>
<li><a href="#symbolic-derivation-example"
id="toc-symbolic-derivation-example">3.3 Symbolic Derivation
Example</a></li>
<li><a href="#tail-calls-and-tail-recursion"
id="toc-tail-calls-and-tail-recursion">3.4 Tail Calls and Tail
Recursion</a></li>
<li><a href="#first-encounter-of-continuation-passing-style"
id="toc-first-encounter-of-continuation-passing-style">3.5 First
Encounter of Continuation Passing Style</a></li>
<li><a href="#exercises-2" id="toc-exercises-2">3.6 Exercises</a></li>
</ul></li>
<li><a href="#chapter-4-functions" id="toc-chapter-4-functions">Chapter
4: Functions</a>
<ul>
<li><a href="#review-computation-by-hand"
id="toc-review-computation-by-hand">4.1 Review: Computation by
Hand</a></li>
<li><a href="#language-and-rules-of-the-untyped-lambda-calculus"
id="toc-language-and-rules-of-the-untyped-lambda-calculus">4.2 Language
and Rules of the Untyped Lambda-Calculus</a></li>
<li><a href="#booleans" id="toc-booleans">4.3 Booleans</a></li>
<li><a href="#if-then-else-and-pairs"
id="toc-if-then-else-and-pairs">4.4 If-then-else and Pairs</a></li>
<li><a href="#pair-encoded-natural-numbers"
id="toc-pair-encoded-natural-numbers">4.5 Pair-Encoded Natural
Numbers</a></li>
<li><a href="#church-numerals" id="toc-church-numerals">4.6 Church
Numerals</a></li>
<li><a href="#recursion-fixpoint-combinators"
id="toc-recursion-fixpoint-combinators">4.7 Recursion: Fixpoint
Combinators</a></li>
<li><a href="#encoding-lists-and-trees"
id="toc-encoding-lists-and-trees">4.8 Encoding Lists and Trees</a></li>
<li><a href="#looping-recursion" id="toc-looping-recursion">4.9 Looping
Recursion</a></li>
<li><a href="#exercises-3" id="toc-exercises-3">4.10 Exercises</a></li>
</ul></li>
<li><a href="#chapter-5-polymorphism-and-abstract-data-types"
id="toc-chapter-5-polymorphism-and-abstract-data-types">Chapter 5:
Polymorphism and Abstract Data Types</a>
<ul>
<li><a href="#type-inference" id="toc-type-inference">5.1 Type
Inference</a></li>
<li><a href="#parametric-types" id="toc-parametric-types">5.2 Parametric
Types</a></li>
<li><a href="#type-inference-formally"
id="toc-type-inference-formally">5.3 Type Inference, Formally</a></li>
<li><a href="#algebraic-specification"
id="toc-algebraic-specification">5.4 Algebraic Specification</a></li>
<li><a href="#homomorphisms" id="toc-homomorphisms">5.5
Homomorphisms</a></li>
<li><a href="#example-maps" id="toc-example-maps">5.6 Example:
Maps</a></li>
<li><a href="#modules-and-interfaces-signatures-syntax"
id="toc-modules-and-interfaces-signatures-syntax">5.7 Modules and
Interfaces (Signatures): Syntax</a></li>
<li><a href="#implementing-maps-association-lists"
id="toc-implementing-maps-association-lists">5.8 Implementing Maps:
Association Lists</a></li>
<li><a href="#implementing-maps-binary-search-trees"
id="toc-implementing-maps-binary-search-trees">5.9 Implementing Maps:
Binary Search Trees</a></li>
<li><a href="#implementing-maps-red-black-trees"
id="toc-implementing-maps-red-black-trees">5.10 Implementing Maps:
Red-Black Trees</a></li>
<li><a href="#exercises-4" id="toc-exercises-4">Exercises</a></li>
</ul></li>
<li><a href="#chapter-6-folding-and-backtracking"
id="toc-chapter-6-folding-and-backtracking">Chapter 6: Folding and
Backtracking</a>
<ul>
<li><a href="#basic-generic-list-operations"
id="toc-basic-generic-list-operations">6.1 Basic Generic List
Operations</a></li>
<li><a href="#making-fold-tail-recursive"
id="toc-making-fold-tail-recursive">6.2 Making Fold
Tail-Recursive</a></li>
<li><a href="#map-and-fold-for-trees-and-other-structures"
id="toc-map-and-fold-for-trees-and-other-structures">6.3 Map and Fold
for Trees and Other Structures</a></li>
<li><a href="#point-free-programming"
id="toc-point-free-programming">6.4 Point-Free Programming</a></li>
<li><a href="#reductions-and-more-higher-order-functions"
id="toc-reductions-and-more-higher-order-functions">6.5 Reductions and
More Higher-Order Functions</a></li>
<li><a href="#grouping-and-map-reduce"
id="toc-grouping-and-map-reduce">6.6 Grouping and Map-Reduce</a></li>
<li><a href="#higher-order-functions-for-the-option-type"
id="toc-higher-order-functions-for-the-option-type">6.7 Higher-Order
Functions for the Option Type</a></li>
<li><a href="#the-countdown-problem-puzzle"
id="toc-the-countdown-problem-puzzle">6.8 The Countdown Problem
Puzzle</a></li>
<li><a href="#the-honey-islands-puzzle"
id="toc-the-honey-islands-puzzle">6.9 The Honey Islands Puzzle</a></li>
<li><a href="#constraint-based-puzzles"
id="toc-constraint-based-puzzles">6.10 Constraint-Based Puzzles</a></li>
<li><a href="#exercises-5" id="toc-exercises-5">6.11 Exercises</a></li>
</ul></li>
<li><a href="#chapter-7-laziness" id="toc-chapter-7-laziness">Chapter 7:
Laziness</a>
<ul>
<li><a href="#evaluation-strategies-and-parameter-passing"
id="toc-evaluation-strategies-and-parameter-passing">7.1 Evaluation
Strategies and Parameter Passing</a></li>
<li><a href="#call-by-name-streams" id="toc-call-by-name-streams">7.2
Call-by-name: Streams</a></li>
<li><a href="#lazy-values" id="toc-lazy-values">7.3 Lazy Values</a></li>
<li><a href="#power-series-and-differential-equations"
id="toc-power-series-and-differential-equations">7.4 Power Series and
Differential Equations</a></li>
<li><a href="#arbitrary-precision-computation"
id="toc-arbitrary-precision-computation">7.5 Arbitrary Precision
Computation</a></li>
<li><a href="#circular-data-structures-double-linked-lists"
id="toc-circular-data-structures-double-linked-lists">7.6 Circular Data
Structures: Double-Linked Lists</a></li>
<li><a href="#input-output-streams" id="toc-input-output-streams">7.7
Input-Output Streams</a></li>
<li><a href="#pipes" id="toc-pipes">7.8 Pipes</a></li>
<li><a href="#example-pretty-printing"
id="toc-example-pretty-printing">7.9 Example: Pretty-Printing</a></li>
</ul></li>
</ul></li>
<li><a href="#let-print_endline-pretty-30-test_doc"
id="toc-let-print_endline-pretty-30-test_doc">let () = print_endline
(pretty 30 test_doc);;</a></li>
<li><a href="#let-print_endline-pretty-20-test_doc"
id="toc-let-print_endline-pretty-20-test_doc">let () = print_endline
(pretty 20 test_doc);;</a></li>
<li><a href="#let-print_endline-pretty-60-test_doc"
id="toc-let-print_endline-pretty-60-test_doc">let () = print_endline
(pretty 60 test_doc);;</a>
<ul>
<li><a href="#chapter-8-monads" id="toc-chapter-8-monads">Chapter 8:
Monads</a>
<ul>
<li><a href="#list-comprehensions" id="toc-list-comprehensions">8.1 List
Comprehensions</a></li>
<li><a href="#generalized-comprehensions-binding-operators"
id="toc-generalized-comprehensions-binding-operators">8.2 Generalized
Comprehensions: Binding Operators</a></li>
<li><a href="#monads" id="toc-monads">8.3 Monads</a></li>
<li><a href="#monad-laws" id="toc-monad-laws">8.4 Monad Laws</a></li>
<li><a href="#monoid-laws-and-monad-plus"
id="toc-monoid-laws-and-monad-plus">8.5 Monoid Laws and
Monad-Plus</a></li>
<li><a href="#backtracking-computation-with-choice"
id="toc-backtracking-computation-with-choice">8.6 Backtracking:
Computation with Choice</a></li>
<li><a href="#the-two-metaphors" id="toc-the-two-metaphors">8.9 The Two
Metaphors</a></li>
<li><a href="#monad-classes-and-instances"
id="toc-monad-classes-and-instances">8.10 Monad Classes and
Instances</a></li>
<li><a href="#monad-instances" id="toc-monad-instances">8.11 Monad
Instances</a></li>
<li><a href="#exercises-6" id="toc-exercises-6">8.15 Exercises</a></li>
</ul></li>
<li><a href="#chapter-9-algebraic-effects"
id="toc-chapter-9-algebraic-effects">Chapter 9: Algebraic
Effects</a></li>
<li><a href="#chapter-10-functional-reactive-programming"
id="toc-chapter-10-functional-reactive-programming">Chapter 10:
Functional Reactive Programming</a>
<ul>
<li><a href="#zippers" id="toc-zippers">10.1 Zippers</a></li>
<li><a href="#reactivity-by-incremental-computing"
id="toc-reactivity-by-incremental-computing">10.6 Reactivity by
Incremental Computing</a></li>
<li><a href="#lightweight-fp-non-solution-extensible-variant-types"
id="toc-lightweight-fp-non-solution-extensible-variant-types">11.3
Lightweight FP Non-Solution: Extensible Variant Types</a></li>
<li><a href="#polymorphic-variants" id="toc-polymorphic-variants">11.7
Polymorphic Variants</a></li>
<li><a href="#parser-combinators" id="toc-parser-combinators">11.9
Parser Combinators</a></li>
<li><a href="#parser-combinators-implementation"
id="toc-parser-combinators-implementation">11.10 Parser Combinators:
Implementation</a></li>
<li><a href="#parser-combinators-dynamic-code-loading"
id="toc-parser-combinators-dynamic-code-loading">11.12 Parser
Combinators: Dynamic Code Loading</a></li>
<li><a href="#exercises-7" id="toc-exercises-7">11.14 Exercises</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
<!-- Do NOT modify this file, it is automatically generated -->
<h1 id="curious-ocaml">Curious OCaml</h1>
<p><em>Curious OCaml</em> invites you to explore programming through the
lens of types, logic, and algebra. OCaml is a language that rewards
curiosity—its type system catches errors before your code runs, its
functional style encourages clear thinking about data transformations,
and its mathematical foundations reveal deep connections between
programming and logic. Whether you’re new to programming, experienced
with OCaml, or a seasoned developer discovering functional programming
for the first time, this book aims to spark that “aha!” moment when
abstract concepts click into place.</p>
<p>This book is intended for three audiences:</p>
<ul>
<li>New to programming: ambitious students in areas with formal rigor –
math, computer science, philosophy, linguistics, etc.</li>
<li>Intermediate: OCaml programmers.</li>
<li>Advanced: programmers who are new to functional programming.</li>
</ul>
<h2 id="chapter-1-logic">Chapter 1: Logic</h2>
<p><em>From logic rules to programming constructs</em></p>
<h3 id="in-the-beginning-there-was-logos">1.1 In the Beginning there was
Logos</h3>
<p>What logical connectives do you know? Before we write any code, let
us take a step back and think about logic itself. The connectives listed
below form the foundation of reasoning, and as we will discover, they
also form the foundation of programming.</p>
<table>
<colgroup>
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr>
<th><span class="math inline">\top</span></th>
<th><span class="math inline">\bot</span></th>
<th><span class="math inline">\wedge</span></th>
<th><span class="math inline">\vee</span></th>
<th><span class="math inline">\rightarrow</span></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td><span class="math inline">a \wedge b</span></td>
<td><span class="math inline">a \vee b</span></td>
<td><span class="math inline">a \rightarrow b</span></td>
</tr>
<tr>
<td>truth</td>
<td>falsehood</td>
<td>conjunction</td>
<td>disjunction</td>
<td>implication</td>
</tr>
<tr>
<td>“trivial”</td>
<td>“impossible”</td>
<td><span class="math inline">a</span> and <span
class="math inline">b</span></td>
<td><span class="math inline">a</span> or <span
class="math inline">b</span></td>
<td><span class="math inline">a</span> gives <span
class="math inline">b</span></td>
</tr>
<tr>
<td></td>
<td>shouldn’t get</td>
<td>got both</td>
<td>got at least one</td>
<td>given <span class="math inline">a</span>, we get <span
class="math inline">b</span></td>
</tr>
</tbody>
</table>
<p>How can we define these connectives precisely? The key insight is to
think in terms of <em>derivation trees</em>. A derivation tree shows how
we arrive at conclusions from premises, building up knowledge step by
step:</p>
<p><span class="math display">
\frac{
\frac{\frac{\,}{\text{a premise}} \; \frac{\,}{\text{another
premise}}}{\text{some fact}} \;
\frac{\frac{\,}{\text{this we have by default}}}{\text{another fact}}}
{\text{final conclusion}}
</span></p>
<p>We define connectives by providing rules for using them. For example,
a rule <span class="math inline">\frac{a \; b}{c}</span> matches parts
of the tree that have two premises, represented by variables <span
class="math inline">a</span> and <span class="math inline">b</span>, and
have any conclusion, represented by variable <span
class="math inline">c</span>. These variables act as placeholders that
can match any proposition.</p>
<p><strong>Design principle:</strong> When defining a connective, we try
to use only that connective in its definition. This keeps definitions
self-contained and avoids circular dependencies between connectives.</p>
<h3 id="rules-for-logical-connectives">1.2 Rules for Logical
Connectives</h3>
<p>Each logical connective comes with two kinds of rules:</p>
<p><strong>Introduction rules</strong> tell us how to <em>produce</em>
or <em>construct</em> a connective. If you want to prove “A and B”, the
introduction rule tells you what you need: proofs of both A and B.</p>
<p><strong>Elimination rules</strong> tell us how to <em>use</em> or
<em>consume</em> a connective. If you already have “A and B”, the
elimination rules tell you what you can get from it: either A or B (your
choice).</p>
<p>In the table below, text in parentheses provides informal commentary.
Letters like <span class="math inline">a</span>, <span
class="math inline">b</span>, and <span class="math inline">c</span> are
variables that can stand for any proposition.</p>
<table>
<colgroup>
<col style="width: 24%" />
<col style="width: 38%" />
<col style="width: 38%" />
</colgroup>
<thead>
<tr>
<th>Connective</th>
<th>Introduction Rules</th>
<th>Elimination Rules</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">\top</span></td>
<td><span class="math inline">\frac{}{\top}</span></td>
<td>doesn’t have</td>
</tr>
<tr>
<td><span class="math inline">\bot</span></td>
<td>doesn’t have</td>
<td><span class="math inline">\frac{\bot}{a}</span> (i.e.,
anything)</td>
</tr>
<tr>
<td><span class="math inline">\wedge</span></td>
<td><span class="math inline">\frac{a \quad b}{a \wedge b}</span></td>
<td><span class="math inline">\frac{a \wedge b}{a}</span> (take first)  
<span class="math inline">\frac{a \wedge b}{b}</span> (take second)</td>
</tr>
<tr>
<td><span class="math inline">\vee</span></td>
<td><span class="math inline">\frac{a}{a \vee b}</span> (put first)  
<span class="math inline">\frac{b}{a \vee b}</span> (put second)</td>
<td><span class="math inline">\frac{a \vee b \quad
\genfrac{}{}{0pt}{}{[a]^x}{\vdots \; c} \quad
\genfrac{}{}{0pt}{}{[b]^y}{\vdots \; c}}{c}</span> using <span
class="math inline">x, y</span></td>
</tr>
<tr>
<td><span class="math inline">\rightarrow</span></td>
<td><span class="math inline">\frac{\genfrac{}{}{0pt}{}{[a]^x}{\vdots \;
b}}{a \rightarrow b}</span> using <span
class="math inline">x</span></td>
<td><span class="math inline">\frac{a \rightarrow b \quad
a}{b}</span></td>
</tr>
</tbody>
</table>
<h4 id="notation-for-hypothetical-derivations">Notation for Hypothetical
Derivations</h4>
<p>The notation <span
class="math inline">\genfrac{}{}{0pt}{}{[a]^x}{\vdots \; b}</span>
(sometimes written as a tree) matches any subtree that derives <span
class="math inline">b</span> and can use <span
class="math inline">a</span> as an assumption (marked with label <span
class="math inline">x</span>), even though <span
class="math inline">a</span> might not otherwise be warranted. The
square brackets around <span class="math inline">a</span> indicate that
this is a <em>hypothetical</em> assumption, not something we have
actually established. The superscript <span class="math inline">x</span>
is a label that helps us track which assumption gets “discharged” when
we complete the derivation.</p>
<p>This is the key to proving implications: to prove “if A then B”, we
temporarily assume A and show we can derive B. For example, we can
derive “sunny <span class="math inline">\rightarrow</span> happy” by
showing that <em>assuming</em> it is sunny, we can derive happiness:</p>
<p><span class="math display">
\frac{\frac{\frac{\frac{\frac{\,}{\text{sunny}}^x}{\text{go
outdoor}}}{\text{playing}}}{\text{happy}}}{\text{sunny} \rightarrow
\text{happy}} \text{ using } x
</span></p>
<p>Notice how the assumption “sunny” (marked with <span
class="math inline">x</span>) appears at the top of the derivation tree.
We use this assumption to derive “go outdoor”, then “playing”, and
finally “happy”. Once we complete the derivation, the assumption is
<em>discharged</em>: we no longer need to assume it is sunny because we
have established the conditional “sunny <span
class="math inline">\rightarrow</span> happy”.</p>
<p>A crucial point: such assumptions can only be used within the matched
subtree! However, they can be used <em>multiple times</em> within that
subtree. For example, if someone’s mood is more difficult to influence
and requires multiple sunny conditions:</p>
<p><span class="math display">
\frac{\frac{
  \frac{\frac{\frac{\,}{\text{sunny}}^x}{\text{go
outdoor}}}{\text{playing}} \quad
  \frac{\frac{\,}{\text{sunny}}^x \quad
\frac{\frac{\,}{\text{sunny}}^x}{\text{go outdoor}}}{\text{nice view}}
}{\text{happy}}}{\text{sunny} \rightarrow \text{happy}} \text{ using } x
</span></p>
<p>In this more complex derivation, the assumption “sunny” (labeled
<span class="math inline">x</span>) is used three times: once to derive
“go outdoor”, and twice more in deriving “nice view”. All three uses are
valid because they occur within the same hypothetical subtree.</p>
<h4 id="reasoning-by-cases">Reasoning by Cases</h4>
<p>The elimination rule for disjunction deserves special attention
because it represents <strong>reasoning by cases</strong>, one of the
most fundamental proof techniques.</p>
<p>Suppose we know “A or B” is true, but we do not know which one. How
can we still derive a conclusion C? We must show that C follows
<em>regardless</em> of which alternative holds. In other words, we need
to prove: (1) assuming A, we can derive C, and (2) assuming B, we can
derive C. Since one of A or B must be true, and both lead to C, we can
conclude C.</p>
<p>Here is a concrete example: How can we use the fact that it is sunny
<span class="math inline">\vee</span> cloudy (but not rainy)?</p>
<p><span class="math display">
\frac{
  \frac{\,}{\text{sunny} \vee \text{cloudy}}^{\text{forecast}} \quad
  \frac{\frac{\,}{\text{sunny}}^x}{\text{no-umbrella}} \quad
  \frac{\frac{\,}{\text{cloudy}}^y}{\text{no-umbrella}}
}{\text{no-umbrella}} \text{ using } x, y
</span></p>
<p>We know that it will be sunny or cloudy (by watching the weather
forecast). Now we reason by cases: <em>If</em> it will be sunny, we will
not need an umbrella. <em>If</em> it will be cloudy, we will not need an
umbrella. Since one of these must be the case, and both lead to the same
conclusion, we can confidently say: we will not need an umbrella.</p>
<h4 id="reasoning-by-induction">Reasoning by Induction</h4>
<p>We need one more kind of rule to do serious math: <strong>reasoning
by induction</strong>. This rule is somewhat similar to reasoning by
cases, but instead of considering a finite number of alternatives, it
allows us to prove properties that hold for infinitely many cases, such
as all natural numbers.</p>
<p>Here is the example rule for induction on natural numbers:</p>
<p><span class="math display">
\frac{p(0) \quad \genfrac{}{}{0pt}{}{[p(x)]^x}{\vdots \; p(x+1)}}{p(n)}
\text{ by induction, using } x
</span></p>
<p>This rule says: we get property <span class="math inline">p</span>
for <em>any</em> natural number <span class="math inline">n</span>,
provided we can do two things:</p>
<ol type="1">
<li><strong>Base case:</strong> Establish <span
class="math inline">p(0)</span>, that is, prove the property holds for
zero.</li>
<li><strong>Inductive step:</strong> Show that <em>assuming</em> <span
class="math inline">p(x)</span> holds for some arbitrary <span
class="math inline">x</span>, we can derive <span
class="math inline">p(x+1)</span>. This assumption <span
class="math inline">p(x)</span> is called the <em>induction
hypothesis</em>.</li>
</ol>
<p>Here <span class="math inline">x</span> is a unique variable
representing an arbitrary natural number. We cannot substitute a
particular number for it because we write “using <span
class="math inline">x</span>” on the side, indicating that the
derivation works for any choice of <span
class="math inline">x</span>.</p>
<p>The power of induction lies in this: once we have the base case and
the inductive step, we have implicitly covered <em>all</em> natural
numbers. Starting from <span class="math inline">p(0)</span>, we can
derive <span class="math inline">p(1)</span>, then <span
class="math inline">p(2)</span>, then <span
class="math inline">p(3)</span>, and so on, reaching any natural number
<span class="math inline">n</span> we wish.</p>
<h3 id="logos-was-programmed-in-ocaml">1.3 Logos was Programmed in
OCaml</h3>
<p>We now arrive at one of the most remarkable discoveries in the
foundations of computer science: the <strong>Curry-Howard
correspondence</strong>, also known as “propositions as types” or the
“proofs-as-programs” interpretation. This deep correspondence reveals
that logical proofs and computer programs are, in a precise sense, the
same thing!</p>
<p>Under this correspondence:</p>
<ul>
<li><strong>Propositions</strong> (logical statements) correspond to
<strong>types</strong></li>
<li><strong>Proofs</strong> (derivations showing a proposition is true)
correspond to <strong>programs</strong> (expressions of a given
type)</li>
<li><strong>Introduction rules</strong> correspond to
<strong>constructors</strong> (ways to build values)</li>
<li><strong>Elimination rules</strong> correspond to
<strong>destructors</strong> (ways to use values)</li>
</ul>
<p>This is not merely an analogy. The formal rules for logic and the
formal rules for type checking are <em>identical</em>. When you write a
well-typed program, you are simultaneously constructing a proof!</p>
<p>The following table shows how each logical connective corresponds to
a programming construct in OCaml:</p>
<table>
<colgroup>
<col style="width: 19%" />
<col style="width: 16%" />
<col style="width: 33%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr>
<th>Logic</th>
<th>Type</th>
<th>Expression</th>
<th>Intuition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">\top</span></td>
<td><code>unit</code></td>
<td><code>()</code></td>
<td>The trivially true proposition; the type with exactly one value</td>
</tr>
<tr>
<td><span class="math inline">\bot</span></td>
<td><code>'a</code></td>
<td><code>raise</code></td>
<td>Falsehood; a type with no values (exceptions escape normal
typing)</td>
</tr>
<tr>
<td><span class="math inline">\wedge</span></td>
<td><code>*</code></td>
<td><code>(,)</code></td>
<td>Conjunction corresponds to pairs: having both A and B</td>
</tr>
<tr>
<td><span class="math inline">\vee</span></td>
<td><code>\|</code></td>
<td><code>match</code></td>
<td>Disjunction corresponds to variants: having either A or B</td>
</tr>
<tr>
<td><span class="math inline">\rightarrow</span></td>
<td><code>-&gt;</code></td>
<td><code>fun</code></td>
<td>Implication corresponds to functions: given A, produce B</td>
</tr>
<tr>
<td>induction</td>
<td>-</td>
<td><code>rec</code></td>
<td>Inductive proofs correspond to recursive functions</td>
</tr>
</tbody>
</table>
<p>Let us now see the precise typing rules for each OCaml construct,
presented in the same style as our logical rules:</p>
<p><strong>Typing rules for OCaml constructs:</strong></p>
<ul>
<li><p><strong>Unit (truth):</strong> <span
class="math inline">\frac{}{\texttt{()} : \texttt{unit}}</span></p>
<p>The unit value <code>()</code> always has type <code>unit</code>.
This is like <span class="math inline">\top</span> in logic: we can
always produce it without any premises.</p></li>
<li><p><strong>Exception (falsehood):</strong> <span
class="math inline">\frac{\text{oops!}}{\texttt{raise exn} : c}</span>
can produce any type</p>
<p>The <code>raise</code> expression can have <em>any</em> type <span
class="math inline">c</span>. This corresponds to the principle of
“explosion” in logic: from falsehood, anything follows. In practice,
<code>raise</code> never actually produces a value; it transfers control
to an exception handler. The type system allows it to have any type
because the expression will never complete normally.</p></li>
<li><p><strong>Pair (conjunction):</strong></p>
<ul>
<li>Introduction: <span class="math inline">\frac{s : a \quad t : b}{(s,
t) : a * b}</span></li>
<li>Elimination: <span class="math inline">\frac{p : a *
b}{\texttt{fst}~p : a}</span> and <span class="math inline">\frac{p : a
* b}{\texttt{snd}~p : b}</span></li>
</ul>
<p>To construct a pair, you need both components. To use a pair, you can
extract either component. This mirrors conjunction perfectly: to prove
“A and B”, you need proofs of both; given “A and B”, you can conclude
either A or B.</p></li>
<li><p><strong>Variant (disjunction):</strong></p>
<ul>
<li>Introduction: <span class="math inline">\frac{s : a}{\texttt{A}(s) :
\texttt{A of}~a~|~\texttt{B of}~b}</span></li>
<li>Elimination (match): given <span class="math inline">t</span> of
variant type and branches for each case, produce result <span
class="math inline">c</span></li>
</ul>
<p>To construct a variant, you only need one of the alternatives. To use
a variant, you must handle <em>all</em> possible cases (pattern
matching). This mirrors disjunction: to prove “A or B”, you only need
one; to use “A or B”, you must consider both possibilities.</p></li>
<li><p><strong>Function (implication):</strong></p>
<ul>
<li>Introduction: <span class="math inline">\frac{\genfrac{}{}{0pt}{}{[x
: a]}{e : b}}{\texttt{fun}~x \to e : a \to b}</span></li>
<li>Elimination (application): <span class="math inline">\frac{f : a \to
b \quad t : a}{f~t : b}</span></li>
</ul>
<p>To construct a function, you assume you have an input of type <span
class="math inline">a</span> (the parameter <span
class="math inline">x</span>) and show how to produce a result of type
<span class="math inline">b</span>. To use a function, you apply it to
an argument. This mirrors implication: to prove “A implies B”, assume A
and derive B; given “A implies B” and A, conclude B.</p></li>
<li><p><strong>Recursion (induction):</strong> <span
class="math inline">\frac{\genfrac{}{}{0pt}{}{[x : a]}{e :
a}}{\texttt{rec}~x = e : a}</span></p>
<p>In recursion, the function being defined can refer to itself. This
corresponds to induction: we can use the property we are trying to prove
(the induction hypothesis) in the inductive step.</p></li>
</ul>
<h4 id="definitions">Definitions</h4>
<p>Writing out expressions and types repetitively quickly becomes
tedious. More importantly, without definitions we cannot give names to
our concepts, making code harder to understand and maintain. This is why
we need definitions.</p>
<p><strong>Type definitions</strong> are written: <code>type ty =</code>
some type.</p>
<ul>
<li><p>Writing <code>A(s) : A of a | B of b</code> in the table above
was a simplification. In practice, we usually have to define the type
first and then use it. For example, using <code>int</code> for <span
class="math inline">a</span> and <code>string</code> for <span
class="math inline">b</span>:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> int_string_choice = A <span class="kw">of</span> <span class="dt">int</span> | B <span class="kw">of</span> <span class="dt">string</span></span></code></pre></div>
<p>This allows us to write
<code>A(s) : int_string_choice</code>.</p></li>
<li><p>Why do we need to define variant types? The reasons are:
exhaustiveness checks, performnance of generated code, and ease of type
inference. When OCaml sees <code>A(5)</code>, it needs to figure out (or
“infer”) the type. Without a type definition, how would OCaml know
whether this is <code>A of int | B of string</code> or
<code>A of int | B of float | C of bool</code>? The definition tells
OCaml exactly what variants exist. When you match
<code>| A i -&gt; ...</code>, the compiler will warn you if you forgot
to also cover <code>C b</code> in your match patterns.</p></li>
<li><p>OCaml does provide an alternative: <em>polymorphic variants</em>,
written with a backtick. We can write
<code>`A(s) : [`A of a | `B of b]</code>. With <code>`</code> variants,
OCaml does infer what other variants might exist based on usage. These
types are powerful and flexible, we will discuss them in chapter
11.</p></li>
<li><p>Tuple elements do not need labels because we always know at which
position a tuple element stands: the first element is first, the second
is second, and so on. However, having labels makes code much clearer,
especially when tuples have many components or components of the same
type. For this reason, we can define a <em>record type</em>:</p>
<p><code>ocaml skip type int_string_record = {a: int; b: string}</code></p>
<p>and create its values: <code>{a = 7; b = "Mary"}</code>. OCaml 5.4
and newer also support labeled tuples, we will not discuss
these.</p></li>
<li><p>We access the <em>fields</em> of records using the dot notation:
<code>{a=7; b="Mary"}.b = "Mary"</code>. Unlike tuples where you must
remember “the second element is the name”, with records you can write
<code>.b</code> to get the field named <code>b</code>.</p></li>
</ul>
<h4 id="expression-definitions">Expression Definitions</h4>
<p>The recursive expression <code>rec x = e</code> that appeared in our
table was a simplification: <code>rec</code> (usually called
<code>fix</code> in programming language theory) cannot appear alone in
OCaml! It must always be part of a <code>let</code> definition.</p>
<p>This brings us to <strong>expression definitions</strong>, which let
us give names to values. The typing rules for definitions are a bit more
complex than what we have seen so far:</p>
<p><span class="math display">
\frac{e_1 : a \quad \frac{[x : a]}{e_2 : b}}{\texttt{let } x = e_1
\texttt{ in } e_2 : b}
</span></p>
<p>This rule says: if <span class="math inline">e_1</span> has type
<span class="math inline">a</span>, and assuming <span
class="math inline">x</span> has type <span class="math inline">a</span>
we can show that <span class="math inline">e_2</span> has type <span
class="math inline">b</span>, then the whole <code>let</code> expression
has type <span class="math inline">b</span>. Interestingly, this rule is
equivalent to introducing a function and immediately applying it:
<code>let x = e1 in e2</code> behaves the same as
<code>(fun x -&gt; e2) e1</code>. This equivalence reflects a deep
connection in the Curry-Howard correspondence.</p>
<p>For recursive definitions, we need an additional rule:</p>
<p><span class="math display">
\frac{\frac{[x : a]}{e_1 : a} \quad \frac{[x : a]}{e_2 : b}}{\texttt{let
rec } x = e_1 \texttt{ in } e_2 : b}
</span></p>
<p>Notice the crucial difference: in the recursive case, <span
class="math inline">x</span> can appear in <span
class="math inline">e_1</span> itself! This is what allows functions to
call themselves. The name <span class="math inline">x</span> is visible
both in its own definition (<span class="math inline">e_1</span>) and in
the body that uses the definition (<span
class="math inline">e_2</span>).</p>
<p>These rules are slightly simplified. The full rules involve a concept
called <strong>polymorphism</strong>, which we will cover in a later
chapter. Polymorphism explains how the same function can work with
different types.</p>
<h4 id="scoping-rules">Scoping Rules</h4>
<p>Understanding <em>scope</em>—where names are visible—is essential for
reading and writing OCaml programs.</p>
<ul>
<li><p><strong>Type definitions</strong> we have seen above are
<em>global</em>: they need to be at the top-level (not nested in
expressions), and they extend from the point they occur till the end of
the source file or interactive session. You cannot define a type inside
a function.</p></li>
<li><p><strong><code>let</code>-<code>in</code> definitions</strong> for
expressions: <code>let x = e1 in e2</code> are <em>local</em>—the name
<span class="math inline">x</span> is only visible within <span
class="math inline">e_2</span>. Once you exit the <code>in</code> part,
<span class="math inline">x</span> no longer exists. This is useful for
temporary values that should not pollute the global namespace.</p></li>
<li><p><strong><code>let</code> definitions</strong> without
<code>in</code> are global: placing <code>let x = e1</code> at the
top-level makes <span class="math inline">x</span> visible from after
<span class="math inline">e_1</span> till the end of the source file or
interactive session. This is how you define functions and values that
the rest of your program can use.</p></li>
<li><p>In the interactive session (toplevel/REPL), we mark the end of a
top-level “sentence” with <code>;;</code>. This tells OCaml “I am done
typing, please evaluate this.” In source files compiled by the build
system, <code>;;</code> is unnecessary because the end of each
definition is clear from context.</p></li>
</ul>
<h4 id="operators">Operators</h4>
<p>Operators like <code>+</code>, <code>*</code>, <code>&lt;</code>,
<code>=</code> are simply names of functions. In OCaml, there is nothing
magical about operators; they are ordinary functions that happen to have
special characters in their names and can be used in infix position
(between their arguments).</p>
<p>Just like other names, you can define your own operators:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> (+:) a b = <span class="dt">String</span>.concat <span class="st">&quot;&quot;</span> [a; b];;  <span class="co">(* Special way of defining *)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;Alpha&quot;</span> +: <span class="st">&quot;Beta&quot;</span>;;  <span class="co">(* but normal way of using operators *)</span></span></code></pre></div>
<p>Notice the asymmetry here: when <em>defining</em> an operator, we
wrap it in parentheses to tell OCaml “this is the name I am defining”.
When <em>using</em> the operator, we write it in the normal infix
position between its arguments. This asymmetry exists because the
definition syntax needs to distinguish between “the name
<code>+:</code>” and “the expression <code>a +: b</code>”.</p>
<p>An important feature of OCaml is that operators are <strong>not
overloaded</strong>. This means that a single operator cannot work for
multiple types. Each type needs its own set of operators: -
<code>+</code>, <code>*</code>, <code>/</code> work for integers -
<code>+.</code>, <code>*.</code>, <code>/.</code> work for floating
point numbers</p>
<p>This design choice makes type inference simpler and more predictable.
When you see <code>x + y</code>, OCaml knows immediately that
<code>x</code> and <code>y</code> must be integers.</p>
<p><strong>Exception:</strong> The comparison operators
<code>&lt;</code>, <code>=</code>, <code>&lt;=</code>,
<code>&gt;=</code>, <code>&lt;&gt;</code> do work for all values other
than functions. These are called <em>polymorphic comparisons</em>.</p>
<h3 id="exercises">1.4 Exercises</h3>
<p>The following exercises are adapted from <em>Think OCaml: How to
Think Like a Computer Scientist</em> by Nicholas Monje and Allen Downey.
They will help you get comfortable with OCaml’s syntax and type
system.</p>
<ol type="1">
<li><p>Assume that we execute the following assignment statements:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> width = <span class="dv">17</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> height = <span class="fl">12.0</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> delimiter = <span class="ch">&#39;.&#39;</span></span></code></pre></div>
<p>For each of the following expressions, write the value of the
expression and the type (of the value of the expression), or the
resulting type error.</p>
<ol type="1">
<li><code>width/2</code></li>
<li><code>width/.2.0</code></li>
<li><code>height/3</code></li>
<li><code>1 + 2 * 5</code></li>
<li><code>delimiter * 5</code></li>
</ol></li>
<li><p>Practice using the OCaml interpreter as a calculator:</p>
<ol type="1">
<li>The volume of a sphere with radius <span
class="math inline">r</span> is <span class="math inline">\frac{4}{3}
\pi r^3</span>. What is the volume of a sphere with radius 5?
(<em>Hint:</em> 392.6 is wrong!)</li>
<li>Suppose the cover price of a book is $24.95, but bookstores get a
40% discount. Shipping costs $3 for the first copy and 75 cents for each
additional copy. What is the total wholesale cost for 60 copies?</li>
<li>If I leave my house at 6:52 am and run 1 mile at an easy pace (8:15
per mile), then 3 miles at tempo (7:12 per mile) and 1 mile at easy pace
again, what time do I get home for breakfast?</li>
</ol></li>
<li><p>You’ve probably heard of the Fibonacci numbers before, but in
case you haven’t, they’re defined by the following recursive
relationship: <span class="math display">
\begin{cases}
f(0) = 0 \\
f(1) = 1 \\
f(n+1) = f(n) + f(n-1) &amp; \text{for } n = 2, 3, \ldots
\end{cases}
</span> Write a recursive function to calculate these numbers.</p></li>
<li><p>A palindrome is a word that is spelled the same backward and
forward, like “noon” and “redivider”. Recursively, a word is a
palindrome if the first and last letters are the same and the middle is
a palindrome.</p>
<p>The following are functions that take a string argument and return
the first, last, and middle letters:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> first_char word = word.[<span class="dv">0</span>]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> last_char word =</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> len = <span class="dt">String</span>.length word - <span class="dv">1</span> <span class="kw">in</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  word.[len]</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> middle word =</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> len = <span class="dt">String</span>.length word - <span class="dv">2</span> <span class="kw">in</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">String</span>.sub word <span class="dv">1</span> len</span></code></pre></div>
<ol type="1">
<li>Enter these functions into the toplevel and test them out. What
happens if you call <code>middle</code> with a string with two letters?
One letter? What about the empty string <code>""</code>?</li>
<li>Write a function called <code>is_palindrome</code> that takes a
string argument and returns <code>true</code> if it is a palindrome and
<code>false</code> otherwise.</li>
</ol></li>
<li><p>The greatest common divisor (GCD) of <span
class="math inline">a</span> and <span class="math inline">b</span> is
the largest number that divides both of them with no remainder.</p>
<p>One way to find the GCD of two numbers is Euclid’s algorithm, which
is based on the observation that if <span class="math inline">r</span>
is the remainder when <span class="math inline">a</span> is divided by
<span class="math inline">b</span>, then <span
class="math inline">\gcd(a, b) = \gcd(b, r)</span>. As a base case, we
can consider <span class="math inline">\gcd(a, 0) = a</span>.</p>
<p>Write a function called <code>gcd</code> that takes parameters
<code>a</code> and <code>b</code> and returns their greatest common
divisor.</p>
<p>If you need help, see <a
href="http://en.wikipedia.org/wiki/Euclidean_algorithm">http://en.wikipedia.org/wiki/Euclidean_algorithm</a>.</p></li>
</ol>
<h2 id="chapter-2-algebra">Chapter 2: Algebra</h2>
<p><em>Algebraic Data Types and some curious analogies</em></p>
<p>In this chapter, we will deepen our understanding of OCaml’s type
system by working through type inference examples by hand. Then we will
explore algebraic data types—a cornerstone of functional programming
that allows us to define rich, structured data. Along the way, we will
discover a surprising and beautiful connection between these types and
ordinary polynomials from high-school algebra.</p>
<h3 id="a-glimpse-at-type-inference">2.1 A Glimpse at Type
Inference</h3>
<p>For a refresher, let us apply the type inference rules introduced in
Chapter 1 to some simple examples. We will start with the identity
function <code>fun x -&gt; x</code>—perhaps the simplest possible
function, yet one that reveals important aspects of polymorphism. In the
derivations below, <span class="math inline">[?]</span> means “dunno
yet” (type unknown).</p>
<p>We begin with an incomplete derivation:</p>
<p><span class="math display">
\frac{[?]}{\texttt{fun x -&gt; x} : [?]}
</span></p>
<p>Using the <span class="math inline">\rightarrow</span> introduction
rule, we need to derive the body <code>x</code> assuming <code>x</code>
has some type <span class="math inline">a</span>:</p>
<p><span class="math display">
\frac{\frac{\,}{\texttt{x} : a}^x}{\texttt{fun x -&gt; x} : [?]
\rightarrow [?]}
</span></p>
<p>The premise <span class="math inline">\frac{\,}{\texttt{x} :
a}^x</span> matches the pattern for hypothetical derivations since <span
class="math inline">e = \texttt{x}</span>. Since the body <code>x</code>
has type <span class="math inline">a</span> (from our assumption), and
the parameter <code>x</code> also has type <span
class="math inline">a</span>, we conclude:</p>
<p><span class="math display">
\frac{\frac{\,}{\texttt{x} : a}^x}{\texttt{fun x -&gt; x} : a
\rightarrow a}
</span></p>
<p>Because <span class="math inline">a</span> is arbitrary (we made no
assumptions constraining it), OCaml introduces a <em>type variable</em>
<code>'a</code> to represent it. This is how polymorphism emerges
naturally from the inference process—the identity function can work with
values of any type:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a># <span class="kw">fun</span> x -&gt; x;;</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>- : &#39;a -&gt; &#39;a = &lt;<span class="kw">fun</span>&gt;</span></code></pre></div>
<h4 id="a-more-complex-example">A More Complex Example</h4>
<p>Now let us try something that will constrain the types more:
<code>fun x -&gt; x+1</code>. This is the same as
<code>fun x -&gt; ((+) x) 1</code> (try it in OCaml to verify!). The
addition operator forces specific types upon us.</p>
<p>We will use the notation <span class="math inline">[?\alpha]</span>
to mean “type unknown yet, but the same as in other places marked <span
class="math inline">[?\alpha]</span>.” This notation helps us track how
constraints propagate through the derivation.</p>
<p>Starting the derivation and applying <span
class="math inline">\rightarrow</span> introduction:</p>
<p><span class="math display">
\frac{\frac{[?]}{\texttt{((+) x) 1} : [?\alpha]}}{\texttt{fun x -&gt;
((+) x) 1} : [?] \rightarrow [?\alpha]}
</span></p>
<p>Applying <span class="math inline">\rightarrow</span> elimination
(function application) to <code>((+) x) 1</code>:</p>
<p><span class="math display">
\frac{\frac{\frac{[?]}{\texttt{(+) x} : [?\beta] \rightarrow [?\alpha]}
\quad \frac{[?]}{\texttt{1} : [?\beta]}}{\texttt{((+) x) 1} :
[?\alpha]}}{\texttt{fun x -&gt; ((+) x) 1} : [?] \rightarrow [?\alpha]}
</span></p>
<p>We know that <code>1 : int</code>, so <span
class="math inline">[?\beta] = \texttt{int}</span>:</p>
<p><span class="math display">
\frac{\frac{\frac{[?]}{\texttt{(+) x} : \texttt{int} \rightarrow
[?\alpha]} \quad \frac{\,}{\texttt{1} :
\texttt{int}}^{\text{(constant)}}}{\texttt{((+) x) 1} :
[?\alpha]}}{\texttt{fun x -&gt; ((+) x) 1} : [?] \rightarrow [?\alpha]}
</span></p>
<p>Applying function application again to <code>(+) x</code>:</p>
<p><span class="math display">
\frac{\frac{\frac{\frac{[?]}{\texttt{(+)} : [?\gamma] \rightarrow
\texttt{int} \rightarrow [?\alpha]} \quad \frac{[?]}{\texttt{x} :
[?\gamma]}}{\texttt{(+) x} : \texttt{int} \rightarrow [?\alpha]} \quad
\frac{\,}{\texttt{1} : \texttt{int}}^{\text{(constant)}}}{\texttt{((+)
x) 1} : [?\alpha]}}{\texttt{fun x -&gt; ((+) x) 1} : [?\gamma]
\rightarrow [?\alpha]}
</span></p>
<p>Since <code>(+) : int -&gt; int -&gt; int</code>, we have <span
class="math inline">[?\gamma] = \texttt{int}</span> and <span
class="math inline">[?\alpha] = \texttt{int}</span>:</p>
<p><span class="math display">
\frac{\frac{\frac{\frac{\,}{\texttt{(+)} : \texttt{int} \rightarrow
\texttt{int} \rightarrow \texttt{int}}^{\text{(constant)}} \quad
\frac{\,}{\texttt{x} : \texttt{int}}^x}{\texttt{(+) x} : \texttt{int}
\rightarrow \texttt{int}} \quad \frac{\,}{\texttt{1} :
\texttt{int}}^{\text{(constant)}}}{\texttt{((+) x) 1} :
\texttt{int}}}{\texttt{fun x -&gt; ((+) x) 1} : \texttt{int} \rightarrow
\texttt{int}}
</span></p>
<h4 id="curried-form">Curried Form</h4>
<p>When there are several arrows “on the same depth” in a function type,
it means that the function returns a function. For example,
<code>(+) : int -&gt; int -&gt; int</code> is just a shorthand for
<code>(+) : int -&gt; (int -&gt; int)</code>. The arrow associates to
the right, so we can omit the parentheses.</p>
<p>This is very different from:</p>
<p><span class="math display">
\texttt{fun f -&gt; (f 1) + 1} : (\texttt{int} \rightarrow \texttt{int})
\rightarrow \texttt{int}
</span></p>
<p>In the first case, <code>(+)</code> is a function that takes an
integer and returns a function from integers to integers. In the second
case, we have a function that takes a function as an argument—a
<em>higher-order function</em>. The parentheses around
<code>int -&gt; int</code> are essential here; without them, the meaning
would be completely different.</p>
<p>This style of defining multi-argument functions, where each function
takes one argument and returns another function expecting the remaining
arguments, is called <em>curried form</em> (named after logician Haskell
Curry). It enables a powerful technique called <em>partial
application</em>.</p>
<p>For example, instead of writing <code>(fun x -&gt; x+1)</code>, we
can simply write <code>((+) 1)</code>. Here we apply <code>(+)</code> to
just one argument, getting back a function that adds 1 to its input.
What expanded form does <code>((+) 1)</code> correspond to exactly
(computationally)?</p>
<p><em>Think about it before reading on…</em></p>
<p>It corresponds to <code>fun y -&gt; 1 + y</code>. We have “baked in”
the first argument, and the resulting function waits for the second.</p>
<p>We will become more familiar with functions returning functions when
we study the <em>lambda calculus</em> in a later chapter.</p>
<h3 id="algebraic-data-types">2.2 Algebraic Data Types</h3>
<p>In Chapter 1, we learned about the <code>unit</code> type and variant
types like:</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> int_string_choice = A <span class="kw">of</span> <span class="dt">int</span> | B <span class="kw">of</span> <span class="dt">string</span></span></code></pre></div>
<p>We also covered tuple types, record types, and type definitions. Now
let us explore these concepts more deeply, building up to the powerful
notion of <em>algebraic data types</em>.</p>
<h4 id="variants-without-arguments">Variants Without Arguments</h4>
<p>Variants do not have to carry arguments. Instead of writing
<code>A of unit</code>, we can simply use <code>A</code>. This is more
convenient and idiomatic:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> color = Red | Green | Blue</span></code></pre></div>
<p>This defines a type with exactly three possible values—no more, no
less. The compiler knows this, which enables exhaustive pattern matching
checks.</p>
<p><strong>A subtle point about OCaml:</strong> In OCaml, variants take
multiple arguments rather than taking tuples as arguments. This means
<code>A of int * string</code> is different from
<code>A of (int * string)</code>. The first takes two separate
arguments, while the second takes a single tuple argument. This
distinction is usually not important—until you get bitten by it in some
corner case! For most purposes, you can ignore it.</p>
<h4 id="recursive-type-definitions">Recursive Type Definitions</h4>
<p>Here is where things get really interesting: type definitions can be
recursive! This allows us to define data structures of arbitrary size
using a finite definition:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> int_list = Empty | Cons <span class="kw">of</span> <span class="dt">int</span> * int_list</span></code></pre></div>
<p>Let us see what values inhabit <code>int_list</code>. The definition
tells us there are two ways to build an <code>int_list</code>: -
<code>Empty</code> represents the empty list—a list with no elements -
<code>Cons (5, Empty)</code> is a list containing just 5 -
<code>Cons (5, Cons (7, Cons (13, Empty)))</code> is a list containing
5, 7, and 13</p>
<p>Notice how <code>Cons</code> takes an integer and another
<code>int_list</code>, allowing us to chain together as many elements as
we like. This recursive structure is the essence of how functional
languages represent unbounded data.</p>
<p>The built-in type <code>bool</code> can be viewed as if it were
defined as <code>type bool = true | false</code>—just a variant with two
constructors. Similarly, <code>int</code> can be thought of as a very
large variant: <code>type int = 0 | -1 | 1 | -2 | 2 | ...</code> (though
of course the compiler implements it more efficiently!)</p>
<h4 id="parametric-type-definitions">Parametric Type Definitions</h4>
<p>Our <code>int_list</code> type only works with integers. But what if
we want a list of strings? Or a list of booleans? We would have to
define separate types for each, duplicating the same structure.</p>
<p>Type definitions can be <em>parametric</em> with respect to the types
of their components. This allows us to define generic data structures
that work with any element type. For example, a list of elements of
arbitrary type:</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> &#39;elem <span class="dt">list</span> = Empty | Cons <span class="kw">of</span> &#39;elem * &#39;elem <span class="dt">list</span></span></code></pre></div>
<p>The <code>'elem</code> is a <em>type parameter</em>—a placeholder
that gets filled in when we use the type. We can have a
<code>string list</code>, an <code>int list</code>, or even an
<code>int list list</code> (a list of lists of integers).</p>
<p>Several conventions and syntax rules apply to parametric types:</p>
<ul>
<li><p>Type variables must start with <code>'</code>, but since OCaml
will not remember the names we give, it is customary to use the names
OCaml uses: <code>'a</code>, <code>'b</code>, <code>'c</code>,
<code>'d</code>, etc.</p></li>
<li><p>The OCaml syntax places the type parameter before the type name,
mimicking English word order. A silly example that reads almost like
English:</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> &#39;white_color dog = Dog <span class="kw">of</span> &#39;white_color</span></code></pre></div>
<p>This defines a “white-color dog” type—the syntax reads
naturally!</p></li>
<li><p>With multiple parameters, OCaml uses parentheses:</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> (&#39;a, &#39;b) choice = Left <span class="kw">of</span> &#39;a | Right <span class="kw">of</span> &#39;b</span></code></pre></div>
<p>Compare this to F# syntax:
<code>type choice&lt;'a,'b&gt; = Left of 'a | Right of 'b</code></p>
<p>And Haskell syntax:
<code>data Choice a b = Left a | Right b</code></p>
<p>Different languages have different conventions, but the underlying
concept is the same.</p></li>
</ul>
<h3 id="syntactic-bread-and-sugar">2.3 Syntactic Bread and Sugar</h3>
<p>OCaml provides various syntactic conveniences—sometimes called
<em>syntactic sugar</em>—that make code more pleasant to write and read.
Let us survey the most important ones.</p>
<h4 id="constructor-naming">Constructor Naming</h4>
<p>Names of variants, called <em>constructors</em>, must start with a
capital letter. If we wanted to define our own booleans, we would
write:</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> my_bool = True | False</span></code></pre></div>
<p>Only constructors and module names can start with capital letters in
OCaml. Everything else (values, functions, type names) must start with a
lowercase letter. This convention makes it easy to distinguish
constructors at a glance.</p>
<p><em>Modules</em> are organizational units (like “shelves”) containing
related values. For example, the <code>List</code> module provides
operations on lists, including <code>List.map</code> and
<code>List.filter</code>. We will learn more about modules in later
chapters.</p>
<h4 id="accessing-record-fields">Accessing Record Fields</h4>
<p>Did we mention that we can use dot notation to access record fields?
The syntax <code>record.field</code> extracts a field value. For
example, if we have <code>let person = {name="Alice"; age=30}</code>, we
can write <code>person.name</code> to get <code>"Alice"</code>.</p>
<h4 id="function-definition-shortcuts">Function Definition
Shortcuts</h4>
<p>Several syntactic shortcuts make function definitions more concise.
These are worth memorizing, as you will see them constantly in OCaml
code:</p>
<ul>
<li><p><code>fun x y -&gt; e</code> stands for
<code>fun x -&gt; fun y -&gt; e</code>. Note that
<code>fun x -&gt; fun y -&gt; e</code> parses as
<code>fun x -&gt; (fun y -&gt; e)</code>. This shorthand aligns with
curried form—we can write multi-argument functions without nesting
<code>fun</code> expressions.</p></li>
<li><p><code>function A x -&gt; e1 | B y -&gt; e2</code> stands for
<code>fun p -&gt; match p with A x -&gt; e1 | B y -&gt; e2</code>. The
general form is: <code>function PATTERN-MATCHING</code> stands for
<code>fun v -&gt; match v with PATTERN-MATCHING</code>. This is handy
when you want to immediately pattern-match on a function’s
argument.</p></li>
<li><p><code>let f ARGS = e</code> is a shorthand for
<code>let f = fun ARGS -&gt; e</code>. This is probably the most common
way to define functions in practice.</p></li>
</ul>
<h3 id="pattern-matching">2.4 Pattern Matching</h3>
<p>Pattern matching is one of the most powerful features of OCaml and
similar languages. It lets us examine the structure of data and extract
components in a single, elegant construct.</p>
<p>Recall that we introduced <code>fst</code> and <code>snd</code> as
means to access elements of a pair. But what about larger tuples? There
is no built-in <code>thd</code> for the third element. The fundamental
way to access any tuple—or any algebraic data type—uses the
<code>match</code> construct. In fact, <code>fst</code> and
<code>snd</code> can easily be defined using pattern matching:</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="dt">fst</span> = <span class="kw">fun</span> p -&gt; <span class="kw">match</span> p <span class="kw">with</span> (a, b) -&gt; a</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="dt">snd</span> = <span class="kw">fun</span> p -&gt; <span class="kw">match</span> p <span class="kw">with</span> (a, b) -&gt; b</span></code></pre></div>
<p>The pattern <code>(a, b)</code> <em>destructures</em> the pair,
binding its first component to <code>a</code> and its second to
<code>b</code>. We then return whichever component we want.</p>
<h4 id="matching-on-records">Matching on Records</h4>
<p>Pattern matching also works with records, letting us extract multiple
fields at once:</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> person = {name: <span class="dt">string</span>; surname: <span class="dt">string</span>; age: <span class="dt">int</span>}</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> greet_person () =</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">match</span> {name=<span class="st">&quot;Walker&quot;</span>; surname=<span class="st">&quot;Johnnie&quot;</span>; age=<span class="dv">207</span>}</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">with</span> {name=n; surname=sn; age=a} -&gt; <span class="st">&quot;Hi &quot;</span> ^ sn ^ <span class="st">&quot;!&quot;</span></span></code></pre></div>
<p>Here we match against a record pattern, binding each field to a
variable. Note that we bind <code>name</code> to <code>n</code>,
<code>surname</code> to <code>sn</code>, and <code>age</code> to
<code>a</code>—then use <code>sn</code> in the greeting.</p>
<h4 id="understanding-patterns">Understanding Patterns</h4>
<p>The left-hand sides of <code>-&gt;</code> in <code>match</code>
expressions are called <strong>patterns</strong>. Patterns describe the
structure of values we want to match against. They can include: -
Constants (like <code>1</code>, <code>"hello"</code>, or
<code>true</code>) - Variables (which bind to the matched value) -
Constructors (like <code>None</code>, <code>Some x</code>, or
<code>Cons (h, t)</code>) - Tuples and records - Nested combinations of
all the above</p>
<p>Patterns can be nested to arbitrary depth, allowing us to match
complex structures in one go:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">match</span> <span class="dt">Some</span> (<span class="dv">5</span>, <span class="dv">7</span>) <span class="kw">with</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>| <span class="dt">None</span> -&gt; <span class="st">&quot;sum: nothing&quot;</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>| <span class="dt">Some</span> (x, y) -&gt; <span class="st">&quot;sum: &quot;</span> ^ <span class="dt">string_of_int</span> (x+y)</span></code></pre></div>
<p>Here <code>Some (x, y)</code> is a nested pattern: we match
<code>Some</code> of <em>something</em>, and that something must be a
pair, whose components we bind to <code>x</code> and <code>y</code>.</p>
<h4 id="simple-patterns-and-wildcards">Simple Patterns and
Wildcards</h4>
<p>A pattern can simply bind the entire value without destructuring.
Writing <code>match f x with v -&gt; ...</code> is the same as
<code>let v = f x in ...</code>. This is occasionally useful when you
want the syntax of <code>match</code> but do not need to take the value
apart.</p>
<p>When we do not need a value in a pattern, it is good practice to use
the underscore <code>_</code>, which is a <em>wildcard</em>. The
wildcard matches anything but does not bind it to a name. This signals
to the reader (and the compiler) that we are intentionally ignoring that
part:</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="dt">fst</span> (a, _) = a</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="dt">snd</span> (_, b) = b</span></code></pre></div>
<p>Using <code>_</code> instead of an unused variable name avoids
compiler warnings about unused bindings.</p>
<h4 id="pattern-linearity">Pattern Linearity</h4>
<p>A variable can only appear once in a pattern. This property is called
<em>linearity</em>. You might think this is a limitation—what if we want
to check that two parts of a structure are equal? We cannot write
<code>(x, x)</code> to match pairs with equal components.</p>
<p>However, we can add conditions to patterns using <code>when</code>,
so linearity is not really a limitation in practice:</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> describe_point p =</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">match</span> p <span class="kw">with</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  | (x, y) <span class="kw">when</span> x = y -&gt; <span class="st">&quot;diag&quot;</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  | _ -&gt; <span class="st">&quot;off-diag&quot;</span></span></code></pre></div>
<p>The <code>when</code> clause acts as a guard: the pattern matches
only if both the structure matches <em>and</em> the condition is
true.</p>
<p>Here is a more elaborate example showing how to implement a
comparison function:</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="dt">compare</span> a b = <span class="kw">match</span> a, b <span class="kw">with</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  | (x, y) <span class="kw">when</span> x &lt; y -&gt; <span class="dv">-1</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  | (x, y) <span class="kw">when</span> x = y -&gt; <span class="dv">0</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  | _ -&gt; <span class="dv">1</span></span></code></pre></div>
<p>Notice how we match against the tuple <code>(a, b)</code> in
different ways, using guards to distinguish the cases.</p>
<h4 id="partial-record-patterns">Partial Record Patterns</h4>
<p>We can skip unused fields of a record in a pattern. Only the fields
we care about need to be mentioned. This keeps patterns concise and
means we do not have to update every pattern when we add a new field to
a record type.</p>
<h4 id="or-patterns">Or-Patterns</h4>
<p>We can compress patterns by using <code>|</code> inside a single
pattern to match multiple alternatives. This is different from having
multiple pattern clauses—it lets us share a single right-hand side for
several patterns:</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> month =</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  | Jan | Feb | Mar | Apr | May | Jun</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  | Jul | Aug | Sep | Oct | Nov | Dec</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> weekday = Mon | Tue | Wed | Thu | Fri | Sat | Sun</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> date =</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  {year: <span class="dt">int</span>; month: month; day: <span class="dt">int</span>; weekday: weekday}</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> day =</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>  {year = <span class="dv">2012</span>; month = Feb; day = <span class="dv">14</span>; weekday = Wed};;</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="kw">match</span> day <span class="kw">with</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>  | {weekday = Sat | Sun; _} -&gt; <span class="st">&quot;Weekend!&quot;</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>  | _ -&gt; <span class="st">&quot;Work day&quot;</span></span></code></pre></div>
<p>The pattern <code>Sat | Sun</code> matches either <code>Sat</code> or
<code>Sun</code>. This is much cleaner than writing two separate clauses
with the same right-hand side.</p>
<h4 id="named-patterns-with-as">Named Patterns with <code>as</code></h4>
<p>Sometimes we want to both destructure a value <em>and</em> keep a
reference to the whole thing (or some intermediate part). We use
<code>(pattern as v)</code> to name a nested pattern, binding the
matched value to <code>v</code>:</p>
<pre><code>match day with
  | {weekday = (Mon | Tue | Wed | Thu | Fri as wday); _}
      when not (day.month = Dec &amp;&amp; day.day = 24) -&gt;
    Some (work (get_plan wday))
  | _ -&gt; None</code></pre>
<p>This example demonstrates several features working together:</p>
<ul>
<li>An or-pattern matches any weekday from Monday to Friday</li>
<li>The <code>as wday</code> clause binds the matched weekday to the
variable <code>wday</code></li>
<li>A <code>when</code> guard checks that it is not Christmas Eve</li>
<li>The bound variable <code>wday</code> is then used in the expression
<code>get_plan wday</code></li>
</ul>
<p>This combination of features makes OCaml’s pattern matching
remarkably expressive.</p>
<h3 id="interpreting-algebraic-data-types-as-polynomials">2.5
Interpreting Algebraic Data Types as Polynomials</h3>
<p>Now we come to one of the most delightful aspects of algebraic data
types: they really are <em>algebraic</em> in a precise mathematical
sense. Let us explore a curious analogy between types and polynomials
that turns out to be surprisingly deep.</p>
<p>The translation from types to mathematical expressions works as
follows:</p>
<ul>
<li>Replace <code>|</code> (variant choice) with <span
class="math inline">+</span> (addition)</li>
<li>Replace <code>*</code> (tuple product) with <span
class="math inline">\times</span> (multiplication)</li>
<li>Treat record types as tuple types (erasing field names and
translating <code>;</code> as <span
class="math inline">\times</span>)</li>
</ul>
<p>We also need translations for some special types:</p>
<ul>
<li><p>The <strong>void type</strong> (a type with no constructors,
hence no values):</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> void</span></code></pre></div>
<p>(Yes, this is its complete definition, with no
<code>= something</code> part.) Since no values can be constructed, it
represents emptiness—translate it as <span
class="math inline">0</span>.</p></li>
<li><p>The <strong>unit type</strong> has exactly one value, so
translate it as <span class="math inline">1</span>. Since variants
without arguments behave like variants <code>of unit</code>, translate
them as <span class="math inline">1</span> as well.</p></li>
<li><p>The <strong>bool type</strong> has exactly two values
(<code>true</code> and <code>false</code>), so translate it as <span
class="math inline">2</span>.</p></li>
<li><p>Types like <code>int</code>, <code>string</code>,
<code>float</code>, and type parameters are treated as variables. We do
not care about their exact number of values; we just give them symbolic
names like <span class="math inline">x</span>, <span
class="math inline">y</span>, etc.</p></li>
<li><p>Defined types translate according to their definitions
(substituting variables as necessary).</p></li>
</ul>
<p>Give a name to the type being defined (representing a function of the
introduced variables). Now interpret the result as an ordinary numeric
polynomial! (Or a “rational function” if recursively defined.)</p>
<p>This might seem like a mere curiosity, but it leads to real insights.
Let us have some fun with it!</p>
<h4 id="example-date-type">Example: Date Type</h4>
<div class="sourceCode" id="cb22"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> date = {year: <span class="dt">int</span>; month: <span class="dt">int</span>; day: <span class="dt">int</span>}</span></code></pre></div>
<p>A date is a record with three <code>int</code> fields. Translating to
a polynomial (using <span class="math inline">x</span> for
<code>int</code>):</p>
<p><span class="math display">D = x \times x \times x = x^3</span></p>
<p>The cube makes sense: a date is essentially a triple of integers.</p>
<h4 id="example-option-type">Example: Option Type</h4>
<p>The built-in option type is defined as:</p>
<pre><code>type &#39;a option = None | Some of &#39;a</code></pre>
<p>Translating (using <span class="math inline">x</span> for the type
parameter <code>'a</code>):</p>
<p><span class="math display">O = 1 + x</span></p>
<p>This reads as: an option is either nothing (1) or something of type
<span class="math inline">x</span>. The polynomial <span
class="math inline">1 + x</span> is beautifully simple!</p>
<h4 id="example-list-type">Example: List Type</h4>
<div class="sourceCode" id="cb24"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> &#39;a my_list = Empty | Cons <span class="kw">of</span> &#39;a * &#39;a my_list</span></code></pre></div>
<p>Translating (where <span class="math inline">L</span> represents the
list type itself, and <span class="math inline">x</span> represents the
element type):</p>
<p><span class="math display">L = 1 + x \cdot L</span></p>
<p>This is a recursive equation! A list is either empty (<span
class="math inline">1</span>) or an element times another list (<span
class="math inline">x \cdot L</span>). If you solve this equation
algebraically, you get <span class="math inline">L = \frac{1}{1-x} = 1 +
x + x^2 + x^3 + \ldots</span>, which corresponds to: a list is either
empty, or has one element, or has two elements, etc.</p>
<h4 id="example-binary-tree-type">Example: Binary Tree Type</h4>
<div class="sourceCode" id="cb25"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> btree = Tip | Node <span class="kw">of</span> <span class="dt">int</span> * btree * btree</span></code></pre></div>
<p>Translating:</p>
<p><span class="math display">T = 1 + x \cdot T \cdot T = 1 + x \cdot
T^2</span></p>
<p>A binary tree is either a tip (<span class="math inline">1</span>) or
a node containing a value and two subtrees (<span class="math inline">x
\cdot T^2</span>).</p>
<h4 id="type-isomorphisms">Type Isomorphisms</h4>
<p>Here is the remarkable payoff: when translations of two types are
equal according to the laws of high-school algebra, the types are
<em>isomorphic</em>. This means there exist bijective (one-to-one and
onto) functions between them—you can convert from one type to the other
and back without losing any information.</p>
<p>Let us play with the binary tree polynomial and see where algebra
takes us:</p>
<p><span class="math display">
\begin{aligned}
T &amp;= 1 + x \cdot T^2 \\
  &amp;= 1 + x \cdot T + x^2 \cdot T^3 \\
  &amp;= 1 + x + x^2 \cdot T^2 + x^2 \cdot T^3 \\
  &amp;= 1 + x + x^2 \cdot T^2 \cdot (1 + T) \\
  &amp;= 1 + x \cdot (1 + x \cdot T^2 \cdot (1 + T))
\end{aligned}
</span></p>
<p>Each step uses standard algebraic manipulations: substituting <span
class="math inline">T = 1 + xT^2</span>, expanding, factoring, and
rearranging. The result is a different but algebraically equivalent
expression.</p>
<p>Now let us translate this resulting expression back to a type:</p>
<div class="sourceCode" id="cb26"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> repr =</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  (<span class="dt">int</span> * (<span class="dt">int</span> * btree * btree * btree <span class="dt">option</span>) <span class="dt">option</span>) <span class="dt">option</span></span></code></pre></div>
<p>Reading the polynomial <span class="math inline">1 + x \cdot (1 + x
\cdot T^2 \cdot (1 + T))</span> from outside in: we have an option (the
outermost <span class="math inline">1 + \ldots</span>), whose
<code>Some</code> case contains an <code>int</code> times another
option, and so on.</p>
<p>The challenge is to find isomorphism functions with signatures:</p>
<pre><code>val iso1 : btree -&gt; repr
val iso2 : repr -&gt; btree</code></pre>
<p>These functions should satisfy: for all trees <code>t</code>,
<code>iso2 (iso1 t) = t</code>, and for all representations
<code>r</code>, <code>iso1 (iso2 r) = r</code>. Can you write them?</p>
<h4 id="my-first-failed-attempt">My First (Failed) Attempt</h4>
<p>Here is my first attempt, trying to guess the pattern directly:</p>
<pre><code># let iso1 (t : btree) : repr =
  match t with
    | Tip -&gt; None
    | Node (x, Tip, Tip) -&gt; Some (x, None)
    | Node (x, Node (y, t1, t2), Tip) -&gt;
      Some (x, Some (y, t1, t2, None))
    | Node (x, Node (y, t1, t2), t3) -&gt;
      Some (x, Some (y, t1, t2, Some t3));;

Warning 8: this pattern-matching is not exhaustive.
Here is an example of a value that is not matched:
Node (_, Tip, Node (_, _, _))</code></pre>
<p>I forgot about one case! The case
<code>Node (_, Tip, Node (_, _, _))</code>—a node with an empty left
subtree and non-empty right subtree—was not covered. It seems difficult
to guess the solution directly when trying to map the complex final form
all at once.</p>
<p>Have you found it on your first try? If so, congratulations! Most
people do not. This illustrates an important principle: complex
transformations are easier to get right when broken into smaller
steps.</p>
<h4 id="breaking-down-the-problem">Breaking Down the Problem</h4>
<p>Let us divide the task into smaller steps corresponding to
intermediate points in the polynomial transformation. Instead of jumping
from <span class="math inline">T = 1 + xT^2</span> directly to the final
form, we will introduce intermediate types for each algebraic step:</p>
<div class="sourceCode" id="cb29"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> (&#39;a, &#39;b) choice = Left <span class="kw">of</span> &#39;a | Right <span class="kw">of</span> &#39;b</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> interm1 =</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>  ((<span class="dt">int</span> * btree, <span class="dt">int</span> * <span class="dt">int</span> * btree * btree * btree) choice)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">option</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> interm2 =</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>  ((<span class="dt">int</span>, <span class="dt">int</span> * <span class="dt">int</span> * btree * btree * btree <span class="dt">option</span>) choice)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">option</span></span></code></pre></div>
<p>Now we can define each step:</p>
<div class="sourceCode" id="cb30"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> step1r (t : btree) : interm1 =</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">match</span> t <span class="kw">with</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    | Tip -&gt; <span class="dt">None</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    | Node (x, t1, Tip) -&gt; <span class="dt">Some</span> (Left (x, t1))</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    | Node (x, t1, Node (y, t2, t3)) -&gt;</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Some</span> (Right (x, y, t1, t2, t3))</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> step2r (r : interm1) : interm2 =</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">match</span> r <span class="kw">with</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    | <span class="dt">None</span> -&gt; <span class="dt">None</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    | <span class="dt">Some</span> (Left (x, Tip)) -&gt; <span class="dt">Some</span> (Left x)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    | <span class="dt">Some</span> (Left (x, Node (y, t1, t2))) -&gt;</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Some</span> (Right (x, y, t1, t2, <span class="dt">None</span>))</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    | <span class="dt">Some</span> (Right (x, y, t1, t2, t3)) -&gt;</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Some</span> (Right (x, y, t1, t2, <span class="dt">Some</span> t3))</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> step3r (r : interm2) : repr =</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>  <span class="kw">match</span> r <span class="kw">with</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    | <span class="dt">None</span> -&gt; <span class="dt">None</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    | <span class="dt">Some</span> (Left x) -&gt; <span class="dt">Some</span> (x, <span class="dt">None</span>)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    | <span class="dt">Some</span> (Right (x, y, t1, t2, t3opt)) -&gt;</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Some</span> (x, <span class="dt">Some</span> (y, t1, t2, t3opt))</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> iso1 (t : btree) : repr =</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>  step3r (step2r (step1r t))</span></code></pre></div>
<p>Each step function handles one small transformation, and the compiler
verifies that our pattern matching is exhaustive. No more missed
cases!</p>
<p><strong>Exercise:</strong> Define <code>step1l</code>,
<code>step2l</code>, <code>step3l</code>, and <code>iso2</code>.</p>
<p><em>Hint:</em> Now it is straightforward—each step is simply the
inverse of its corresponding forward step. The left-going functions undo
what the right-going functions do.</p>
<h4 id="take-home-lessons">Take-Home Lessons</h4>
<p>This exploration of type isomorphisms teaches us two valuable
principles:</p>
<ol type="1">
<li><p><strong>Design for validity:</strong> Try to define data
structures so that only meaningful information can be represented—as
long as it does not overcomplicate the data structures. Avoid catch-all
clauses when defining functions. The compiler will then tell you if you
have forgotten about a case. The exhaustiveness checker is your
friend.</p></li>
<li><p><strong>Divide and conquer:</strong> Break solutions into small
steps so that each step can be easily understood and verified. When I
tried to write <code>iso1</code> directly, I made a mistake. When I
broke it into three simple steps, each step was obviously correct, and
composing them gave the right answer.</p></li>
</ol>
<h3 id="differentiating-algebraic-data-types">2.6 Differentiating
Algebraic Data Types</h3>
<p>Of course, you might object that the pompous title is wrong—we will
differentiate the translated polynomials, not the types themselves. Fair
enough! But what sense does differentiating a type’s polynomial
make?</p>
<p>It turns out that taking the partial derivative of a polynomial
(translated from a data type), when translated back, gives a type
representing a “one-hole context”—a data structure with one piece
missing. This missing piece corresponds to the variable with respect to
which we differentiated. The derivative tells us: “Here are all the ways
to point at one element of this type.”</p>
<h4 id="example-differentiating-the-date-type">Example: Differentiating
the Date Type</h4>
<p>Let us start with our familiar date type:</p>
<div class="sourceCode" id="cb31"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> date = {year: <span class="dt">int</span>; month: <span class="dt">int</span>; day: <span class="dt">int</span>}</span></code></pre></div>
<p>The translation and its derivative:</p>
<p><span class="math display">
\begin{aligned}
D &amp;= x \cdot x \cdot x = x^3 \\
\frac{\partial D}{\partial x} &amp;= 3x^2 = x \cdot x + x \cdot x + x
\cdot x
\end{aligned}
</span></p>
<p>We could have left it as <span class="math inline">3 \cdot x \cdot
x</span>, but expanding it as a sum shows the structure more clearly.
The derivative <span class="math inline">3x^2</span> says: there are
three ways to “point at” an <code>int</code> in a date, and each way
leaves two other <code>int</code>s behind.</p>
<p>Translating the expanded form back to a type:</p>
<div class="sourceCode" id="cb32"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> date_deriv =</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>  Year <span class="kw">of</span> <span class="dt">int</span> * <span class="dt">int</span> | Month <span class="kw">of</span> <span class="dt">int</span> * <span class="dt">int</span> | Day <span class="kw">of</span> <span class="dt">int</span> * <span class="dt">int</span></span></code></pre></div>
<p>Each variant represents a “hole” at a different position: -
<code>Year (m, d)</code> means the year field is the hole (and we have
the month <code>m</code> and day <code>d</code>) -
<code>Month (y, d)</code> means the month field is the hole (and we have
year <code>y</code> and day <code>d</code>) - <code>Day (y, m)</code>
means the day field is the hole</p>
<p>Now we can define functions to introduce and eliminate this
derivative type:</p>
<div class="sourceCode" id="cb33"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> date_deriv {year=y; month=m; day=d} =</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>  [Year (m, d); Month (y, d); Day (y, m)]</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> date_integr n = <span class="kw">function</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  | Year (m, d) -&gt; {year=n; month=m; day=d}</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>  | Month (y, d) -&gt; {year=y; month=n; day=d}</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  | Day (y, m) -&gt; {year=y; month=m; day=n}</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>;;</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="dt">List</span>.map (date_integr <span class="dv">7</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>  (date_deriv {year=<span class="dv">2012</span>; month=<span class="dv">2</span>; day=<span class="dv">14</span>})</span></code></pre></div>
<p>The <code>date_deriv</code> function produces all contexts (one for
each field)—it “differentiates” a date into a list of one-hole contexts.
The <code>date_integr</code> function fills in a hole with a new
value—it “integrates” by putting a value back into the context. Notice
how the naming follows the calculus analogy!</p>
<p>The example above takes the date February 14, 2012, produces three
contexts (one for each field), and then fills each hole with the number
7, producing three modified dates.</p>
<h4 id="example-differentiating-binary-trees">Example: Differentiating
Binary Trees</h4>
<p>Now let us tackle the more challenging case of binary trees:</p>
<div class="sourceCode" id="cb34"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> btree = Tip | Node <span class="kw">of</span> <span class="dt">int</span> * btree * btree</span></code></pre></div>
<p>The translation and differentiation:</p>
<p><span class="math display">
\begin{aligned}
T &amp;= 1 + x \cdot T^2 \\
\frac{\partial T}{\partial x} &amp;= 0 + T^2 + 2 \cdot x \cdot T \cdot
\frac{\partial T}{\partial x} = T \cdot T + 2 \cdot x \cdot T \cdot
\frac{\partial T}{\partial x}
\end{aligned}
</span></p>
<p>Something interesting happened: the derivative is recursive! It
refers to itself via <span class="math inline">\frac{\partial
T}{\partial x}</span>. This makes perfect sense when you think about
it:</p>
<ul>
<li><span class="math inline">T \cdot T</span> represents pointing at
the root: the hole is at the current node, and we have the two
subtrees.</li>
<li><span class="math inline">2 \cdot x \cdot T \cdot \frac{\partial
T}{\partial x}</span> represents pointing deeper in the tree: we choose
left or right (the factor of 2), remember the current node’s value
(<span class="math inline">x</span>), keep the other subtree (<span
class="math inline">T</span>), and then have a context in the chosen
subtree (<span class="math inline">\frac{\partial T}{\partial
x}</span>).</li>
</ul>
<p>Instead of translating <span class="math inline">2</span> as
<code>bool</code>, we introduce a more descriptive type to make the code
clearer:</p>
<div class="sourceCode" id="cb35"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> btree_dir = LeftBranch | RightBranch</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> btree_deriv =</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>  | Here <span class="kw">of</span> btree * btree</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>  | Below <span class="kw">of</span> btree_dir * <span class="dt">int</span> * btree * btree_deriv</span></code></pre></div>
<p>The <code>Here</code> constructor means the hole is at the current
position, and we have the left and right subtrees. The
<code>Below</code> constructor means we go down one level, remembering
which direction we went, the value at the node we passed, and the
subtree we did not enter.</p>
<p>(You might someday hear about <em>zippers</em>—they are “inverted”
relative to our type. In a zipper, the hole comes first, and the context
trails behind. Both representations are useful in different
situations.)</p>
<p><strong>Exercise:</strong> Write a function that takes a number and a
<code>btree_deriv</code>, and builds a <code>btree</code> by putting the
number into the “hole” in <code>btree_deriv</code>.</p>
<details>
<summary>
Solution
</summary>
<p>The integration function fills the hole with a value. It must be
recursive because the derivative type is recursive—we may need to
descend through multiple <code>Below</code> constructors before reaching
the <code>Here</code> where the hole actually is:</p>
<div class="sourceCode" id="cb36"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> btree_integr n = <span class="kw">function</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  | Here (ltree, rtree) -&gt; Node (n, ltree, rtree)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>  | Below (LeftBranch, m, rtree, deriv) -&gt;</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    Node (m, btree_integr n deriv, rtree)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>  | Below (RightBranch, m, ltree, deriv) -&gt;</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    Node (m, ltree, btree_integr n deriv)</span></code></pre></div>
<p>When we reach <code>Here</code>, we create a node with the new value
<code>n</code> and the two subtrees. When we see <code>Below</code>, we
reconstruct the node we passed through and recursively integrate into
the appropriate subtree.</p>
</details>
<h3 id="exercises-1">2.7 Exercises</h3>
<h4 id="exercise-1-designing-valid-data-structures">Exercise 1:
Designing Valid Data Structures</h4>
<p><em>Due to Yaron Minsky.</em></p>
<p>This exercise practices the principle of “making invalid states
unrepresentable.” Consider a datatype to store internet connection
information. The time <code>when_initiated</code> marks the start of
connecting and is not needed after the connection is established (it is
only used to decide whether to give up trying to connect). The ping
information is available for established connections but not straight
away.</p>
<pre><code>type connectionstate = Connecting | Connected | Disconnected

type connectioninfo = {
  state : connectionstate;
  server : Inetaddr.t;
  lastpingtime : Time.t option;
  lastpingid : int option;
  sessionid : string option;
  wheninitiated : Time.t option;
  whendisconnected : Time.t option;
}</code></pre>
<p>(The types <code>Time.t</code> and <code>Inetaddr.t</code> come from
the <em>Core</em> library. You can replace them with <code>float</code>
and <code>Unix.inet_addr</code>. Load the Unix library in the
interactive toplevel with <code>#load "unix.cma";;</code>.)</p>
<p>The problem with this design is that it allows many nonsensical
combinations: a <code>Connecting</code> state with ping information, a
<code>Disconnected</code> state with a session ID, etc. The optional
fields (all those <code>option</code> types) make it unclear which
fields are valid in which states.</p>
<p>Rewrite the type definitions so that the datatype will contain only
reasonable combinations of information. Use separate record types for
each connection state, with only the fields that make sense for that
state.</p>
<h4 id="exercise-2-labeled-and-optional-arguments">Exercise 2: Labeled
and Optional Arguments</h4>
<p>In OCaml, functions can have labeled arguments and optional arguments
(parameters with default values that can be omitted). This exercise
explores these features.</p>
<p>Labels can differ from the names of argument values:</p>
<div class="sourceCode" id="cb38"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> f ~meaningfulname:n = n + <span class="dv">1</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> _ = f ~meaningfulname:<span class="dv">5</span>  <span class="co">(* We do not need the result so we ignore it. *)</span></span></code></pre></div>
<p>When the label and value names are the same, the syntax is
shorter:</p>
<div class="sourceCode" id="cb39"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> g ~pos ~len =</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">StringLabels</span>.sub <span class="st">&quot;0123456789abcdefghijklmnopqrstuvwxyz&quot;</span> ~pos ~len</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> () =  <span class="co">(* A nicer way to mark computations that return unit. *)</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> pos = <span class="dt">Random</span>.<span class="dt">int</span> <span class="dv">26</span> <span class="kw">in</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> len = <span class="dt">Random</span>.<span class="dt">int</span> <span class="dv">10</span> <span class="kw">in</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">print_string</span> (g ~pos ~len)</span></code></pre></div>
<p>When some function arguments are optional, the function must take
non-optional arguments after the last optional argument. Optional
parameters with default values:</p>
<div class="sourceCode" id="cb40"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> h ?(len=<span class="dv">1</span>) pos = g ~pos ~len</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> () = <span class="dt">print_string</span> (h <span class="dv">10</span>)</span></code></pre></div>
<p>Optional arguments are implemented as parameters of an option type.
This allows checking whether the argument was provided:</p>
<div class="sourceCode" id="cb41"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> foo ?bar n =</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">match</span> bar <span class="kw">with</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    | <span class="dt">None</span> -&gt; <span class="st">&quot;Argument = &quot;</span> ^ <span class="dt">string_of_int</span> n</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    | <span class="dt">Some</span> m -&gt; <span class="st">&quot;Sum = &quot;</span> ^ <span class="dt">string_of_int</span> (m + n)</span></code></pre></div>
<p>We can use it in various ways:</p>
<div class="sourceCode" id="cb42"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> _ = foo <span class="dv">5</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> _ = foo ~bar:<span class="dv">5</span> <span class="dv">7</span></span></code></pre></div>
<p>We can also provide the option value directly:</p>
<div class="sourceCode" id="cb43"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> test_foo () =</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> bar = <span class="kw">if</span> <span class="dt">Random</span>.<span class="dt">int</span> <span class="dv">10</span> &lt; <span class="dv">5</span> <span class="kw">then</span> <span class="dt">None</span> <span class="kw">else</span> <span class="dt">Some</span> <span class="dv">7</span> <span class="kw">in</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  foo ?bar <span class="dv">7</span></span></code></pre></div>
<ol type="1">
<li><p>Observe the types that functions with labeled and optional
arguments have. Come up with coding style guidelines for when to use
labeled arguments. When might they improve readability? When might they
be overkill?</p></li>
<li><p>Write a rectangle-drawing procedure that takes three optional
arguments: left-upper corner, right-lower corner, and a width-height
pair. It should draw a correct rectangle whenever two of the three
arguments are given (since any two determine the third), and raise an
exception otherwise. Load the graphics library with
<code>#load "graphics.cma";;</code>. Use <code>invalid_arg</code>,
<code>Graphics.open_graph</code>, and
<code>Graphics.draw_rect</code>.</p></li>
<li><p>Write a function that takes an optional argument of arbitrary
type and a function argument, and passes the optional argument to the
function without inspecting it. This tests your understanding of how
optional arguments work at the type level.</p></li>
</ol>
<h4 id="exercise-3-type-inference-practice">Exercise 3: Type Inference
Practice</h4>
<p><em>From a past exam.</em></p>
<p>These exercises help you internalize how type inference works. Try to
work them out by hand before checking with the OCaml toplevel.</p>
<ol type="1">
<li>Give the (most general) types of the following expressions, either
by guessing or by inferring by hand:
<ol type="1">
<li><code>let double f y = f (f y) in fun g x -&gt; double (g x)</code></li>
<li><code>let rec tails l = match l with [] -&gt; [] | x::xs -&gt; xs::tails xs in fun l -&gt; List.combine l (tails l)</code></li>
</ol></li>
<li>Give example expressions that have the following types (without
using type constraints). There are many possible answers for each:
<ol type="1">
<li><code>(int -&gt; int) -&gt; bool</code></li>
<li><code>'a option -&gt; 'a list</code></li>
</ol></li>
</ol>
<h4 id="exercise-4-types-as-exponents">Exercise 4: Types as
Exponents</h4>
<p>We have seen that algebraic data types can be related to analytic
functions (the subset definable from polynomials via recursion)—by
literally interpreting sum types (variant types) as sums and product
types (tuple and record types) as products. We can extend this
interpretation to function types by interpreting <span
class="math inline">a \rightarrow b</span> as <span
class="math inline">b^a</span> (i.e., <span class="math inline">b</span>
to the power of <span class="math inline">a</span>). Note that the <span
class="math inline">b^a</span> notation is actually used to denote
functions in set theory.</p>
<p>This interpretation makes sense: a function from a set with <span
class="math inline">a</span> elements to a set with <span
class="math inline">b</span> elements is choosing, for each of the <span
class="math inline">a</span> inputs, one of <span
class="math inline">b</span> outputs—giving <span
class="math inline">b^a</span> possible functions.</p>
<ol type="1">
<li><p>Translate <span class="math inline">a^{b + cd}</span> and <span
class="math inline">a^b \cdot (a^c)^d</span> into OCaml types, using any
distinct types for <span class="math inline">a, b, c, d</span>, and
using <code>type ('a,'b) choice = Left of 'a | Right of 'b</code> for
<span class="math inline">+</span>. Write the bijection functions in
both directions. Verify algebraically that <span
class="math inline">a^{b + cd} = a^b \cdot (a^c)^d</span> using the laws
of exponents.</p></li>
<li><p>Come up with a type <code>'t exp</code> that shares with the
exponential function the following property: <span
class="math inline">\frac{\partial \exp(t)}{\partial t} =
\exp(t)</span>, where we translate a derivative of a type as a context
(i.e., the type with a “hole”), as in this chapter. In other words, the
derivative of the type should be isomorphic to the type itself! Explain
why your answer is correct. <em>Hint:</em> in computer science, our
logarithms are mostly base 2.</p></li>
</ol>
<p><em>Further reading:</em> <a
href="http://bababadalgharaghtakamminarronnkonnbro.blogspot.com/2012/10/algebraic-type-systems-combinatorial.html">Algebraic
Type Systems - Combinatorial Species</a></p>
<h4 id="exercise-5-homework-finding-contexts">Exercise 5 (Homework):
Finding Contexts</h4>
<p>Write a function <code>btree_deriv_at</code> that takes a predicate
over integers (i.e., a function <code>f: int -&gt; bool</code>) and a
<code>btree</code>, and builds a <code>btree_deriv</code> whose “hole”
is in the first position for which the predicate returns true. It should
return a <code>btree_deriv option</code>, with <code>None</code> if the
predicate does not hold for any node.</p>
<p>This function lets you “search” a tree and get back a context
pointing to the found element. Think about what order you want to search
in (pre-order, in-order, or post-order) and what “first” means in that
context.</p>
<h2 id="chapter-3-computation">Chapter 3: Computation</h2>
<p><em>Reduction semantics and operational reasoning</em></p>
<p><strong>References:</strong></p>
<ul>
<li>“Using, Understanding and Unraveling the OCaml Language” by Didier
Remy, Chapter 1</li>
<li>“The OCaml system” manual, the tutorial part, Chapter 1</li>
</ul>
<p>In this chapter, we explore how functional programs actually execute.
We will learn how to reason about computation step by step using
<em>reduction semantics</em>, and discover important optimization
techniques like <em>tail call optimization</em> that make functional
programming practical. Along the way, we will encounter our first taste
of <em>continuation passing style</em>, a powerful programming technique
that will reappear throughout this book.</p>
<h3 id="function-composition">3.1 Function Composition</h3>
<p>Function composition is one of the most fundamental operations in
functional programming. It allows us to build complex transformations by
combining simpler functions. The usual way function composition is
defined in mathematics is “backward”—the notation follows the convention
of mathematical function application:</p>
<p><span class="math display">
(f \circ g)(x) = f(g(x))
</span></p>
<p>This means that when we write <span class="math inline">f \circ
g</span>, we first apply <span class="math inline">g</span> and then
apply <span class="math inline">f</span> to the result. The function
written on the left is applied last—hence the term “backward”
composition. Here is how this is expressed in different functional
programming languages:</p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td>Math</td>
<td><span class="math inline">(f \circ g)(x) = f(g(x))</span></td>
</tr>
<tr>
<td>OCaml</td>
<td><code>let (-|) f g x = f (g x)</code></td>
</tr>
<tr>
<td>F#</td>
<td><code>let (&lt;&lt;) f g x = f (g x)</code></td>
</tr>
<tr>
<td>Haskell</td>
<td><code>(.) f g = \x -&gt; f (g x)</code></td>
</tr>
</tbody>
</table>
<p>This backward composition looks like function application but needs
fewer parentheses. Do you recall the functions <code>iso1</code> and
<code>iso2</code> from the previous chapter on type isomorphisms? Using
backward composition, we could write:</p>
<pre><code>let iso2 = step1l -| step2l -| step3l</code></pre>
<p>While backward composition matches traditional mathematical notation,
many programmers find a “forward” composition more intuitive. Forward
composition follows the order in which computation actually
proceeds—data flows from left to right, matching how we typically read
code in most programming languages:</p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td>OCaml</td>
<td><code>let (\|-) f g x = g (f x)</code></td>
</tr>
<tr>
<td>F#</td>
<td><code>let (&gt;&gt;) f g x = g (f x)</code></td>
</tr>
</tbody>
</table>
<p>With forward composition, you can read a pipeline of transformations
in the natural order:</p>
<pre><code>let iso1 = step1r |- step2r |- step3r</code></pre>
<p>Here, the data first passes through <code>step1r</code>, then the
result goes to <code>step2r</code>, and finally to <code>step3r</code>.
This “pipeline” style of programming is particularly popular in
languages like F# and has influenced the design of many modern
programming languages.</p>
<h4 id="partial-application">Partial Application</h4>
<p>Both composition examples above rely on <strong>partial
application</strong>, a technique we introduced in the previous chapter.
Recall that <code>((+) 1)</code> is a function that adds 1 to its
argument—we have provided only one of the two arguments that
<code>(+)</code> requires. Partial application occurs whenever we supply
fewer arguments than a function expects; the result is a new function
that waits for the remaining arguments.</p>
<p>Consider the composition <code>step1r |- step2r |- step3r</code>. How
exactly does partial application come into play here? The composition
operator <code>(|-)</code> is defined as
<code>let (|-) f g x = g (f x)</code>, which means it takes
<em>three</em> arguments: two functions <code>f</code> and
<code>g</code>, and a value <code>x</code>. When we write
<code>step1r |- step2r</code>, we are partially applying
<code>(|-)</code> with just two arguments. The result is a function that
still needs the final argument <code>x</code>.</p>
<p><em>Exercise:</em> Think about the types involved. If
<code>step1r</code> has type <code>'a -&gt; 'b</code> and
<code>step2r</code> has type <code>'b -&gt; 'c</code>, what is the type
of <code>step1r |- step2r</code>?</p>
<h4 id="power-function">Power Function</h4>
<p>Now we define iterated function composition—applying a function to
itself repeatedly. This is written mathematically as:</p>
<p><span class="math display">
f^n(x) := \underbrace{(f \circ \cdots \circ f)}_{n \text{ times}}(x)
</span></p>
<p>In other words, <span class="math inline">f^0</span> is the identity
function, <span class="math inline">f^1 = f</span>, <span
class="math inline">f^2 = f \circ f</span>, and so on. In OCaml, we
first define the backward composition operator, then use it to implement
<code>power</code>:</p>
<div class="sourceCode" id="cb46"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> (-|) f g x = f (g x)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> power f n =</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">if</span> n &lt;= <span class="dv">0</span> <span class="kw">then</span> (<span class="kw">fun</span> x -&gt; x) <span class="kw">else</span> f -| power f (n<span class="dv">-1</span>)</span></code></pre></div>
<p>When <code>n &lt;= 0</code>, we return the identity function
<code>fun x -&gt; x</code>. Otherwise, we compose <code>f</code> with
<code>power f (n-1)</code>, which gives us one more application of
<code>f</code>. Notice how elegantly this definition expresses the
mathematical concept—we are literally composing <code>f</code> with
itself <code>n</code> times.</p>
<p>This <code>power</code> function is surprisingly versatile. For
example, we can use it to define addition in terms of the successor
function:</p>
<pre><code>let add n = power ((+) 1) n</code></pre>
<p>Here <code>add 5 7</code> would compute <span class="math inline">7 +
1 + 1 + 1 + 1 + 1 = 12</span>. We could even define multiplication:</p>
<pre><code>let mult k n = power ((+) k) n 0</code></pre>
<p>This computes <span class="math inline">0 + k + k + \ldots + k</span>
(adding <span class="math inline">k</span> a total of <span
class="math inline">n</span> times), giving us <span
class="math inline">k \times n</span>. While not the most efficient
implementation, these examples show how higher-order functions like
<code>power</code> can express fundamental mathematical operations.</p>
<h4 id="numerical-derivative">Numerical Derivative</h4>
<p>A beautiful application of <code>power</code> is computing
higher-order derivatives. First, let us define a numerical approximation
of the derivative using the standard finite difference formula:</p>
<div class="sourceCode" id="cb49"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> derivative dx f = <span class="kw">fun</span> x -&gt; (f(x +. dx) -. f(x)) /. dx</span></code></pre></div>
<p>This definition computes <span class="math inline">\frac{f(x + dx) -
f(x)}{dx}</span>, which approximates <span
class="math inline">f&#39;(x)</span> when <code>dx</code> is small.
Notice the explicit <code>fun x -&gt; ...</code> syntax, which
emphasizes that <code>derivative dx f</code> is itself a function—we are
transforming a function <code>f</code> into its derivative function.</p>
<p>We can write the same definition more concisely using OCaml’s curried
function syntax:</p>
<div class="sourceCode" id="cb50"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> derivative dx f x = (f(x +. dx) -. f(x)) /. dx</span></code></pre></div>
<p>Both definitions are equivalent, but the first makes the “function
returning a function” structure more explicit, while the second is more
compact.</p>
<p><strong>A note on OCaml’s numeric operators:</strong> OCaml uses
different operators for floating-point arithmetic than for integers. The
type of <code>(+)</code> is <code>int -&gt; int -&gt; int</code>, so we
cannot use <code>+</code> with <code>float</code> values. Instead,
operators followed by a dot work on <code>float</code> numbers:
<code>+.</code>, <code>-.</code>, <code>*.</code>, and <code>/.</code>.
This might seem inconvenient at first, but it catches type errors at
compile time and avoids the implicit conversions that cause subtle bugs
in other languages.</p>
<h4 id="computing-higher-order-derivatives">Computing Higher-Order
Derivatives</h4>
<p>Now comes the payoff. With <code>power</code> and
<code>derivative</code>, we can elegantly compute higher-order
derivatives:</p>
<div class="sourceCode" id="cb51"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> pi = <span class="fl">4.0</span> *. <span class="dt">atan</span> <span class="fl">1.0</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> sin&#39;&#39;&#39; = (power (derivative <span class="fl">1e-5</span>) <span class="dv">3</span>) <span class="dt">sin</span>;;</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>sin&#39;&#39;&#39; pi</span></code></pre></div>
<p>Here <code>sin'''</code> is the third derivative of sine. The
expression <code>(power (derivative 1e-5) 3)</code> creates a function
that applies the derivative operation three times—exactly what we need
for the third derivative.</p>
<p>Mathematically, the third derivative of <span
class="math inline">\sin(x)</span> is <span
class="math inline">-\cos(x)</span>, so <code>sin''' pi</code> should
give us <span class="math inline">-\cos(\pi) = 1</span>. The actual
result will be close to 1, with some numerical error due to the finite
difference approximation (the error compounds with each derivative we
take).</p>
<p>This example demonstrates the power of treating functions as
first-class values. We have built a general-purpose derivative operator
and combined it with our <code>power</code> function to create an <span
class="math inline">n</span>th-derivative calculator—all in just a few
lines of code.</p>
<h3 id="evaluation-rules-reduction-semantics">3.2 Evaluation Rules
(Reduction Semantics)</h3>
<p>So far, we have written OCaml programs and observed their results,
but we have not precisely described <em>how</em> those results are
computed. To understand how OCaml programs execute, we need to formalize
the evaluation process. This section presents <strong>reduction
semantics</strong> (also called <em>operational semantics</em>), which
describes computation as a series of rewriting steps that transform
expressions until we reach a final value.</p>
<p>Understanding reduction semantics is valuable for several reasons. It
helps us predict what our programs will do, reason about their
efficiency, and understand subtle behaviors like infinite loops and
non-termination. The ideas here also form the foundation for
understanding more advanced topics like type systems and program
verification.</p>
<h4 id="expressions">Expressions</h4>
<p>Programs consist of <strong>expressions</strong>. Here is the grammar
of expressions for a simplified version of OCaml (we omit some features
for clarity):</p>
<p><span class="math display">
\begin{array}{lcll}
a &amp; := &amp; x &amp; \text{variables} \\
  &amp; |  &amp; \texttt{fun } x \texttt{ -&gt; } a &amp;
\text{(defined) functions} \\
  &amp; |  &amp; a \; a &amp; \text{applications} \\
  &amp; |  &amp; C^0 &amp; \text{value constructors of arity } 0 \\
  &amp; |  &amp; C^n(a, \ldots, a) &amp; \text{value constructors of
arity } n \\
  &amp; |  &amp; f^n &amp; \text{built-in values (primitives) of arity }
n \\
  &amp; |  &amp; \texttt{let } x = a \texttt{ in } a &amp; \text{name
bindings (local definitions)} \\
  &amp; |  &amp; \texttt{match } a \texttt{ with} &amp; \\
  &amp;    &amp; \quad p \texttt{ -&gt; } a \texttt{ | } \cdots \texttt{
| } p \texttt{ -&gt; } a &amp; \text{pattern matching} \\[1em]
p &amp; := &amp; x &amp; \text{pattern variables} \\
  &amp; |  &amp; (p, \ldots, p) &amp; \text{tuple patterns} \\
  &amp; |  &amp; C^0 &amp; \text{variant patterns of arity } 0 \\
  &amp; |  &amp; C^n(p, \ldots, p) &amp; \text{variant patterns of arity
} n
\end{array}
</span></p>
<p><strong>Arity</strong> means how many arguments something requires.
For constructors, arity tells us how many components the constructor
holds; for functions (primitives), it tells us how many arguments they
need before they can compute a result. For tuple patterns, arity is
simply the length of the tuple.</p>
<h4 id="the-fix-primitive">The <code>fix</code> Primitive</h4>
<p>Our grammar above includes functions defined with <code>fun</code>,
but what about recursive functions defined with <code>let rec</code>? To
keep our semantics simple, we introduce a primitive <code>fix</code>
that captures the essence of recursion:</p>
<p><span class="math display">
\texttt{let rec } f \; x = e_1 \texttt{ in } e_2 \equiv \texttt{let } f
= \texttt{fix (fun } f \; x \texttt{ -&gt; } e_1 \texttt{) in } e_2
</span></p>
<p>The <code>fix</code> primitive is a <em>fixpoint combinator</em>. It
takes a function that expects to receive “itself” as its first argument
and produces a function that, when called, behaves as if it has access
to itself for recursive calls. This might seem mysterious now, but we
will see exactly how it works when we examine its reduction rule
below.</p>
<h4 id="values">Values</h4>
<p>Expressions evaluate (i.e., compute) to <strong>values</strong>.
Values are expressions that cannot be reduced further—they are the
“final answers” of computation:</p>
<p><span class="math display">
\begin{array}{lcll}
v &amp; := &amp; \texttt{fun } x \texttt{ -&gt; } a &amp;
\text{(defined) functions} \\
  &amp; |  &amp; C^n(v_1, \ldots, v_n) &amp; \text{constructed values}
\\
  &amp; |  &amp; f^n \; v_1 \; \cdots \; v_k &amp; k &lt; n \text{
(partially applied primitives)}
\end{array}
</span></p>
<p>Note that functions are values: <code>fun x -&gt; x + 1</code> is
already fully evaluated—there is nothing more to compute until the
function is applied to an argument. Similarly, constructed values like
<code>Some 42</code> or <code>(1, 2, 3)</code> are values when all their
components are values.</p>
<p>Partially applied primitives like <code>(+) 3</code> are also values.
The expression <code>(+) 3</code> has received one argument but needs
another before it can compute a sum. Until that second argument arrives,
there is nothing more to do, so <code>(+) 3</code> is a value.</p>
<h4 id="substitution">Substitution</h4>
<p>The heart of evaluation is <strong>substitution</strong>. To
substitute a value <span class="math inline">v</span> for a variable
<span class="math inline">x</span> in expression <span
class="math inline">a</span>, we write <span class="math inline">a[x :=
v]</span>. This notation means that every occurrence of <span
class="math inline">x</span> in <span class="math inline">a</span> is
replaced by <span class="math inline">v</span>.</p>
<p>For example, if <span class="math inline">a</span> is the expression
<code>x + x * y</code> and we substitute 3 for <code>x</code>, we get
<code>3 + 3 * y</code>. In our notation:
<code>(x + x * y)[x := 3] = 3 + 3 * y</code>.</p>
<p><strong>Implementation note:</strong> Although we describe
substitution as “replacing” variables with values, the actual
implementation in OCaml does not duplicate the value <span
class="math inline">v</span> in memory each time it appears. Instead,
OCaml uses closures and sharing to ensure that values are stored once
and referenced wherever needed. This is both more efficient and
essential for handling recursive data structures.</p>
<h4 id="reduction-rules-redexes">Reduction Rules (Redexes)</h4>
<p>Now we can describe how computation actually proceeds. Reduction
works by finding reducible expressions called <strong>redexes</strong>
(short for “reducible expressions”) and applying reduction rules that
rewrite them into simpler forms. We write <span class="math inline">e_1
\rightsquigarrow e_2</span> to mean “expression <span
class="math inline">e_1</span> reduces to expression <span
class="math inline">e_2</span> in one step.”</p>
<p>Here are the fundamental reduction rules:</p>
<p><strong>Function application (beta reduction):</strong> <span
class="math display">
(\texttt{fun } x \texttt{ -&gt; } a) \; v \rightsquigarrow a[x := v]
</span></p>
<p>This is the most important rule. When we apply a function
<code>fun x -&gt; a</code> to a value <span
class="math inline">v</span>, we substitute <span
class="math inline">v</span> for the parameter <span
class="math inline">x</span> throughout the function body <span
class="math inline">a</span>. This rule is traditionally called “beta
reduction” in the lambda calculus literature.</p>
<p>For example: <code>(fun x -&gt; x + 1) 5</code> <span
class="math inline">\rightsquigarrow</span> <code>5 + 1</code> <span
class="math inline">\rightsquigarrow</span> <code>6</code>.</p>
<p><strong>Let binding:</strong> <span class="math display">
\texttt{let } x = v \texttt{ in } a \rightsquigarrow a[x := v]
</span></p>
<p>A let binding works similarly: once the bound expression has been
evaluated to a value <span class="math inline">v</span>, we substitute
it into the body. Notice that <code>let x = e in a</code> is essentially
equivalent to <code>(fun x -&gt; a) e</code>—both bind <span
class="math inline">x</span> to the result of evaluating <span
class="math inline">e</span> within the expression <span
class="math inline">a</span>.</p>
<p><strong>Primitive application:</strong> <span class="math display">
f^n \; v_1 \; \cdots \; v_n \rightsquigarrow f(v_1, \ldots, v_n)
</span></p>
<p>When a primitive (like <code>+</code> or <code>*</code>) receives all
the arguments it needs (determined by its arity <span
class="math inline">n</span>), it computes the result. Here <span
class="math inline">f(v_1, \ldots, v_n)</span> denotes the actual result
of the primitive operation—for example, <code>(+) 2 3</code> <span
class="math inline">\rightsquigarrow</span> <code>5</code>.</p>
<p><strong>Pattern matching with a variable pattern:</strong> <span
class="math display">
\texttt{match } v \texttt{ with } x \texttt{ -&gt; } a \texttt{ | }
\cdots \rightsquigarrow a[x := v]
</span></p>
<p>A variable pattern always matches, binding the entire value to the
variable.</p>
<p><strong>Pattern matching with a non-matching constructor:</strong>
<span class="math display">
\frac{C_1 \neq C_2}{\texttt{match } C_1^n(v_1, \ldots, v_n) \texttt{
with } C_2^k(p_1, \ldots, p_k) \texttt{ -&gt; } a \texttt{ | } pm
\rightsquigarrow \texttt{match } C_1^n(v_1, \ldots, v_n) \texttt{ with }
pm}
</span></p>
<p>If the constructor in the value (<span
class="math inline">C_1</span>) does not match the constructor in the
pattern (<span class="math inline">C_2</span>), we skip this branch and
try the remaining patterns (<span class="math inline">pm</span>). This
is how OCaml searches through pattern match cases from top to
bottom.</p>
<p><strong>Pattern matching with a matching constructor:</strong> <span
class="math display">
\texttt{match } C_1^n(v_1, \ldots, v_n) \texttt{ with } C_1^n(x_1,
\ldots, x_n) \texttt{ -&gt; } a \texttt{ | } \cdots \rightsquigarrow
a[x_1 := v_1; \ldots; x_n := v_n]
</span></p>
<p>If the constructor matches, we substitute all the values from inside
the constructor for the corresponding pattern variables. For example,
<code>match Some 42 with Some x -&gt; x + 1 | None -&gt; 0</code>
reduces to <code>42 + 1</code> because <code>Some</code> matches
<code>Some</code> and we substitute 42 for <code>x</code>.</p>
<p>If <span class="math inline">n = 0</span>, then <span
class="math inline">C_1^n(v_1, \ldots, v_n)</span> stands for simply
<span class="math inline">C_1^0</span>, a constructor with no arguments
(like <code>None</code> or <code>[]</code>). We omit the more complex
cases of nested pattern matching for brevity.</p>
<h4 id="rule-variables">Rule Variables</h4>
<p>In these rules, we use <em>metavariables</em>—placeholders that can
be replaced with actual expressions. Understanding them is key to
applying the rules:</p>
<ul>
<li><span class="math inline">x</span> matches any variable name (like
<code>foo</code>, <code>n</code>, or <code>result</code>)</li>
<li><span class="math inline">a, a_1, \ldots, a_n</span> match any
expression (not necessarily a value)</li>
<li><span class="math inline">v, v_1, \ldots, v_n</span> match any
<em>value</em> (expressions that are fully evaluated)</li>
</ul>
<p>To apply a rule, find substitutions for these metavariables that make
the left-hand side of the rule match your expression. Then the
right-hand side (with the same substitutions applied) gives you the
reduced expression.</p>
<p>For example, to apply the beta reduction rule to
<code>(fun n -&gt; n * 2) 5</code>: 1. Match <code>fun x -&gt; a</code>
with <code>fun n -&gt; n * 2</code>, giving us <span
class="math inline">x = \texttt{n}</span> and <span
class="math inline">a = \texttt{n * 2}</span> 2. Match <span
class="math inline">v</span> with <code>5</code> 3. The right-hand side
<span class="math inline">a[x := v]</span> becomes
<code>(n * 2)[n := 5]</code> which equals <code>5 * 2</code></p>
<h4 id="evaluation-context-rules">Evaluation Context Rules</h4>
<p>The reduction rules above only apply when the arguments are already
values. But what if we have <code>(fun x -&gt; x + 1) (2 + 3)</code>?
The argument <code>2 + 3</code> is not a value, so we cannot directly
apply beta reduction. We need rules that tell us evaluation can proceed
inside subexpressions.</p>
<p>If <span class="math inline">a_i \rightsquigarrow a_i&#39;</span>
(meaning <span class="math inline">a_i</span> can take a reduction
step), then:</p>
<p><span class="math display">
\begin{array}{lcl}
a_1 \; a_2 &amp; \rightsquigarrow &amp; a_1&#39; \; a_2 \\
a_1 \; a_2 &amp; \rightsquigarrow &amp; a_1 \; a_2&#39; \\
C^n(a_1, \ldots, a_i, \ldots, a_n) &amp; \rightsquigarrow &amp; C^n(a_1,
\ldots, a_i&#39;, \ldots, a_n) \\
\texttt{let } x = a_1 \texttt{ in } a_2 &amp; \rightsquigarrow &amp;
\texttt{let } x = a_1&#39; \texttt{ in } a_2 \\
\texttt{match } a_1 \texttt{ with } pm &amp; \rightsquigarrow &amp;
\texttt{match } a_1&#39; \texttt{ with } pm
\end{array}
</span></p>
<p>These rules describe <em>where</em> reduction can happen: - In a
function application <span class="math inline">a_1 \; a_2</span>, either
the function (<span class="math inline">a_1</span>) or the argument
(<span class="math inline">a_2</span>) can be evaluated. The two rules
allow evaluation in arbitrary order—this gives the implementation
flexibility in how it schedules computation. - In a constructor
application, any argument can be evaluated. - In a let binding
<code>let x = a1 in a2</code>, the bound expression <span
class="math inline">a_1</span> must be evaluated to a value before we
can proceed. Notice there is no rule for evaluating <span
class="math inline">a_2</span> directly—the body is only evaluated after
the substitution happens. - In a match expression, the scrutinee (the
expression being matched) must be evaluated before pattern matching can
proceed.</p>
<h4 id="the-fix-rule">The <code>fix</code> Rule</h4>
<p>Finally, the rule for the <code>fix</code> primitive, which enables
recursion:</p>
<p><span class="math display">
\texttt{fix}^2 \; v_1 \; v_2 \rightsquigarrow v_1 \; (\texttt{fix}^2 \;
v_1) \; v_2
</span></p>
<p>This rule is subtle but powerful. Let us unpack it:</p>
<ol type="1">
<li><code>fix</code> is a binary primitive (arity 2), meaning it needs
two arguments before it computes.</li>
<li>When we apply <code>fix</code> to two values <span
class="math inline">v_1</span> and <span class="math inline">v_2</span>,
it “unrolls” one level of recursion by calling <span
class="math inline">v_1</span> with two arguments: <code>(fix v1)</code>
(which represents “the recursive function itself”) and <span
class="math inline">v_2</span> (the actual argument to the recursive
call).</li>
<li>Because <code>fix</code> has arity 2, the expression
<code>(fix v1)</code> is a <em>partially applied primitive</em>—and
partially applied primitives are values! This is crucial: it means
<code>(fix v1)</code> will not be evaluated further until it is applied
to another argument inside <span class="math inline">v_1</span>.</li>
</ol>
<p>This delayed evaluation is what prevents infinite loops. If
<code>(fix v1)</code> were evaluated immediately, we would get an
infinite chain of expansions. Instead, evaluation only continues when
the recursive function actually makes a recursive call.</p>
<h4 id="practice">Practice</h4>
<p>The best way to understand reduction semantics is to work through
examples by hand. Trace the evaluation of these expressions step by
step:</p>
<p><strong>Exercise 1:</strong> Evaluate
<code>let double x = x + x in double 3</code></p>
<p><strong>Exercise 2:</strong> Evaluate
<code>(fun f -&gt; fun x -&gt; f (f x)) (fun y -&gt; y + 1) 0</code></p>
<p><strong>Exercise 3:</strong> Define the factorial function using
<code>fix</code> and trace the evaluation of
<code>factorial 3</code></p>
<h3 id="symbolic-derivation-example">3.3 Symbolic Derivation
Example</h3>
<p>Let us see the reduction rules in action with a more substantial
example. We will build a small computer algebra system that can
represent mathematical expressions symbolically, evaluate them, and even
compute their derivatives symbolically.</p>
<p>Consider the symbolic expression type from <code>Lec3.ml</code>:</p>
<div class="sourceCode" id="cb52"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> expression =</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>  | Const <span class="kw">of</span> <span class="dt">float</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>  | Var <span class="kw">of</span> <span class="dt">string</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>  | Sum <span class="kw">of</span> expression * expression    <span class="co">(* e1 + e2 *)</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>  | Diff <span class="kw">of</span> expression * expression   <span class="co">(* e1 - e2 *)</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>  | Prod <span class="kw">of</span> expression * expression   <span class="co">(* e1 * e2 *)</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>  | Quot <span class="kw">of</span> expression * expression   <span class="co">(* e1 / e2 *)</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a><span class="kw">exception</span> Unbound_variable <span class="kw">of</span> <span class="dt">string</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> eval env <span class="dt">exp</span> =</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">match</span> <span class="dt">exp</span> <span class="kw">with</span></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>  | Const c -&gt; c</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>  | Var v -&gt;</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>    (<span class="kw">try</span> <span class="dt">List</span>.assoc v env <span class="kw">with</span> <span class="dt">Not_found</span> -&gt; <span class="dt">raise</span> (Unbound_variable v))</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>  | Sum(f, g) -&gt; eval env f +. eval env g</span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>  | Diff(f, g) -&gt; eval env f -. eval env g</span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>  | Prod(f, g) -&gt; eval env f *. eval env g</span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a>  | Quot(f, g) -&gt; eval env f /. eval env g</span></code></pre></div>
<p>The <code>expression</code> type represents mathematical expressions
as a tree structure. Each constructor corresponds to a different kind of
expression: constants, variables, and the four basic arithmetic
operations. The <code>eval</code> function takes an environment
<code>env</code> (a list of variable-value pairs) and recursively
evaluates an expression to a floating-point number.</p>
<p>We can also define <em>symbolic differentiation</em>—computing the
derivative of an expression without evaluating it numerically:</p>
<div class="sourceCode" id="cb53"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> deriv <span class="dt">exp</span> dv =</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">match</span> <span class="dt">exp</span> <span class="kw">with</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>  | Const c -&gt; Const <span class="fl">0.0</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>  | Var v -&gt; <span class="kw">if</span> v = dv <span class="kw">then</span> Const <span class="fl">1.0</span> <span class="kw">else</span> Const <span class="fl">0.0</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>  | Sum(f, g) -&gt; Sum(deriv f dv, deriv g dv)</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>  | Diff(f, g) -&gt; Diff(deriv f dv, deriv g dv)</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>  | Prod(f, g) -&gt; Sum(Prod(f, deriv g dv), Prod(deriv f dv, g))</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>  | Quot(f, g) -&gt; Quot(Diff(Prod(deriv f dv, g), Prod(f, deriv g dv)),</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>                       Prod(g, g))</span></code></pre></div>
<p>The <code>deriv</code> function implements the standard rules of
calculus: - The derivative of a constant is 0. - The derivative of the
variable we are differentiating with respect to is 1; any other variable
is treated as a constant (derivative 0). - The sum and difference rules:
<span class="math inline">(f + g)&#39; = f&#39; + g&#39;</span> and
<span class="math inline">(f - g)&#39; = f&#39; - g&#39;</span>. - The
product rule: <span class="math inline">(f \cdot g)&#39; = f \cdot
g&#39; + f&#39; \cdot g</span>. - The quotient rule: <span
class="math inline">(f / g)&#39; = (f&#39; \cdot g - f \cdot g&#39;) /
g^2</span>.</p>
<p>For convenience, let us define some operators and variables so we can
write expressions more naturally:</p>
<div class="sourceCode" id="cb54"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> x = Var <span class="st">&quot;x&quot;</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> y = Var <span class="st">&quot;y&quot;</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> (+:) f g = Sum (f, g)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> (-:) f g = Diff (f, g)</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> ( *: ) f g = Prod (f, g)</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> (/:) f g = Quot (f, g)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> (!:) i = Const i</span></code></pre></div>
<p>These custom operators (ending in <code>:</code>) let us write
symbolic expressions that look almost like regular mathematical
notation.</p>
<p>Now let us evaluate the expression <span class="math inline">3x + 2y
+ x^2 y</span> at <span class="math inline">x = 1, y = 2</span>:</p>
<div class="sourceCode" id="cb55"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> example = !:<span class="fl">3.0</span> *: x +: !:<span class="fl">2.0</span> *: y +: x *: x *: y</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> env = [<span class="st">&quot;x&quot;</span>, <span class="fl">1.0</span>; <span class="st">&quot;y&quot;</span>, <span class="fl">2.0</span>]</span></code></pre></div>
<p>When we trace the evaluation using OCaml’s <code>#trace</code>
directive, we can see the recursive structure of the computation
unfold:</p>
<pre><code>eval_1_2 &lt;-- 3.00 * x + 2.00 * y + x * x * y
  eval_1_2 &lt;-- x * x * y
    eval_1_2 &lt;-- y
    eval_1_2 --&gt; 2.
    eval_1_2 &lt;-- x * x
      eval_1_2 &lt;-- x
      eval_1_2 --&gt; 1.
      eval_1_2 &lt;-- x
      eval_1_2 --&gt; 1.
    eval_1_2 --&gt; 1.
  eval_1_2 --&gt; 2.
  eval_1_2 &lt;-- 3.00 * x + 2.00 * y
    eval_1_2 &lt;-- 2.00 * y
      eval_1_2 &lt;-- y
      eval_1_2 --&gt; 2.
      eval_1_2 &lt;-- 2.00
      eval_1_2 --&gt; 2.
    eval_1_2 --&gt; 4.
    eval_1_2 &lt;-- 3.00 * x
      eval_1_2 &lt;-- x
      eval_1_2 --&gt; 1.
      eval_1_2 &lt;-- 3.00
      eval_1_2 --&gt; 3.
    eval_1_2 --&gt; 3.
  eval_1_2 --&gt; 7.
eval_1_2 --&gt; 9.
- : float = 9.</code></pre>
<p>The arrows <code>&lt;--</code> and <code>--&gt;</code> show function
calls and returns, respectively. Each level of indentation represents a
nested function call. These indentation levels correspond to
<strong>stack frames</strong>—the runtime structures that store the
state of each function call. Each time <code>eval_1_2</code> is called
recursively, a new stack frame is created to remember where to return
and what computation remains.</p>
<p>The final result is <span class="math inline">3 \cdot 1 + 2 \cdot 2 +
1 \cdot 1 \cdot 2 = 3 + 4 + 2 = 9</span>, as expected.</p>
<p>This trace visualization brings us to an important question: what
happens when we have very deep recursion? This leads us to our next
topic.</p>
<h3 id="tail-calls-and-tail-recursion">3.4 Tail Calls and Tail
Recursion</h3>
<p>The call stack is finite, and each recursive call typically adds a
new frame to it. This means that deeply recursive functions can exhaust
the stack and crash—a notorious problem known as “stack overflow.”
Fortunately, functional language implementations have a trick to avoid
this problem in many cases.</p>
<p>Excuse me for not formally defining what a <em>function call</em> is…
Computers normally evaluate programs by creating <strong>stack
frames</strong> on the call stack for each function call. A stack frame
stores the local variables, the return address (where to continue after
the function returns), and other bookkeeping information. The trace in
the previous section illustrates this: each level of indentation
represents a new stack frame.</p>
<h4 id="what-is-a-tail-call">What is a Tail Call?</h4>
<p>The key insight is that not all function calls require a new stack
frame. A <strong>tail call</strong> is a function call that is performed
as the very last action when computing a function—there is nothing more
to do after the call returns except to return that value. For
example:</p>
<pre><code>let f x = g (x + 1)</code></pre>
<p>The call to <code>g</code> is a tail call. Once <code>g</code>
returns some value, <code>f</code> simply returns that same value—no
further computation is needed.</p>
<p>In contrast:</p>
<pre><code>let f x = 1 + g x</code></pre>
<p>The call to <code>g</code> is <em>not</em> a tail call. After
<code>g</code> returns, we still need to add 1 to the result before
<code>f</code> can return. This means we need to remember to do the
addition, which requires keeping the stack frame around.</p>
<h4 id="tail-call-optimization">Tail Call Optimization</h4>
<p>Functional language compilers (including OCaml’s) recognize tail
calls and optimize them by performing <strong>tail call
optimization</strong> (TCO). Instead of creating a new stack frame, the
compiler generates code that reuses the current frame by performing a
“jump” to the called function. This means tail calls use constant stack
space, no matter how deep the call chain goes.</p>
<p>This optimization is not just a nice-to-have; it is
<em>essential</em> for functional programming. Without TCO, many natural
recursive algorithms would be impractical because they would overflow
the stack on moderately large inputs.</p>
<h4 id="tail-recursive-functions">Tail Recursive Functions</h4>
<p>A function is <strong>tail recursive</strong> if all of its recursive
calls (including calls to mutually recursive functions it depends on)
are tail calls.</p>
<p>Writing tail recursive functions requires a shift in thinking.
Instead of building up the result as recursive calls return, we build it
up as we <em>make</em> the calls. This typically requires an extra
<strong>accumulator</strong> argument that carries the partial result
through the recursion.</p>
<p>The key insight is that with an accumulator, results are computed in
“reverse order”—we do the work while climbing <em>into</em> the
recursion (making calls) rather than while climbing <em>out</em>
(returning from calls).</p>
<h4 id="example-counting">Example: Counting</h4>
<p>Let us see this in action with a simple counting function. Compare
these two versions:</p>
<div class="sourceCode" id="cb59"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> count n =</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">if</span> n &lt;= <span class="dv">0</span> <span class="kw">then</span> <span class="dv">0</span> <span class="kw">else</span> <span class="dv">1</span> + (count (n<span class="dv">-1</span>))</span></code></pre></div>
<p>This version is <em>not</em> tail recursive. Look at the recursive
case: after <code>count (n-1)</code> returns, we still need to add 1 to
the result. Each recursive call must remember to do this addition,
consuming a stack frame.</p>
<p>Now compare with the tail recursive version:</p>
<div class="sourceCode" id="cb60"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> count_tcall acc n =</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">if</span> n &lt;= <span class="dv">0</span> <span class="kw">then</span> acc <span class="kw">else</span> count_tcall (acc+<span class="dv">1</span>) (n<span class="dv">-1</span>)</span></code></pre></div>
<p>Here, the recursive call <code>count_tcall (acc+1) (n-1)</code> is
the very last thing the function does—its result becomes our result
directly. The accumulator <code>acc</code> carries the running count: we
add 1 to it <em>before</em> the recursive call rather than
<em>after</em> it returns. To count to 1000000, we call
<code>count_tcall 0 1000000</code>.</p>
<h4 id="example-building-lists">Example: Building Lists</h4>
<p>The counting example does not really show the practical impact
because the numbers are so small. Let us see a more dramatic example
with lists:</p>
<div class="sourceCode" id="cb61"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> unfold n = <span class="kw">if</span> n &lt;= <span class="dv">0</span> <span class="kw">then</span> [] <span class="kw">else</span> n :: unfold (n<span class="dv">-1</span>)</span></code></pre></div>
<p>This function builds a list counting down from <code>n</code> to 1.
It is not tail recursive because after the recursive call
<code>unfold (n-1)</code> returns, we must cons <code>n</code> onto the
front of the result.</p>
<pre><code># unfold 100000;;
- : int list = [100000; 99999; 99998; 99997; ...]

# unfold 1000000;;
Stack overflow during evaluation (looping recursion?).</code></pre>
<p>With 100,000 elements, it works. But with a million elements, we run
out of stack space and the program crashes! This is a serious problem
for practical programming.</p>
<p>Now consider the tail-recursive version:</p>
<div class="sourceCode" id="cb63"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> unfold_tcall acc n =</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">if</span> n &lt;= <span class="dv">0</span> <span class="kw">then</span> acc <span class="kw">else</span> unfold_tcall (n::acc) (n<span class="dv">-1</span>)</span></code></pre></div>
<p>The accumulator <code>acc</code> collects the list as we go. We cons
each element onto the accumulator <em>before</em> the recursive call.
However, there is a catch: because we are building the list as we
descend into the recursion (rather than as we return), the list comes
out in reverse order:</p>
<pre><code># unfold_tcall [] 100000;;
- : int list = [1; 2; 3; 4; 5; 6; 7; 8; 9; 10; 11; 12; ...]

# unfold_tcall [] 1000000;;
- : int list = [1; 2; 3; 4; 5; 6; 7; 8; 9; 10; 11; 12; ...]</code></pre>
<p>The tail-recursive version handles a million elements effortlessly.
The trade-off is that we get <code>[1; 2; 3; ...]</code> instead of
<code>[1000000; 999999; ...]</code>. If we need the original order, we
could reverse the result at the end (which is an O(n) operation but uses
only constant stack space).</p>
<h4 id="a-challenge-tree-depth">A Challenge: Tree Depth</h4>
<p>Not all recursive functions can be easily converted to tail recursive
form. Consider this problem: can we find the depth of a binary tree
using a tail-recursive function?</p>
<div class="sourceCode" id="cb65"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> btree = Tip | Node <span class="kw">of</span> <span class="dt">int</span> * btree * btree</span></code></pre></div>
<p>Here is the natural recursive approach:</p>
<div class="sourceCode" id="cb66"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> depth tree = <span class="kw">match</span> tree <span class="kw">with</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>  | Tip -&gt; <span class="dv">0</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>  | Node(_, left, right) -&gt; <span class="dv">1</span> + <span class="dt">max</span> (depth left) (depth right)</span></code></pre></div>
<p>This is not tail recursive: after both recursive calls return, we
still need to compute <code>1 + max ...</code>. The fundamental
challenge is that we have <em>two</em> recursive calls that we need to
make. A simple accumulator will not work—we cannot proceed with one
subtree until we know the result of the other.</p>
<p>This seems like an impossible situation. How can we make a function
tail recursive when it inherently needs to explore two branches? The
answer involves a technique called <em>continuation passing style</em>,
which we explore in the next section.</p>
<h4 id="note-on-lazy-languages">Note on Lazy Languages</h4>
<p>The issue of tail recursion is more nuanced for <strong>lazy</strong>
programming languages like Haskell. In a lazy language, expressions are
only evaluated when their values are actually needed. The cons operation
<code>(:)</code> does not immediately evaluate its arguments—it just
builds a “promise” to compute them later.</p>
<p>This means that building a list with <code>n : unfold (n-1)</code>
does not consume stack space in the same way as in OCaml. The
<code>unfold (n-1)</code> is not evaluated immediately; it is just
stored as an unevaluated expression (called a “thunk”). Stack space is
only consumed later, when you actually traverse the list. This gives
lazy languages different performance characteristics and trade-offs.</p>
<h3 id="first-encounter-of-continuation-passing-style">3.5 First
Encounter of Continuation Passing Style</h3>
<p>We can solve the tree depth problem using <strong>Continuation
Passing Style (CPS)</strong>. This is a powerful technique that
transforms programs in a surprising way: instead of returning values,
functions receive an extra argument—a <em>continuation</em>—that tells
them what to do with their result.</p>
<p>The key idea is to postpone doing actual work until the very last
moment by passing around a continuation—a function that represents “what
to do next with this result.”</p>
<div class="sourceCode" id="cb67"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> depth_cps tree k = <span class="kw">match</span> tree <span class="kw">with</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>  | Tip -&gt; k <span class="dv">0</span></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>  | Node(_, left, right) -&gt;</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>    depth_cps left (<span class="kw">fun</span> dleft -&gt;</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>      depth_cps right (<span class="kw">fun</span> dright -&gt;</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>        k (<span class="dv">1</span> + (<span class="dt">max</span> dleft dright))))</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> depth tree = depth_cps tree (<span class="kw">fun</span> d -&gt; d)</span></code></pre></div>
<p>Let us understand how this works step by step:</p>
<ol type="1">
<li><p><strong>The continuation parameter:</strong> The function takes
an extra parameter <code>k</code>, called the
<strong>continuation</strong>. Instead of returning a value directly,
<code>depth_cps</code> will call <code>k</code> with its result. You can
think of <code>k</code> as meaning “and then do this with the
answer.”</p></li>
<li><p><strong>The base case (<code>Tip</code>):</strong> When we reach
a leaf, the depth is 0. Instead of returning 0, we call
<code>k 0</code>—“give 0 to whoever is waiting for our answer.”</p></li>
<li><p><strong>The recursive case (<code>Node</code>):</strong> This is
where CPS shines. We need to compute depths of both subtrees and combine
them. Here is how we do it:</p>
<ul>
<li>First, recursively compute the depth of the left subtree. But
instead of waiting for the result, we pass a continuation:
<code>fun dleft -&gt; ...</code></li>
<li>This continuation says “when you have the left depth (call it
<code>dleft</code>), then…”</li>
<li>…compute the depth of the right subtree, passing another
continuation: <code>fun dright -&gt; ...</code></li>
<li>This inner continuation says “when you have the right depth (call it
<code>dright</code>), then…”</li>
<li>…finally call the original continuation <code>k</code> with the
combined result <code>1 + max dleft dright</code></li>
</ul></li>
<li><p><strong>The wrapper function:</strong> To use
<code>depth_cps</code>, we need to provide an initial continuation. We
pass the identity function <code>fun d -&gt; d</code>, which just
returns whatever it receives. This is the “final consumer” of the
result.</p></li>
</ol>
<p>The magic is that <em>every recursive call is now a tail call</em>!
Look carefully: <code>depth_cps left (...)</code> is the last thing the
function does in that branch—everything else is inside the continuation,
which will be called later.</p>
<p>Where does the “pending work” go? Instead of being stored on the call
stack, it is captured in the continuation closures. These closures are
allocated on the heap. We have traded stack space for heap space.</p>
<p><strong>Important caveat:</strong> This does not completely solve the
stack overflow problem—we are just moving the problem from the stack to
the heap. For very deep trees, the continuation closures can grow very
large, potentially exhausting memory. True solutions for extreme cases
involve techniques like <em>trampolining</em> (returning control to a
loop) or using explicit data structures to represent the pending work.
Nevertheless, CPS is often more space-efficient than direct recursion,
and it is a fundamental technique that appears throughout functional
programming.</p>
<p>We will encounter CPS again when studying monads and advanced control
flow, where it provides the foundation for powerful abstractions.</p>
<h3 id="exercises-2">3.6 Exercises</h3>
<p>These exercises will help you practice the concepts from this
chapter: function composition, reduction semantics, tail recursion, and
continuation passing style.</p>
<p><strong>Exercise 1: Tree Traversals</strong></p>
<p>By “traverse a tree” below we mean: write a function that takes a
tree and returns a list of values in the nodes of the tree. Use the
<code>btree</code> type defined earlier.</p>
<ol type="1">
<li><p>Write a function (of type <code>btree -&gt; int list</code>) that
traverses a binary tree in <strong>prefix order</strong> (also called
<em>preorder</em>)—first the value stored in a node, then values in all
nodes to the left, then values in all nodes to the right.</p></li>
<li><p>Write a traversal in <strong>infix order</strong> (also called
<em>inorder</em>)—first values in all nodes to the left, then the value
stored in the node, then values in all nodes to the right. For a binary
search tree, this would give you the elements in sorted order.</p></li>
<li><p>Write a traversal in <strong>breadth-first order</strong> (also
called <em>level order</em>)—visit all nodes at depth 0, then all nodes
at depth 1, and so on. Hint: you will need an auxiliary data structure
(a queue) to keep track of nodes to visit.</p></li>
</ol>
<p><strong>Exercise 2: CPS Transformation</strong></p>
<p>Turn the function from Exercise 1 (prefix or infix traversal) into
continuation passing style. Compare the structure of your CPS version to
the original. What are the trade-offs?</p>
<p><strong>Exercise 3: Tree Derivatives Revisited</strong></p>
<p>Do the homework from the end of Chapter 2: write
<code>btree_deriv_at</code> that takes a predicate over integers and a
<code>btree</code>, and builds a <code>btree_deriv</code> whose “hole”
is in the first position (using your chosen traversal order) for which
the predicate returns true.</p>
<p><strong>Exercise 4: Expression Simplification</strong></p>
<p>Write a function <code>simplify: expression -&gt; expression</code>
that simplifies symbolic expressions, so that for example the result of
<code>simplify (deriv exp dv)</code> looks more like what a human would
get computing the derivative of <code>exp</code> with respect to
<code>dv</code>.</p>
<p>Some simplifications to consider: - <span class="math inline">0 + x =
x</span> and <span class="math inline">x + 0 = x</span> - <span
class="math inline">0 \cdot x = 0</span> and <span class="math inline">x
\cdot 0 = 0</span> - <span class="math inline">1 \cdot x = x</span> and
<span class="math inline">x \cdot 1 = x</span> - <span
class="math inline">x - 0 = x</span> - <span class="math inline">x / 1 =
x</span></p>
<p>Approach this in two steps: 1. Write a <code>simplify_once</code>
function that performs a single “pass” of simplification over the
expression tree. 2. Wrap it using a general <code>fixpoint</code>
function that performs an operation until a <strong>fixed point</strong>
is reached: given <span class="math inline">f</span> and <span
class="math inline">x</span>, it computes <span
class="math inline">f^n(x)</span> such that <span
class="math inline">f^n(x) = f^{n+1}(x)</span> (i.e., applying <span
class="math inline">f</span> one more time does not change the
result).</p>
<p>Why do we need iteration to a fixed point rather than a single
pass?</p>
<p><strong>Exercise 5: Sorting Algorithms</strong></p>
<p>Write two sorting algorithms working on lists: merge sort and
quicksort.</p>
<ol type="1">
<li><p><strong>Merge sort</strong> splits the list roughly in half,
sorts the parts recursively, and merges the sorted parts into the sorted
result. You will need a helper function to merge two sorted
lists.</p></li>
<li><p><strong>Quicksort</strong> splits the list into elements smaller
than and greater-than-or-equal-to the first element (the “pivot”), sorts
the parts recursively, and concatenates them.</p></li>
</ol>
<p>Which of these algorithms can be implemented in a tail-recursive
manner? What about the helper functions (merge, partition)?</p>
<h2 id="chapter-4-functions">Chapter 4: Functions</h2>
<p><em>Programming in untyped lambda-calculus</em></p>
<p>This chapter explores the theoretical foundations of functional
programming through the untyped lambda-calculus. We embark on a
fascinating journey that reveals a surprising truth: every computation
can be expressed using nothing but functions. No numbers, no booleans,
no data structures—just functions all the way down.</p>
<p>We begin with a review of computation by hand using our reduction
semantics, then introduce the lambda-calculus notation and show how to
encode fundamental data types—booleans, pairs, and natural numbers—using
only functions. The chapter concludes with an examination of recursion
through fixpoint combinators and practical considerations for avoiding
infinite loops in eager evaluation.</p>
<p><strong>References:</strong></p>
<ul>
<li>“Introduction to Lambda Calculus” by Henk Barendregt and Erik
Barendsen</li>
<li>“Lecture Notes on the Lambda Calculus” by Peter Selinger</li>
</ul>
<h3 id="review-computation-by-hand">4.1 Review: Computation by Hand</h3>
<p>Before diving into the lambda-calculus, let us work through a
complete example of evaluation using the reduction rules from Chapter 3.
Computing a larger, recursive program by hand will solidify our
understanding of how computation proceeds step by step and prepare us
for the more abstract setting of lambda-calculus.</p>
<p>Recall that we use <code>fix</code> instead of <code>let rec</code>
to simplify our rules for recursion. Also remember our syntactic
conventions: <code>fun x y -&gt; e</code> stands for
<code>fun x -&gt; (fun y -&gt; e)</code>, and so forth.</p>
<p>Consider the following recursive <code>length</code> function applied
to a two-element list:</p>
<pre><code>let rec fix f x = f (fix f) x

type int_list = Nil | Cons of int * int_list

let length =
  fix (fun f l -&gt;
    match l with
      | Nil -&gt; 0
      | Cons (x, xs) -&gt; 1 + f xs)

length (Cons (1, (Cons (2, Nil))))</code></pre>
<p>Let us trace through this computation step by step. First, we
eliminate the <code>let</code> binding:</p>
<p><span class="math display">\texttt{let } x = v \texttt{ in } a
\Downarrow a[x := v]</span></p>
<p>This gives us:</p>
<pre><code>fix (fun f l -&gt;
    match l with
      | Nil -&gt; 0
      | Cons (x, xs) -&gt; 1 + f xs) (Cons (1, (Cons (2, Nil))))</code></pre>
<p>Next, we apply the <code>fix</code> rule:</p>
<p><span class="math display">\texttt{fix}^2 \; v_1 \; v_2 \Downarrow
v_1 \; (\texttt{fix}^2 \; v_1) \; v_2</span></p>
<p>This unfolds to:</p>
<pre><code>(fun f l -&gt;
    match l with
      | Nil -&gt; 0
      | Cons (x, xs) -&gt; 1 + f xs)
    (fix (fun f l -&gt;
      match l with
        | Nil -&gt; 0
        | Cons (x, xs) -&gt; 1 + f xs))
    (Cons (1, (Cons (2, Nil))))</code></pre>
<p>Function application reduces according to:</p>
<p><span class="math display">(\texttt{fun } x \texttt{ -&gt; } a) \; v
\rightsquigarrow a[x := v]</span></p>
<p>After substituting both <code>f</code> and <code>l</code>, we
get:</p>
<pre><code>(match Cons (1, (Cons (2, Nil))) with
    | Nil -&gt; 0
    | Cons (x, xs) -&gt; 1 + (fix (fun f l -&gt;
      match l with
        | Nil -&gt; 0
        | Cons (x, xs) -&gt; 1 + f xs)) xs)</code></pre>
<p>Pattern matching against a non-matching constructor moves to the next
branch:</p>
<p><span class="math display">
\begin{aligned}
&amp; \texttt{match } C_1^n(v_1, \ldots, v_n) \texttt{ with} \\
&amp; C_2^n(p_1, \ldots, p_k) \texttt{ -&gt; } a \texttt{ | } pm
\Downarrow \texttt{match } C_1^n(v_1, \ldots, v_n) \texttt{ with } pm
\end{aligned}
</span></p>
<p>Pattern matching against a matching constructor performs
substitution:</p>
<p><span class="math display">
\begin{aligned}
&amp; \texttt{match } C_1^n(v_1, \ldots, v_n) \texttt{ with} \\
&amp; C_1^n(x_1, \ldots, x_n) \texttt{ -&gt; } a \texttt{ | } \ldots
\Downarrow a[x_1 := v_1; \ldots; x_n := v_n]
\end{aligned}
</span></p>
<p>After matching and substitution:</p>
<pre><code>1 + (fix (fun f l -&gt;
      match l with
        | Nil -&gt; 0
        | Cons (x, xs) -&gt; 1 + f xs)) (Cons (2, Nil))</code></pre>
<p>Continuing the evaluation, we apply <code>fix</code> again and work
through the pattern match for <code>Cons (2, Nil)</code>, eventually
reaching:</p>
<pre><code>1 + (1 + (fix (fun f l -&gt;
             match l with
               | Nil -&gt; 0
               | Cons (x, xs) -&gt; 1 + f xs)) Nil)</code></pre>
<p>One more unfolding and pattern match against <code>Nil</code>
gives:</p>
<pre><code>1 + (1 + 0)</code></pre>
<p>Finally, applying the built-in addition:</p>
<p><span class="math display">f^n \; v_1 \; \ldots \; v_n \Downarrow
f(v_1, \ldots, v_n)</span></p>
<p>We obtain the result: <code>2</code>.</p>
<h3 id="language-and-rules-of-the-untyped-lambda-calculus">4.2 Language
and Rules of the Untyped Lambda-Calculus</h3>
<p>The lambda-calculus, introduced by Alonzo Church in the 1930s, is a
minimal formal system for expressing computation. It may seem surprising
that such a stripped-down language can be computationally complete, but
that is precisely what we will demonstrate in this chapter. To work with
lambda-calculus, we first simplify our language in several ways:</p>
<ol type="1">
<li><p><strong>Forget about types.</strong> In pure lambda-calculus,
there is no type system constraining which terms can be combined. Any
function can be applied to any argument—including itself!</p></li>
<li><p><strong>Introduce notation.</strong> We write <span
class="math inline">\lambda x.a</span> for <code>fun x -&gt; a</code>,
and <span class="math inline">\lambda xy.a</span> for
<code>fun x y -&gt; a</code>, and so forth. This notation is more
compact and traditional in the literature.</p></li>
<li><p><strong>Reduce to essentials.</strong> We keep only functions
(lambda abstractions) and variables—no constructors, no built-in
primitives. Everything else will be <em>encoded</em> using
functions.</p></li>
</ol>
<p>The core reduction rule of lambda-calculus is called <strong><span
class="math inline">\beta</span>-reduction</strong>:</p>
<p><span class="math display">(\texttt{fun } x \texttt{ -&gt; } a_1) \;
a_2 \rightsquigarrow a_1[x := a_2]</span></p>
<p>Note that this rule is more general than the one we use for OCaml
evaluation. In our OCaml semantics, we require the argument to be a
value: <span class="math inline">(\texttt{fun } x \texttt{ -&gt; } a) \;
v \rightsquigarrow a[x := v]</span>. The general <span
class="math inline">\beta</span>-reduction rule allows substituting any
expression, not just values.</p>
<p>Lambda-calculus also uses <strong><span
class="math inline">\alpha</span>-conversion</strong> (bound variable
renaming), or equivalent techniques, to avoid <strong>variable
capture</strong>—the unintended binding of free variables during
substitution. We will explore the implications of <span
class="math inline">\beta</span>-reduction more deeply in the chapter on
laziness.</p>
<p>Why is <span class="math inline">\beta</span>-reduction more general
than our evaluation rule? Consider the expression <span
class="math inline">(\lambda x. x) \; ((\lambda y. y) \; z)</span>. With
<span class="math inline">\beta</span>-reduction, we could reduce the
outer application first, obtaining <span class="math inline">((\lambda
y. y) \; z)</span>. Our evaluation rule would require first reducing the
argument to a value—but here <code>z</code> is a free variable, not a
value, so we would be stuck!</p>
<h3 id="booleans">4.3 Booleans</h3>
<p>Alonzo Church originally introduced lambda-calculus as a foundation
for logic, seeking to encode logical reasoning in a purely computational
form. There are multiple ways to encode various sorts of data in
lambda-calculus, though not all of them work well in a typed setting—the
straightforward encode/decode functions may not type-check for some
encodings.</p>
<p>The key insight behind the <strong>Church encoding</strong> of
booleans is to represent truth values as <em>selector functions</em>.
Think about what a boolean fundamentally does: it chooses between two
alternatives. So we define:</p>
<ul>
<li><strong>True</strong> selects the first argument:
<code>c_true</code> <span class="math inline">= \lambda xy.x</span></li>
<li><strong>False</strong> selects the second argument:
<code>c_false</code> <span class="math inline">= \lambda
xy.y</span></li>
</ul>
<p>In OCaml syntax:</p>
<div class="sourceCode" id="cb75"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> c_true = <span class="kw">fun</span> x y -&gt; x   <span class="co">(* &quot;True&quot; is projection on the first argument *)</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> c_false = <span class="kw">fun</span> x y -&gt; y  <span class="co">(* And &quot;false&quot; on the second argument *)</span></span></code></pre></div>
<p>Once we have booleans as selectors, logical operations become
elegant. Logical conjunction can be defined as:</p>
<p><span class="math display">\texttt{c\_and} = \lambda xy. x \; y \;
\texttt{c\_false}</span></p>
<p>The logic behind this definition is beautifully simple: we apply
<code>x</code> (which is a selector) to two arguments. If <code>x</code>
is true, it selects its first argument, which is <code>y</code>—so the
result is true only if both <code>x</code> and <code>y</code> are true.
If <code>x</code> is false, it selects its second argument,
<code>c_false</code>, and returns false immediately without even looking
at <code>y</code>.</p>
<div class="sourceCode" id="cb76"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> c_and = <span class="kw">fun</span> x y -&gt; x y c_false  <span class="co">(* If one is false, then return false *)</span></span></code></pre></div>
<p>Let us verify this works. For <code>c_and c_true c_true</code>:</p>
<p><span class="math display">(\lambda xy. x \; y \; \texttt{c\_false})
\; (\lambda xy.x) \; (\lambda xy.x)</span></p>
<p>reduces to:</p>
<p><span class="math display">(\lambda xy.x) \; (\lambda xy.x) \;
\texttt{c\_false}</span></p>
<p>which gives us <span class="math inline">\lambda xy.x</span> =
<code>c_true</code>. You can verify that for any other combination
involving <code>c_false</code>, the result is <code>c_false</code>.</p>
<p>To verify our encodings in OCaml, we need encode and decode
functions. The decoder works by applying our Church boolean to the
actual OCaml values <code>true</code> and <code>false</code>:</p>
<div class="sourceCode" id="cb77"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> encode_bool b = <span class="kw">if</span> b <span class="kw">then</span> c_true <span class="kw">else</span> c_false</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> decode_bool c = c <span class="kw">true</span> <span class="kw">false</span>  <span class="co">(* Test the functions in the toplevel *)</span></span></code></pre></div>
<p><strong>Exercise:</strong> Define <code>c_or</code> and
<code>c_not</code> yourself! Hint: think about what <code>c_or</code>
should return when the first argument is true, and when it is false. For
<code>c_not</code>, consider that a boolean is a function that selects
between two arguments.</p>
<h3 id="if-then-else-and-pairs">4.4 If-then-else and Pairs</h3>
<p>From now on, we will use OCaml syntax for our lambda-calculus
programs. This makes it easier to experiment with our encodings in the
toplevel.</p>
<p>An important observation is that our encoded booleans already
implement conditional selection:</p>
<div class="sourceCode" id="cb78"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> if_then_else = <span class="kw">fun</span> b -&gt; b  <span class="co">(* Booleans select the argument! *)</span></span></code></pre></div>
<p>Wait—<code>if_then_else</code> is just the identity function? Yes!
Since <code>c_true</code> returns its first argument and
<code>c_false</code> returns its second,
<code>if_then_else b then_branch else_branch</code> simply applies
<code>b</code> to the two branches. The boolean <em>is</em> the
conditional. This is one of the elegant surprises of Church
encoding.</p>
<p>Remember to play with these functions in the toplevel to build
intuition. Try expressions like
<code>if_then_else c_true "yes" "no"</code> and see what happens.</p>
<h4 id="pairs">Pairs</h4>
<p>Pairs (ordered tuples of two elements) can be encoded using a similar
idea. The key insight is that a pair needs to “remember” two values and
provide them when asked. We can achieve this by creating a function that
holds onto both values and waits for a selector to choose between
them:</p>
<div class="sourceCode" id="cb79"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> c_pair m n = <span class="kw">fun</span> x -&gt; x m n  <span class="co">(* We couple things *)</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> c_first = <span class="kw">fun</span> p -&gt; p c_true  <span class="co">(* by passing them together *)</span></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> c_second = <span class="kw">fun</span> p -&gt; p c_false  <span class="co">(* Check that it works! *)</span></span></code></pre></div>
<p>A pair is a function that, when given a selector, applies that
selector to both components. To extract the first component, we pass
<code>c_true</code> (which selects the first argument); to extract the
second, we pass <code>c_false</code>. Verify for yourself that
<code>c_first (c_pair a b)</code> reduces to <code>a</code>!</p>
<p>For verification:</p>
<div class="sourceCode" id="cb80"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> encode_pair enc_fst enc_snd (a, b) =</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>  c_pair (enc_fst a) (enc_snd b)</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> decode_pair de_fst de_snd c = c (<span class="kw">fun</span> x y -&gt; de_fst x, de_snd y)</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> decode_bool_pair c = decode_pair decode_bool decode_bool c</span></code></pre></div>
<p>We can define larger tuples in the same manner:</p>
<div class="sourceCode" id="cb81"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> c_triple l m n = <span class="kw">fun</span> x -&gt; x l m n</span></code></pre></div>
<h3 id="pair-encoded-natural-numbers">4.5 Pair-Encoded Natural
Numbers</h3>
<p>Now we come to encoding numbers—a crucial test of whether functions
alone can represent all data. Our first encoding of natural numbers uses
nested pairs. The representation is based on the depth of nested pairs
whose rightmost leaf is the identity function <span
class="math inline">\lambda x.x</span> and whose left elements are
<code>c_false</code>.</p>
<div class="sourceCode" id="cb82"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> pn0 = <span class="kw">fun</span> x -&gt; x           <span class="co">(* Start with the identity function *)</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> pn_succ n = c_pair c_false n  <span class="co">(* Stack another pair *)</span></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> pn_pred = <span class="kw">fun</span> x -&gt; x c_false  <span class="co">(* Extract the nested number *)</span></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> pn_is_zero = <span class="kw">fun</span> x -&gt; x c_true  <span class="co">(* Check if it&#39;s the base case *)</span></span></code></pre></div>
<p>The number 0 is represented as the identity function. The number 1 is
<code>c_pair c_false pn0</code>, the number 2 is
<code>c_pair c_false (c_pair c_false pn0)</code>, and so on. Think of it
as a stack of pairs, where the height of the stack represents the
number.</p>
<p>How do <code>pn_pred</code> and <code>pn_is_zero</code> work? Let us
think through this carefully: - The identity function <code>pn0</code>,
when applied to any argument, returns that argument. - A successor
<code>c_pair c_false n</code> is a function waiting for a selector;
applying it to <code>c_false</code> selects the second component (the
predecessor), while applying it to <code>c_true</code> selects the first
component (<code>c_false</code>).</p>
<p>So <code>pn_is_zero</code> applies the number to <code>c_true</code>:
- For <code>pn0</code>, we get <code>c_true</code> back (since
<code>pn0</code> is the identity)—the number is zero! - For any
successor, we get <code>c_false</code> back (the first component of the
pair)—the number is not zero!</p>
<p>We program in untyped lambda-calculus as an exercise, and we need
encoding/decoding to verify our work. Since these encodings do not
type-check cleanly in OCaml, using <code>Obj.magic</code> to bypass the
type system for encoding/decoding is “fair game”:</p>
<div class="sourceCode" id="cb83"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> encode_pnat n =                <span class="co">(* We use Obj.magic to forget types *)</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">if</span> n &lt;= <span class="dv">0</span> <span class="kw">then</span> <span class="dt">Obj</span>.magic pn0</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">else</span> pn_succ (<span class="dt">Obj</span>.magic (encode_pnat (n<span class="dv">-1</span>)))  <span class="co">(* Disregarding types, *)</span></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> decode_pnat pn =               <span class="co">(* these functions are straightforward! *)</span></span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">if</span> decode_bool (pn_is_zero pn) <span class="kw">then</span> <span class="dv">0</span></span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">else</span> <span class="dv">1</span> + decode_pnat (pn_pred (<span class="dt">Obj</span>.magic pn))</span></code></pre></div>
<h3 id="church-numerals">4.6 Church Numerals</h3>
<p>Do you remember our function <code>power f n</code> from Chapter 3
that composed a function with itself <code>n</code> times? We will use a
similar idea for a different, and historically important, representation
of numbers.</p>
<p><strong>Church numerals</strong> represent a natural number <span
class="math inline">n</span> as a function that applies its first
argument <span class="math inline">n</span> times to its second
argument:</p>
<div class="sourceCode" id="cb84"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cn0 = <span class="kw">fun</span> f x -&gt; x        <span class="co">(* The same as c_false *)</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cn1 = <span class="kw">fun</span> f x -&gt; f x      <span class="co">(* Behaves like identity when f = id *)</span></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cn2 = <span class="kw">fun</span> f x -&gt; f (f x)</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cn3 = <span class="kw">fun</span> f x -&gt; f (f (f x))</span></code></pre></div>
<p>This is the original Alonzo Church encoding, and it is remarkably
elegant. The number <span class="math inline">n</span> is represented as
<span class="math inline">\lambda fx. f^n(x)</span>, where <span
class="math inline">f^n</span> denotes <span
class="math inline">n</span>-fold composition. A number literally
<em>is</em> the act of doing something <span
class="math inline">n</span> times!</p>
<p>Notice that <code>cn0</code> is the same as <code>c_false</code>—zero
applications of <code>f</code> just returns <code>x</code>.</p>
<p>The successor function adds one more application of
<code>f</code>:</p>
<div class="sourceCode" id="cb85"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cn_succ = <span class="kw">fun</span> n f x -&gt; f (n f x)</span></code></pre></div>
<p><strong>Exercise:</strong> Define addition, multiplication, and
comparing to zero for Church numerals. Also try to define the
predecessor function “-1”.</p>
<p>It turns out even Alonzo Church could not define predecessor right
away! The story goes that his student Stephen Kleene figured it out
while at the dentist. Try to make some progress on addition and
multiplication first (they are not too hard), and then attempt
predecessor before looking at the solution below.</p>
<div class="sourceCode" id="cb86"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> (-|) f g x = f (g x)  <span class="co">(* Backward composition operator *)</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> encode_cnat n f =</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">if</span> n &lt;= <span class="dv">0</span> <span class="kw">then</span> (<span class="kw">fun</span> x -&gt; x) <span class="kw">else</span> f -| encode_cnat (n<span class="dv">-1</span>) f</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> decode_cnat n = n ((+) <span class="dv">1</span>) <span class="dv">0</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cn7 f x = encode_cnat <span class="dv">7</span> f x   <span class="co">(* We need to eta-expand these definitions *)</span></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cn13 f x = encode_cnat <span class="dv">13</span> f x  <span class="co">(* for type-system reasons *)</span></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>                                   <span class="co">(* (because OCaml allows side-effects) *)</span></span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cn_add = <span class="kw">fun</span> n m f x -&gt; n f (m f x)  <span class="co">(* Put n of f in front *)</span></span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cn_mult = <span class="kw">fun</span> n m f -&gt; n (m f)       <span class="co">(* Repeat n times *)</span></span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>                                          <span class="co">(* putting m of f in front *)</span></span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cn_prev n =</span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">fun</span> f x -&gt;                  <span class="co">(* This is the &quot;Church numeral signature&quot; *)</span></span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>    n                         <span class="co">(* The only thing we have is an n-step loop *)</span></span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a>      (<span class="kw">fun</span> g v -&gt; v (g f))    <span class="co">(* We need sth that operates on f *)</span></span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a>      (<span class="kw">fun</span> z -&gt; x)            <span class="co">(* We need to ignore the innermost step *)</span></span>
<span id="cb86-17"><a href="#cb86-17" aria-hidden="true" tabindex="-1"></a>      (<span class="kw">fun</span> z -&gt; z)            <span class="co">(* We&#39;ve built a &quot;machine&quot; not results -- start the machine *)</span></span></code></pre></div>
<p>Addition is intuitive: to add <span class="math inline">n</span> and
<span class="math inline">m</span>, we first apply <code>f</code> <span
class="math inline">m</span> times (giving us <code>m f x</code>), then
apply <code>f</code> <span class="math inline">n</span> more times.
Multiplication is even more clever: we apply the operation “apply
<code>f</code> <span class="math inline">m</span> times” <span
class="math inline">n</span> times, which computes <span
class="math inline">m \times n</span> applications of
<code>f</code>.</p>
<p>The predecessor function is ingenious and worth studying carefully.
The challenge is that Church numerals only know how to apply
<code>f</code> more times, not fewer. Kleene’s insight was to build up a
chain of functions that, when “started” with the identity, yields <span
class="math inline">n-1</span> applications of <code>f</code>. The key
is to delay the actual application of <code>f</code> and skip the first
one.</p>
<p><code>cn_is_zero</code> is left as an exercise. Hint: what happens
when you apply zero to a function that always returns
<code>c_false</code> and start with <code>c_true</code>?</p>
<h4 id="tracing-cn_prev-cn3">Tracing <code>cn_prev cn3</code></h4>
<p>The predecessor function is tricky enough that it is worth tracing
through a complete example. Let us trace through
<code>decode_cnat (cn_prev cn3)</code> to see how it computes 2 from
3:</p>
<p><span class="math display">\Downarrow</span></p>
<pre><code>(cn_prev cn3) ((+) 1) 0</code></pre>
<p><span class="math display">\Downarrow</span></p>
<pre><code>(fun f x -&gt;
    cn3
      (fun g v -&gt; v (g f))
      (fun z -&gt; x)
      (fun z -&gt; z)) ((+) 1) 0</code></pre>
<p><span class="math display">\Downarrow</span></p>
<pre><code>((fun f x -&gt; f (f (f x)))
      (fun g v -&gt; v (g ((+) 1)))
      (fun z -&gt; 0)
      (fun z -&gt; z))</code></pre>
<p><span class="math display">\Downarrow</span></p>
<pre><code>((fun g v -&gt; v (g ((+) 1)))
  ((fun g v -&gt; v (g ((+) 1)))
    ((fun g v -&gt; v (g ((+) 1)))
      (fun z -&gt; 0))))
  (fun z -&gt; z))</code></pre>
<p><span class="math display">\Downarrow</span></p>
<pre><code>((fun z -&gt; z)
  (((fun g v -&gt; v (g ((+) 1)))
    ((fun g v -&gt; v (g ((+) 1)))
      (fun z -&gt; 0)))) ((+) 1)))</code></pre>
<p><span class="math display">\Downarrow</span></p>
<pre><code>(fun g v -&gt; v (g ((+) 1)))
  ((fun g v -&gt; v (g ((+) 1)))
    (fun z -&gt; 0)) ((+) 1)</code></pre>
<p><span class="math display">\Downarrow</span></p>
<pre><code>((+) 1) ((fun g v -&gt; v (g ((+) 1)))
          (fun z -&gt; 0) ((+) 1))</code></pre>
<p><span class="math display">\Downarrow</span></p>
<pre><code>((+) 1) (((+) 1) ((fun z -&gt; 0) ((+) 1)))</code></pre>
<p><span class="math display">\Downarrow</span></p>
<pre><code>((+) 1) (((+) 1) (0))</code></pre>
<p><span class="math display">\Downarrow</span></p>
<pre><code>((+) 1) 1</code></pre>
<p><span class="math display">\Downarrow</span></p>
<pre><code>2</code></pre>
<h3 id="recursion-fixpoint-combinators">4.7 Recursion: Fixpoint
Combinators</h3>
<p>We have seen how to encode data in lambda-calculus, but how do we
encode <em>computation</em>, especially recursive computation? In
lambda-calculus, there is no <code>let rec</code> or any built-in notion
of a function referring to itself. Instead, recursion is achieved
through <strong>fixpoint combinators</strong>—remarkable lambda terms
that compute fixed points of functions.</p>
<h4 id="turings-fixpoint-combinator">Turing’s Fixpoint Combinator</h4>
<p><span class="math display">\Theta = (\lambda xy. y \; (x \; x \; y))
\; (\lambda xy. y \; (x \; x \; y))</span></p>
<p>Let us verify it computes fixed points. Define <span
class="math inline">N = \Theta F</span>:</p>
<p><span class="math display">
\begin{aligned}
N &amp;= \Theta F \\
&amp;= (\lambda xy. y \; (x \; x \; y)) \; (\lambda xy. y \; (x \; x \;
y)) \; F \\
&amp;=_{\rightarrow\rightarrow} F \; ((\lambda xy. y \; (x \; x \; y))
\; (\lambda xy. y \; (x \; x \; y)) \; F) \\
&amp;= F \; (\Theta F) = F \; N
\end{aligned}
</span></p>
<p>So <span class="math inline">N = F \; N</span>, meaning <span
class="math inline">N</span> is a fixed point of <span
class="math inline">F</span>.</p>
<h4 id="currys-fixpoint-combinator-y-combinator">Curry’s Fixpoint
Combinator (Y Combinator)</h4>
<p><span class="math display">\mathbf{Y} = \lambda f. (\lambda x. f \;
(x \; x)) \; (\lambda x. f \; (x \; x))</span></p>
<p><span class="math display">
\begin{aligned}
N &amp;= \mathbf{Y} F \\
&amp;= (\lambda f. (\lambda x. f \; (x \; x)) \; (\lambda x. f \; (x \;
x))) \; F \\
&amp;=_{\rightarrow} (\lambda x. F \; (x \; x)) \; (\lambda x. F \; (x
\; x)) \\
&amp;=_{\rightarrow} F \; ((\lambda x. F \; (x \; x)) \; (\lambda x. F
\; (x \; x))) \\
&amp;=_{\leftarrow} F \; ((\lambda f. (\lambda x. f \; (x \; x)) \;
(\lambda x. f \; (x \; x))) \; F) \\
&amp;= F \; (\mathbf{Y} F) = F \; N
\end{aligned}
</span></p>
<h4 id="call-by-value-fixpoint-combinator">Call-by-Value Fixpoint
Combinator</h4>
<p><span class="math display">\texttt{fix} = \lambda f&#39;. (\lambda
fx. f&#39; \; (f \; f) \; x) \; (\lambda fx. f&#39; \; (f \; f) \;
x)</span></p>
<p><span class="math display">
\begin{aligned}
N &amp;= \texttt{fix} \; F \\
&amp;= (\lambda f&#39;. (\lambda fx. f&#39; \; (f \; f) \; x) \;
(\lambda fx. f&#39; \; (f \; f) \; x)) \; F \\
&amp;=_{\rightarrow} (\lambda fx. F \; (f \; f) \; x) \; (\lambda fx. F
\; (f \; f) \; x) \\
&amp;=_{\rightarrow} \lambda x. F \; ((\lambda fx. F \; (f \; f) \; x)
\; (\lambda fx. F \; (f \; f) \; x)) \; x \\
&amp;=_{\leftarrow} \lambda x. F \; ((\lambda f&#39;. (\lambda fx.
f&#39; \; (f \; f) \; x) \; (\lambda fx. f&#39; \; (f \; f) \; x)) \; F)
\; x \\
&amp;= \lambda x. F \; (\texttt{fix} \; F) \; x = \lambda x. F \; N \; x
\\
&amp;=_{\eta} F \; N
\end{aligned}
</span></p>
<p>The lambda-terms we have seen above are <strong>fixpoint
combinators</strong>—the means within lambda-calculus to perform
recursion without any special recursive binding constructs.</p>
<h4 id="the-problem-with-the-first-two-combinators">The Problem with the
First Two Combinators</h4>
<p>What is the problem with Turing’s and Curry’s combinators in a
practical programming language? Consider what happens when we try to
evaluate <span class="math inline">\Theta F</span>:</p>
<p><span class="math display">
\begin{aligned}
\Theta F &amp;\rightsquigarrow\rightsquigarrow F \; ((\lambda xy. y \;
(x \; x \; y)) \; (\lambda xy. y \; (x \; x \; y)) \; F) \\
&amp;\rightsquigarrow\rightsquigarrow F \; (F \; ((\lambda xy. y \; (x
\; x \; y)) \; (\lambda xy. y \; (x \; x \; y)) \; F)) \\
&amp;\rightsquigarrow\rightsquigarrow F \; (F \; (F \; ((\lambda xy. y
\; (x \; x \; y)) \; (\lambda xy. y \; (x \; x \; y)) \; F))) \\
&amp;\rightsquigarrow\rightsquigarrow \ldots
\end{aligned}
</span></p>
<p>Recall the distinction between <em>expressions</em> and
<em>values</em> from Chapter 3 on Computation. The reduction rule for
lambda-calculus is meant to determine which expressions are considered
“equal”—it is highly <em>non-deterministic</em>, while on a computer,
computation needs to go one way or another.</p>
<p>Using the general reduction rule of lambda-calculus, for a recursive
definition, it is always possible to find an infinite reduction
sequence. Why? Because we can always choose to reduce the recursive call
first, which generates another recursive call, and so on forever. This
means a naive lambda-calculus compiler could legitimately generate
infinite loops for all recursive definitions—which would not be very
useful!</p>
<p>Therefore, we need more specific rules. Most languages use
<strong>call-by-value</strong> (also called <strong>eager</strong>
evaluation):</p>
<p><span class="math display">(\texttt{fun } x \texttt{ -&gt; } a) \; v
\rightsquigarrow a[x := v]</span></p>
<p>The program <em>eagerly</em> computes arguments before starting to
compute the function body. This is exactly the rule we introduced in the
Computation chapter.</p>
<h4 id="call-by-value-fixpoint-combinator-in-action">Call-by-Value
Fixpoint Combinator in Action</h4>
<p>What happens with the call-by-value fixpoint combinator?</p>
<p><span class="math display">
\begin{aligned}
\texttt{fix} \; F &amp;\rightsquigarrow (\lambda fx. F \; (f \; f) \; x)
\; (\lambda fx. F \; (f \; f) \; x) \\
&amp;\rightsquigarrow \lambda x. F \; ((\lambda fx. F \; (f \; f) \; x)
\; (\lambda fx. F \; (f \; f) \; x)) \; x
\end{aligned}
</span></p>
<p>The computation stops because we use the rule <span
class="math inline">(\texttt{fun } x \texttt{ -&gt; } a) \; v
\rightsquigarrow a[x := v]</span> rather than <span
class="math inline">(\texttt{fun } x \texttt{ -&gt; } a_1) \; a_2
\rightsquigarrow a_1[x := a_2]</span>. The expression inside the lambda
is not evaluated until the function is applied.</p>
<p>Let us compute the function on some input:</p>
<p><span class="math display">
\begin{aligned}
\texttt{fix} \; F \; v &amp;\rightsquigarrow (\lambda fx. F \; (f \; f)
\; x) \; (\lambda fx. F \; (f \; f) \; x) \; v \\
&amp;\rightsquigarrow (\lambda x. F \; ((\lambda fx. F \; (f \; f) \; x)
\; (\lambda fx. F \; (f \; f) \; x)) \; x) \; v \\
&amp;\rightsquigarrow F \; ((\lambda fx. F \; (f \; f) \; x) \; (\lambda
fx. F \; (f \; f) \; x)) \; v \\
&amp;\rightsquigarrow F \; (\lambda x. F \; ((\lambda fx. F \; (f \; f)
\; x) \; (\lambda fx. F \; (f \; f) \; x)) \; x) \; v \\
&amp;\rightsquigarrow \text{depends on } F
\end{aligned}
</span></p>
<h4 id="why-fixpoint">Why “Fixpoint”?</h4>
<p>If you examine our derivations, you will see they establish <span
class="math inline">x = f(x)</span>. Such values <span
class="math inline">x</span> are called <strong>fixpoints</strong> of
<span class="math inline">f</span>. An arithmetic function can have
several fixpoints—for example, <span class="math inline">f(x) =
x^2</span> has fixpoints 0 and 1 (since <span class="math inline">0^2 =
0</span> and <span class="math inline">1^2 = 1</span>)—or no fixpoints,
such as <span class="math inline">f(x) = x + 1</span> (since <span
class="math inline">x + 1 \neq x</span> for all <span
class="math inline">x</span>).</p>
<p>When you define a function (or another object) by recursion, it has a
similar meaning: the name appears on both sides of the equality. For
example, <code>fact n = if n = 0 then 1 else n * fact (n-1)</code> has
<code>fact</code> on both sides. In lambda-calculus, functions like
<span class="math inline">\Theta</span> and <span
class="math inline">\mathbf{Y}</span> take <em>any</em> function as an
argument and return its fixpoint.</p>
<p>We turn a specification of a recursive object into a definition by
solving it with respect to the recurring name: deriving <span
class="math inline">x = f(x)</span> where <span
class="math inline">x</span> is the recurring name. We then have <span
class="math inline">x = \texttt{fix}(f)</span>.</p>
<h4 id="deriving-factorial">Deriving Factorial</h4>
<p>Let us walk through this process step by step for the factorial
function. This will show how to transform a recursive specification into
a proper definition using <code>fix</code>. We omit the prefix
<code>cn_</code> (could be <code>pn_</code> if using pair-encoded
numbers) and shorten <code>if_then_else</code> to
<code>if_t_e</code>:</p>
<p><span class="math display">
\begin{aligned}
\texttt{fact} \; n &amp;= \texttt{if\_t\_e} \; (\texttt{is\_zero} \; n)
\; \texttt{cn1} \; (\texttt{mult} \; n \; (\texttt{fact} \;
(\texttt{pred} \; n))) \\
\texttt{fact} &amp;= \lambda n. \texttt{if\_t\_e} \; (\texttt{is\_zero}
\; n) \; \texttt{cn1} \; (\texttt{mult} \; n \; (\texttt{fact} \;
(\texttt{pred} \; n))) \\
\texttt{fact} &amp;= (\lambda fn. \texttt{if\_t\_e} \;
(\texttt{is\_zero} \; n) \; \texttt{cn1} \; (\texttt{mult} \; n \; (f \;
(\texttt{pred} \; n)))) \; \texttt{fact} \\
\texttt{fact} &amp;= \texttt{fix} \; (\lambda fn. \texttt{if\_t\_e} \;
(\texttt{is\_zero} \; n) \; \texttt{cn1} \; (\texttt{mult} \; n \; (f \;
(\texttt{pred} \; n))))
\end{aligned}
</span></p>
<p>The last line is a valid definition: we simply give a name to a
<em>ground</em> (also called <em>closed</em>) expression—one with no
free variables. We have already seen how <code>fix</code> works in the
reduction semantics.</p>
<p><strong>Exercise:</strong> Compute <code>fact cn2</code> by hand,
tracing through the reduction steps.</p>
<p><strong>Exercise:</strong> What does
<code>fix (fun x -&gt; cn_succ x)</code> mean? What happens if you try
to evaluate it? Think about whether there is any value <code>x</code>
such that <code>x = cn_succ x</code>.</p>
<h3 id="encoding-lists-and-trees">4.8 Encoding Lists and Trees</h3>
<p>Now that we have numbers and recursion, we can encode more complex
data structures. The pattern we have seen with booleans and pairs
extends naturally to algebraic data types like lists and trees.</p>
<p>A <strong>list</strong> is either empty (often called
<code>Empty</code> or <code>Nil</code>) or consists of an element
followed by another list (the “tail”), called <code>Cons</code>. Since
lists have two variants, we encode them with two-argument selector
functions:</p>
<ul>
<li><code>nil</code> <span class="math inline">= \lambda xy.y</span>
(select the second argument, like <code>c_false</code>)</li>
<li><code>cons</code> <span class="math inline">H \; T = \lambda xy. x
\; H \; T</span> (apply the first argument to head and tail)</li>
</ul>
<p>With these definitions, we can write a function to add all numbers
stored inside a list:</p>
<p><span class="math display">\texttt{addlist} \; l = l \; (\lambda ht.
\texttt{cn\_add} \; h \; (\texttt{addlist} \; t)) \;
\texttt{cn0}</span></p>
<p>To make a proper definition, we apply <span
class="math inline">\texttt{fix}</span> to the solution of the above
equation:</p>
<p><span class="math display">\texttt{addlist} = \texttt{fix} \;
(\lambda fl. l \; (\lambda ht. \texttt{cn\_add} \; h \; (f \; t)) \;
\texttt{cn0})</span></p>
<p>For <strong>trees</strong>, let us use a different form of binary
trees than we have seen before: instead of keeping elements in inner
nodes, we will keep elements in leaves. This is sometimes called an
“external” tree structure.</p>
<p>Again, we have two variants, so we use two-argument selector
functions:</p>
<ul>
<li><code>leaf</code> <span class="math inline">n = \lambda xy. x \;
n</span> (apply first argument to the element)</li>
<li><code>node</code> <span class="math inline">L \; R = \lambda xy. y
\; L \; R</span> (apply second argument to left and right subtrees)</li>
</ul>
<p>To add numbers stored inside a tree:</p>
<p><span class="math display">\texttt{addtree} \; t = t \; (\lambda n.n)
\; (\lambda lr. \texttt{cn\_add} \; (\texttt{addtree} \; l) \;
(\texttt{addtree} \; r))</span></p>
<p>And in solved form:</p>
<p><span class="math display">\texttt{addtree} = \texttt{fix} \;
(\lambda ft. t \; (\lambda n.n) \; (\lambda lr. \texttt{cn\_add} \; (f
\; l) \; (f \; r)))</span></p>
<div class="sourceCode" id="cb98"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> fix f x = f (fix f) x</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> nil = <span class="kw">fun</span> x y -&gt; y</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cons h t = <span class="kw">fun</span> x y -&gt; x h t</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> addlist l =</span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>  fix (<span class="kw">fun</span> f l -&gt; l (<span class="kw">fun</span> h t -&gt; cn_add h (f t)) cn0) l</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>;;</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>decode_cnat</span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>  (addlist (cons cn1 (cons cn2 (cons cn7 nil))));;</span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> leaf n = <span class="kw">fun</span> x y -&gt; x n</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> node l r = <span class="kw">fun</span> x y -&gt; y l r</span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> addtree t =</span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a>  fix (<span class="kw">fun</span> f t -&gt;</span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>    t (<span class="kw">fun</span> n -&gt; n) (<span class="kw">fun</span> l r -&gt; cn_add (f l) (f r))</span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a>  ) t</span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a>;;</span>
<span id="cb98-16"><a href="#cb98-16" aria-hidden="true" tabindex="-1"></a>decode_cnat</span>
<span id="cb98-17"><a href="#cb98-17" aria-hidden="true" tabindex="-1"></a>  (addtree (node (node (leaf cn3) (leaf cn7))</span>
<span id="cb98-18"><a href="#cb98-18" aria-hidden="true" tabindex="-1"></a>              (leaf cn1)));;</span></code></pre></div>
<h4 id="the-general-pattern">The General Pattern</h4>
<p>If you look back at our encodings, you will observe a consistent
pattern: when we encode a variant type with <span
class="math inline">n</span> variants, for each variant we define a
function that takes <span class="math inline">n</span> arguments.</p>
<p>If the <span class="math inline">k</span>th variant <span
class="math inline">C_k</span> has <span class="math inline">m_k</span>
parameters, then the function <span class="math inline">c_k</span> that
encodes it has the form:</p>
<p><span class="math display">C_k(v_1, \ldots, v_{m_k}) \sim c_k \; v_1
\; \ldots \; v_{m_k} = \lambda x_1 \ldots x_n. x_k \; v_1 \; \ldots \;
v_{m_k}</span></p>
<p>The encoded variants serve as shallow pattern matching with
guaranteed exhaustiveness: the <span class="math inline">k</span>th
argument corresponds to the <span class="math inline">k</span>th branch
of pattern matching. This is exactly how <code>match</code> works in
OCaml, but encoded purely with functions!</p>
<h3 id="looping-recursion">4.9 Looping Recursion</h3>
<p>We have been coding in untyped lambda-calculus and verifying our code
works in OCaml. But there is a subtle trap we must be aware of when
combining lambda-calculus encodings with OCaml’s eager evaluation.</p>
<p>Let us return to pair-encoded numbers and define addition:</p>
<pre><code>let pn_add m n =
  fix (fun f m n -&gt;
    if_then_else (pn_is_zero m)
      n (pn_succ (f (pn_pred m) n))
  ) m n;;
decode_pnat (pn_add pn3 pn3);;</code></pre>
<p>Oops… OCaml says:
<code>Stack overflow during evaluation (looping recursion?).</code></p>
<p>What went wrong? Nothing as far as lambda-calculus is concerned—the
definition is mathematically correct. But OCaml (and F#) always compute
arguments before calling a function. This is the <em>eager</em>
evaluation strategy we discussed earlier. By definition of
<code>fix</code>, <code>f</code> corresponds to recursively calling
<code>pn_add</code>. Therefore, <code>(pn_succ (f (pn_pred m) n))</code>
will be evaluated regardless of what <code>(pn_is_zero m)</code>
returns!</p>
<p>In other words, even when <code>m</code> is zero and we should return
<code>n</code>, OCaml first tries to compute the “else” branch, which
makes a recursive call, which computes its “else” branch, and so on
forever.</p>
<p>Why do <code>addlist</code> and <code>addtree</code> work? Look at
them carefully: their recursive calls are “guarded” by corresponding
<code>fun</code>. The expression
<code>(fun h t -&gt; cn_add h (f t))</code> does not immediately call
<code>f</code>—it creates a function that will call <code>f</code> only
when that function is applied to arguments. What is inside of
<code>fun</code> is not computed immediately—only when the function is
applied to argument(s).</p>
<p>To avoid looping recursion, you need to guard all recursive calls.
Besides putting them inside <code>fun</code>, in OCaml or F# you can
also put them in branches of a <code>match</code> clause, as long as one
of the branches does not have unguarded recursive calls.</p>
<p>The trick for functions like <code>if_then_else</code> is to guard
their arguments with <code>fun x -&gt;</code>, where <code>x</code> is
not used, and apply the <em>result</em> of <code>if_then_else</code> to
some dummy value. This delays the evaluation of both branches until the
boolean has selected one of them:</p>
<pre><code>let id x = x
let rec fix f x = f (fix f) x
let pn1 x = pn_succ pn0 x
let pn2 x = pn_succ pn1 x
let pn3 x = pn_succ pn2 x
let pn7 x = encode_pnat 7 x
let pn_add m n =
  fix (fun f m n -&gt;
    (if_then_else (pn_is_zero m)
       (fun x -&gt; n) (fun x -&gt; pn_succ (f (pn_pred m) n)))
      id
  ) m n;;
decode_pnat (pn_add pn3 pn3);;
decode_pnat (pn_add pn3 pn7);;</code></pre>
<p>Now the recursive call is wrapped in <code>fun x -&gt;</code>, so it
is not evaluated until <code>if_then_else</code> selects the second
branch and applies it to <code>id</code>. When <code>m</code> is zero,
the first branch <code>(fun x -&gt; n)</code> is selected and applied to
<code>id</code>, giving us <code>n</code> without ever touching the
recursive call.</p>
<p>In OCaml or F# we would typically guard by <code>fun () -&gt;</code>
and then apply to <code>()</code>, but we do not have datatypes like
<code>unit</code> in pure lambda-calculus, so we use <code>id</code> as
our dummy value.</p>
<h3 id="exercises-3">4.10 Exercises</h3>
<p>The following exercises will help solidify your understanding of
lambda-calculus encodings. For each exercise involving lambda-calculus,
test your implementation by encoding some inputs, applying your
function, and decoding the result.</p>
<p><strong>Exercise 1:</strong> Define (implement) and test on a couple
of examples functions corresponding to or computing:</p>
<ol type="1">
<li><code>c_or</code> and <code>c_not</code>;</li>
<li>exponentiation for Church numerals;</li>
<li>is-zero predicate for Church numerals;</li>
<li>even-number predicate for Church numerals;</li>
<li>multiplication for pair-encoded natural numbers;</li>
<li>factorial <span class="math inline">n!</span> for pair-encoded
natural numbers;</li>
<li>the length of a list (in Church numerals);</li>
<li><code>cn_max</code> – maximum of two Church numerals;</li>
<li>the depth of a tree (in Church numerals).</li>
</ol>
<p><strong>Exercise 2:</strong> Construct lambda-terms <span
class="math inline">m_0, m_1, \ldots</span> such that for all <span
class="math inline">n</span> one has:</p>
<p><span class="math display">
\begin{aligned}
m_0 &amp;= x \\
m_{n+1} &amp;= m_{n+2} \; m_n
\end{aligned}
</span></p>
<p>(where equality is after performing <span
class="math inline">\beta</span>-reductions).</p>
<p><strong>Exercise 3:</strong> Representing side-effects as an
explicitly “passed around” state value, write (higher-order) functions
that represent the imperative constructs:</p>
<ol type="1">
<li><code>for</code>…<code>to</code>…</li>
<li><code>for</code>…<code>downto</code>…</li>
<li><code>while</code>…<code>do</code>…</li>
<li><code>do</code>…<code>while</code>…</li>
<li><code>repeat</code>…<code>until</code>…</li>
</ol>
<p>Rather than writing a lambda-term using the encodings that we have
learnt, just implement the functions in OCaml / F#, using built-in
<code>int</code> and <code>bool</code> types. You can use
<code>let rec</code> instead of <code>fix</code>.</p>
<ul>
<li>For example, in exercise (a), write a function
<code>let rec for_to f beg_i end_i s = ...</code> where <code>f</code>
takes arguments <code>i</code> ranging from <code>beg_i</code> to
<code>end_i</code>, state <code>s</code> at given step, and returns
state <code>s</code> at next step; the <code>for_to</code> function
returns the state after the last step.</li>
<li>And in exercise (c), write a function
<code>let rec while_do p f s = ...</code> where both <code>p</code> and
<code>f</code> take state <code>s</code> at given step, and if
<code>p s</code> returns true, then <code>f s</code> is computed to
obtain state at next step; the <code>while_do</code> function returns
the state after the last step.</li>
</ul>
<p>Do not use the imperative features of OCaml and F#! This exercise
demonstrates that imperative control flow can be encoded purely
functionally by threading state through function calls.</p>
<p>Although we will not cover imperative features in this course, it is
instructive to see the implementation using them, to better understand
what is actually required of a solution to Exercise 3:</p>
<div class="sourceCode" id="cb101"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co">(* (a) *)</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> for_to f beg_i end_i s =</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> s = <span class="dt">ref</span> s <span class="kw">in</span></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">for</span> i = beg_i <span class="kw">to</span> end_i <span class="kw">do</span></span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>    s := f i !s</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">done</span>;</span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>  !s</span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a><span class="co">(* (b) *)</span></span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> for_downto f beg_i end_i s =</span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> s = <span class="dt">ref</span> s <span class="kw">in</span></span>
<span id="cb101-12"><a href="#cb101-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">for</span> i = beg_i <span class="kw">downto</span> end_i <span class="kw">do</span></span>
<span id="cb101-13"><a href="#cb101-13" aria-hidden="true" tabindex="-1"></a>    s := f i !s</span>
<span id="cb101-14"><a href="#cb101-14" aria-hidden="true" tabindex="-1"></a>  <span class="kw">done</span>;</span>
<span id="cb101-15"><a href="#cb101-15" aria-hidden="true" tabindex="-1"></a>  !s</span>
<span id="cb101-16"><a href="#cb101-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-17"><a href="#cb101-17" aria-hidden="true" tabindex="-1"></a><span class="co">(* (c) *)</span></span>
<span id="cb101-18"><a href="#cb101-18" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> while_do p f s =</span>
<span id="cb101-19"><a href="#cb101-19" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> s = <span class="dt">ref</span> s <span class="kw">in</span></span>
<span id="cb101-20"><a href="#cb101-20" aria-hidden="true" tabindex="-1"></a>  <span class="kw">while</span> p !s <span class="kw">do</span></span>
<span id="cb101-21"><a href="#cb101-21" aria-hidden="true" tabindex="-1"></a>    s := f !s</span>
<span id="cb101-22"><a href="#cb101-22" aria-hidden="true" tabindex="-1"></a>  <span class="kw">done</span>;</span>
<span id="cb101-23"><a href="#cb101-23" aria-hidden="true" tabindex="-1"></a>  !s</span>
<span id="cb101-24"><a href="#cb101-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-25"><a href="#cb101-25" aria-hidden="true" tabindex="-1"></a><span class="co">(* (d) *)</span></span>
<span id="cb101-26"><a href="#cb101-26" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> do_while p f s =</span>
<span id="cb101-27"><a href="#cb101-27" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> s = <span class="dt">ref</span> (f s) <span class="kw">in</span></span>
<span id="cb101-28"><a href="#cb101-28" aria-hidden="true" tabindex="-1"></a>  <span class="kw">while</span> p !s <span class="kw">do</span></span>
<span id="cb101-29"><a href="#cb101-29" aria-hidden="true" tabindex="-1"></a>    s := f !s</span>
<span id="cb101-30"><a href="#cb101-30" aria-hidden="true" tabindex="-1"></a>  <span class="kw">done</span>;</span>
<span id="cb101-31"><a href="#cb101-31" aria-hidden="true" tabindex="-1"></a>  !s</span>
<span id="cb101-32"><a href="#cb101-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-33"><a href="#cb101-33" aria-hidden="true" tabindex="-1"></a><span class="co">(* (e) *)</span></span>
<span id="cb101-34"><a href="#cb101-34" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> repeat_until p f s =</span>
<span id="cb101-35"><a href="#cb101-35" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> s = <span class="dt">ref</span> (f s) <span class="kw">in</span></span>
<span id="cb101-36"><a href="#cb101-36" aria-hidden="true" tabindex="-1"></a>  <span class="kw">while</span> <span class="dt">not</span> (p !s) <span class="kw">do</span></span>
<span id="cb101-37"><a href="#cb101-37" aria-hidden="true" tabindex="-1"></a>    s := f !s</span>
<span id="cb101-38"><a href="#cb101-38" aria-hidden="true" tabindex="-1"></a>  <span class="kw">done</span>;</span>
<span id="cb101-39"><a href="#cb101-39" aria-hidden="true" tabindex="-1"></a>  !s</span></code></pre></div>
<h2 id="chapter-5-polymorphism-and-abstract-data-types">Chapter 5:
Polymorphism and Abstract Data Types</h2>
<p>This chapter explores how OCaml’s type system supports generic
programming through parametric polymorphism, and how abstract data types
provide clean interfaces for data structures. We begin by examining how
type inference actually works – the process by which OCaml determines
types for your code. Then we explore parametric types and show how they
enable polymorphic functions to work with data of any shape. The second
half of the chapter introduces algebraic specifications, the
mathematical foundation for describing data structures, and applies
these concepts to build progressively more sophisticated implementations
of the map (dictionary) data structure, culminating in the elegant
red-black tree.</p>
<p><em>If you see any error in this chapter, please let us
know!</em></p>
<h3 id="type-inference">5.1 Type Inference</h3>
<p>We have seen the rules that govern the assignment of types to
expressions, but how does OCaml actually guess what types to use? And
how does it know when no correct types exist? The answer lies in a
beautiful algorithm: OCaml solves equations. When you write code, the
type checker generates a set of equations that must hold for the program
to be well-typed, and then it solves those equations to discover the
types.</p>
<h4 id="variables-unknowns-and-parameters">Variables: Unknowns and
Parameters</h4>
<p>Variables in type inference play two distinct roles, and
understanding this distinction is crucial for mastering OCaml’s type
system. A type variable can be either an <em>unknown</em> (standing for
a specific but not-yet-determined type) or a <em>parameter</em>
(standing for any type whatsoever).</p>
<p>Consider this example:</p>
<div class="sourceCode" id="cb102"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a># <span class="kw">let</span> f = <span class="dt">List</span>.hd;;</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> f : &#39;a <span class="dt">list</span> -&gt; &#39;a = &lt;<span class="kw">fun</span>&gt;</span></code></pre></div>
<p>Here <code>'a</code> is a <em>parameter</em>: it can become any type.
When you use <code>f</code> with a list of integers, <code>'a</code>
becomes <code>int</code>; when you use it with a list of strings,
<code>'a</code> becomes <code>string</code>. Mathematically we write:
<span class="math inline">f : \forall \alpha . \alpha \ \text{list}
\rightarrow \alpha</span> – the quantified type is called a <em>type
scheme</em>. The <span class="math inline">\forall</span> symbol
indicates that this type works “for all” choices of <span
class="math inline">\alpha</span>.</p>
<p>In contrast, consider this example:</p>
<div class="sourceCode" id="cb103"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a># <span class="kw">let</span> x = <span class="dt">ref</span> [];;</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> x : &#39;_weak1 <span class="dt">list</span> <span class="dt">ref</span> = {contents = []}</span></code></pre></div>
<p>Here <code>'_a</code> (displayed as <code>'_weak1</code> in recent
OCaml versions) is an <em>unknown</em>. Unlike a parameter, it stands
for a <em>particular</em> type – perhaps <code>float</code> or
<code>int -&gt; int</code> – but OCaml simply doesn’t know which type
yet. The underscore prefix signals this distinction. OCaml reports
unknowns like <code>'_a</code> in inferred types for reasons related to
mutable state (the “value restriction”), which are not relevant to
purely functional programming.</p>
<p>When unknowns appear in inferred types against our expectations,
<em><span class="math inline">\eta</span>-expansion</em> may help. This
technique involves writing <code>let f x = expr x</code> instead of
<code>let f = expr</code>, essentially adding an extra parameter that
gets immediately applied. For example:</p>
<div class="sourceCode" id="cb104"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a># <span class="kw">let</span> f = <span class="dt">List</span>.append [];;</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> f : &#39;_weak2 <span class="dt">list</span> -&gt; &#39;_weak2 <span class="dt">list</span> = &lt;<span class="kw">fun</span>&gt;</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a># <span class="kw">let</span> f l = <span class="dt">List</span>.append [] l;;</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> f : &#39;a <span class="dt">list</span> -&gt; &#39;a <span class="dt">list</span> = &lt;<span class="kw">fun</span>&gt;</span></code></pre></div>
<p>In the second definition, the eta-expanded form
<code>let f l = List.append [] l</code> allows full generalization,
giving us a truly polymorphic function that can work with lists of any
type.</p>
<h4 id="type-environments">Type Environments</h4>
<p>Before diving into the equation-solving process, we need to
understand how the type checker keeps track of what names are available.
A <em>type environment</em> specifies what names (corresponding to
parameters and definitions) are available for an expression because they
were introduced above it, and it specifies their types. Think of it as a
dictionary that maps variable names to their types at any given point in
your program.</p>
<h4 id="solving-type-equations">Solving Type Equations</h4>
<p>Type inference works by solving equations over unknowns. The central
question the algorithm asks is: “What has to hold so that <span
class="math inline">e : \tau</span> in type environment <span
class="math inline">\Gamma</span>?” The answer takes the form of
equations that constrain the possible types.</p>
<p>Let us walk through how the algorithm handles different expression
forms:</p>
<ul>
<li><p>If, for example, <span class="math inline">f : \forall \alpha .
\alpha \ \text{list} \rightarrow \alpha \in \Gamma</span>, then for
<span class="math inline">f : \tau</span> we introduce <span
class="math inline">\gamma \ \text{list} \rightarrow \gamma =
\tau</span> for some fresh unknown <span
class="math inline">\gamma</span>.</p></li>
<li><p>For function application <span class="math inline">e_1 \ e_2 :
\tau</span>, we introduce <span class="math inline">\beta = \tau</span>
and ask for <span class="math inline">e_1 : \gamma \rightarrow
\beta</span> and <span class="math inline">e_2 : \gamma</span>, for some
fresh unknowns <span class="math inline">\beta, \gamma</span>.</p></li>
<li><p>For a function <span class="math inline">\text{fun} \ x
\rightarrow e : \tau</span>, we introduce <span
class="math inline">\beta \rightarrow \gamma = \tau</span> and ask for
<span class="math inline">e : \gamma</span> in environment <span
class="math inline">\{x : \beta\} \cup \Gamma</span>, for some fresh
unknowns <span class="math inline">\beta, \gamma</span>.</p></li>
<li><p>The case <span class="math inline">\text{let} \ x = e_1 \
\text{in} \ e_2 : \tau</span> is different. One approach is to
<em>first</em> solve the equations that we get by asking for <span
class="math inline">e_1 : \beta</span>, for some fresh unknown <span
class="math inline">\beta</span>. Let us say a solution <span
class="math inline">\beta = \tau_\beta</span> has been found, <span
class="math inline">\alpha_1 \ldots \alpha_n \beta_1 \ldots
\beta_m</span> are the remaining unknowns in <span
class="math inline">\tau_\beta</span>, and <span
class="math inline">\alpha_1 \ldots \alpha_n</span> are all that do not
appear in <span class="math inline">\Gamma</span>. Then we ask for <span
class="math inline">e_2 : \tau</span> in environment <span
class="math inline">\{x : \forall \alpha_1 \ldots \alpha_n .
\tau_\beta\} \cup \Gamma</span>.</p></li>
<li><p>Remember that whenever we establish a solution <span
class="math inline">\beta = \tau_\beta</span> to an unknown <span
class="math inline">\beta</span>, it takes effect everywhere! The
substitution propagates through all the equations, potentially
triggering further unifications.</p></li>
<li><p>To find a type for <span class="math inline">e</span> (in
environment <span class="math inline">\Gamma</span>), we pick a fresh
unknown <span class="math inline">\beta</span> and ask for <span
class="math inline">e : \beta</span> (in <span
class="math inline">\Gamma</span>). The algorithm then generates and
solves equations until either a solution is found or a contradiction
reveals a type error.</p></li>
</ul>
<h4 id="polymorphism">Polymorphism</h4>
<p>The “top-level” definitions for which the system infers types with
variables are called <em>polymorphic</em>, which informally means
“working with different shapes of data.” A polymorphic function like
<code>List.hd</code> can operate on lists containing any type of element
– the function itself doesn’t care what the elements are, only that it’s
working with a list.</p>
<p>This kind of polymorphism is called <em>parametric polymorphism</em>,
since the types have parameters. The term “parametric” emphasizes that
the same code works uniformly for all type instantiations. A different
kind of polymorphism is provided by object-oriented programming
languages (sometimes called <em>subtype polymorphism</em> or <em>ad-hoc
polymorphism</em>), where different code may execute depending on the
runtime type of objects.</p>
<h3 id="parametric-types">5.2 Parametric Types</h3>
<p>Polymorphic functions truly shine when used with polymorphic data
types. The combination of the two is what makes ML-family languages so
expressive. Consider this definition of our own list type:</p>
<div class="sourceCode" id="cb105"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> &#39;a my_list = Empty | Cons <span class="kw">of</span> &#39;a * &#39;a my_list</span></code></pre></div>
<p>We define lists that can store elements of any type <code>'a</code>.
The type parameter <code>'a</code> acts as a placeholder that gets
filled in when we create actual lists. Now we can write functions that
work on these lists:</p>
<div class="sourceCode" id="cb106"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a># <span class="kw">let</span> tail l =</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> l <span class="kw">with</span></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; <span class="dt">invalid_arg</span> <span class="st">&quot;tail&quot;</span></span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>    | Cons (_, tl) -&gt; tl;;</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> tail : &#39;a my_list -&gt; &#39;a my_list = &lt;<span class="kw">fun</span>&gt;</span></code></pre></div>
<p>This is a polymorphic function: it works for lists with elements of
any type. Whether we have a list of integers, strings, or even lists of
lists, the same <code>tail</code> function handles them all.</p>
<p>A crucial point to understand: a <em>parametric type</em> like
<code>'a my_list</code> <em>is not</em> itself a data type but rather a
<em>family</em> of data types. The types <code>bool my_list</code>,
<code>int my_list</code>, etc. <em>are</em> different types – you cannot
mix elements of different types in a single list. We say that the type
<code>int my_list</code> <em>instantiates</em> the parametric type
<code>'a my_list</code>.</p>
<h4 id="multiple-type-parameters">Multiple Type Parameters</h4>
<p>Types can have multiple type parameters. In OCaml, the syntax might
seem a bit unusual at first: type parameters precede the type name,
enclosed in parentheses. For example:</p>
<div class="sourceCode" id="cb107"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> (&#39;a, &#39;b) choice = Left <span class="kw">of</span> &#39;a | Right <span class="kw">of</span> &#39;b</span></code></pre></div>
<p>This type has two parameters and represents a value that is either
something of type <code>'a</code> (wrapped in <code>Left</code>) or
something of type <code>'b</code> (wrapped in <code>Right</code>).
Mathematically we would write <span
class="math inline">\text{choice}(\alpha, \beta)</span>.</p>
<p>Not all functions that use parametric types need to be polymorphic. A
function may constrain the type parameters to specific types:</p>
<div class="sourceCode" id="cb108"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a># <span class="kw">let</span> get_int c =</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> c <span class="kw">with</span></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>    | Left i -&gt; i</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>    | Right b -&gt; <span class="kw">if</span> b <span class="kw">then</span> <span class="dv">1</span> <span class="kw">else</span> <span class="dv">0</span>;;</span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> get_int : (<span class="dt">int</span>, <span class="dt">bool</span>) choice -&gt; <span class="dt">int</span> = &lt;<span class="kw">fun</span>&gt;</span></code></pre></div>
<p>Here, the pattern matching on <code>Left i</code> and
<code>Right b</code> with arithmetic operations constrains the type to
<code>(int, bool) choice</code>.</p>
<h4 id="syntax-in-other-languages">Syntax in Other Languages</h4>
<p>Different functional languages have different syntactic conventions
for type parameters. In F#, we provide parameters (when more than one)
after the type name, using angle brackets:</p>
<div class="sourceCode" id="cb109"><pre
class="sourceCode fsharp"><code class="sourceCode fsharp"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> choice&lt;&#39;a,&#39;b&gt; = Left <span class="kw">of</span> &#39;a | Right <span class="kw">of</span> &#39;b</span></code></pre></div>
<p>In Haskell, the syntax is arguably the cleanest – we provide type
parameters similarly to function arguments, separated by spaces:</p>
<div class="sourceCode" id="cb110"><pre
class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> <span class="dt">Choice</span> a b <span class="ot">=</span> <span class="dt">Left</span> a <span class="op">|</span> <span class="dt">Right</span> b</span></code></pre></div>
<p>Despite the syntactic differences, the underlying concept of
parametric polymorphism is the same across all these languages.</p>
<h3 id="type-inference-formally">5.3 Type Inference, Formally</h3>
<p>Now we present a more formal treatment of type inference. A statement
that an expression has a type in an environment is called a <em>type
judgement</em>. For environment <span class="math inline">\Gamma = \{x :
\forall \alpha_1 \ldots \alpha_n . \tau_x ; \ldots\}</span>, expression
<span class="math inline">e</span> and type <span
class="math inline">\tau</span> we write:</p>
<p><span class="math display">\Gamma \vdash e : \tau</span></p>
<p>This notation reads: “In environment <span
class="math inline">\Gamma</span>, expression <span
class="math inline">e</span> has type <span
class="math inline">\tau</span>.” The turnstile symbol <span
class="math inline">\vdash</span> can be thought of as “entails” or
“proves.”</p>
<p>We will derive all the constraint equations in one go using the
notation <span class="math inline">[\![ \cdot ]\!]</span>, to be solved
later by unification. Besides equations we will need to manage
introduced variables, using existential quantification to express that
“there exists some type variable satisfying these constraints.”</p>
<p>For local definitions we require remembering what constraints should
hold when the definition is used. Therefore we extend <em>type
schemes</em> in the environment to: <span class="math inline">\Gamma =
\{x : \forall \beta_1 \ldots \beta_m [\exists \alpha_1 \ldots \alpha_n .
D] . \tau_x ; \ldots\}</span> where <span class="math inline">D</span>
are equations – keeping the variables <span class="math inline">\alpha_1
\ldots \alpha_n</span> introduced while deriving <span
class="math inline">D</span> in front. A simpler form would be
sufficient: <span class="math inline">\Gamma = \{x : \forall \beta
[\exists \alpha_1 \ldots \alpha_n . D] . \beta ; \ldots\}</span></p>
<p>The formal constraint generation rules are:</p>
<p><span class="math display">[\![ \Gamma \vdash x : \tau ]\!] = \exists
\overline{\beta&#39;} \overline{\alpha&#39;} . (D[\overline{\beta}
\overline{\alpha} := \overline{\beta&#39;} \overline{\alpha&#39;}]
\wedge \tau_x[\overline{\beta} \overline{\alpha} :=
\overline{\beta&#39;} \overline{\alpha&#39;}] \doteq \tau)</span></p>
<p>where <span class="math inline">\Gamma(x) = \forall \overline{\beta}
[\exists \overline{\alpha} . D] . \tau_x</span>, <span
class="math inline">\overline{\beta&#39;} \overline{\alpha&#39;} \#
\text{FV}(\Gamma, \tau)</span></p>
<p><span class="math display">[\![ \Gamma \vdash \mathbf{fun} \ x
\texttt{-&gt;} e : \tau ]\!] = \exists \alpha_1 \alpha_2 . ([\![ \Gamma
\{x : \alpha_1\} \vdash e : \alpha_2 ]\!] \wedge \alpha_1 \rightarrow
\alpha_2 \doteq \tau)</span></p>
<p>where <span class="math inline">\alpha_1 \alpha_2 \#
\text{FV}(\Gamma, \tau)</span></p>
<p><span class="math display">[\![ \Gamma \vdash e_1 \ e_2 : \tau ]\!] =
\exists \alpha . ([\![ \Gamma \vdash e_1 : \alpha \rightarrow \tau ]\!]
\wedge [\![ \Gamma \vdash e_2 : \alpha ]\!]), \alpha \#
\text{FV}(\Gamma, \tau)</span></p>
<p><span class="math display">[\![ \Gamma \vdash K \ e_1 \ldots e_n :
\tau ]\!] = \exists \overline{\alpha&#39;} . (\bigwedge_i [\![ \Gamma
\vdash e_i : \tau_i[\overline{\alpha} := \overline{\alpha&#39;}] ]\!]
\wedge \varepsilon(\overline{\alpha&#39;}) \doteq \tau)</span></p>
<p>where <span class="math inline">K : \forall \overline{\alpha} .
\tau_1 \times \ldots \times \tau_n \rightarrow
\varepsilon(\overline{\alpha})</span>, <span
class="math inline">\overline{\alpha&#39;} \# \text{FV}(\Gamma,
\tau)</span></p>
<p>For let-expressions:</p>
<p><span class="math display">[\![ \Gamma \vdash \mathbf{let} \ x = e_1
\ \mathbf{in} \ e_2 : \tau ]\!] = (\exists \beta . C) \wedge [\![ \Gamma
\{x : \forall \beta [C] . \beta\} \vdash e_2 : \tau ]\!]</span></p>
<p>where <span class="math inline">C = [\![ \Gamma \vdash e_1 : \beta
]\!]</span></p>
<p>For recursive let-expressions:</p>
<p><span class="math display">[\![ \Gamma \vdash \mathbf{letrec} \ x =
e_1 \ \mathbf{in} \ e_2 : \tau ]\!] = (\exists \beta . C) \wedge [\![
\Gamma \{x : \forall \beta [C] . \beta\} \vdash e_2 : \tau
]\!]</span></p>
<p>where <span class="math inline">C = [\![ \Gamma \{x : \beta\} \vdash
e_1 : \beta ]\!]</span></p>
<p>For match expressions:</p>
<p><span class="math display">[\![ \Gamma \vdash \mathbf{match} \ e_v \
\mathbf{with} \ \overline{c} : \tau ]\!] = \exists \alpha_v . [\![
\Gamma \vdash e_v : \alpha_v ]\!] \bigwedge_i [\![ \Gamma \vdash p_i .
e_i : \alpha_v \rightarrow \tau ]\!]</span></p>
<p>where <span class="math inline">\overline{c} = p_1 . e_1 | \ldots |
p_n . e_n</span>, <span class="math inline">\alpha_v \#
\text{FV}(\Gamma, \tau)</span></p>
<p>For pattern clauses:</p>
<p><span class="math display">[\![ \Gamma, \Sigma \vdash p.e : \tau_1
\rightarrow \tau_2 ]\!] = [\![ \Sigma \vdash p \downarrow \tau_1 ]\!]
\wedge \exists \overline{\beta} . [\![ \Gamma \Gamma&#39; \vdash e :
\tau_2 ]\!]</span></p>
<p>where <span class="math inline">\exists \overline{\beta}
\Gamma&#39;</span> is <span class="math inline">[\![ \Sigma \vdash p
\uparrow \tau_1 ]\!]</span>, <span class="math inline">\overline{\beta}
\# \text{FV}(\Gamma, \tau_2)</span></p>
<p>The notation <span class="math inline">[\![ \Sigma \vdash p
\downarrow \tau_1 ]\!]</span> derives constraints on the type of the
matched value, while <span class="math inline">[\![ \Sigma \vdash p
\uparrow \tau_1 ]\!]</span> derives the environment for pattern
variables.</p>
<p>By <span class="math inline">\overline{\alpha}</span> or <span
class="math inline">\overline{\alpha_i}</span> we denote a sequence of
some length: <span class="math inline">\alpha_1 \ldots \alpha_n</span>.
By <span class="math inline">\bigwedge_i \varphi_i</span> we denote a
conjunction of <span class="math inline">\overline{\varphi_i}</span>:
<span class="math inline">\varphi_1 \wedge \ldots \wedge
\varphi_n</span>.</p>
<h4 id="polymorphic-recursion">Polymorphic Recursion</h4>
<p>There is an interesting limitation in standard type inference for
recursive functions. Note the limited polymorphism of
<code>let rec f = ...</code> – we cannot use <code>f</code>
polymorphically within its own definition. Why? Because when
type-checking the body of a recursive definition, we don’t yet know the
final type of <code>f</code>, so we must treat it as having a single,
unknown type.</p>
<p>In modern OCaml we can bypass this limitation if we provide the type
of <code>f</code> upfront:</p>
<pre><code>let rec f : &#39;a. &#39;a -&gt; &#39;a list = ...</code></pre>
<p>where <code>'a. 'a -&gt; 'a list</code> stands for <span
class="math inline">\forall \alpha . \alpha \rightarrow \alpha \
\text{list}</span>.</p>
<p>Using the recursively defined function with different types in its
definition is called <em>polymorphic recursion</em>. It is most useful
together with <em>irregular recursive datatypes</em> – data structures
where the recursive use has different type arguments than the actual
parameters. These “nested” or “non-uniform” datatypes enable some
remarkably elegant data structures.</p>
<h5
id="example-a-list-alternating-between-two-types-of-elements">Example: A
List Alternating Between Two Types of Elements</h5>
<p>Here is a fascinating example: a list that alternates between two
different types of elements. Notice how the recursive occurrence swaps
the type parameters:</p>
<div class="sourceCode" id="cb112"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> (&#39;x, &#39;o) alterning =</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>  | Stop</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>  | One <span class="kw">of</span> &#39;x * (&#39;o, &#39;x) alterning</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> to_list :</span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a>    &#39;x &#39;o &#39;a. (&#39;x -&gt; &#39;a) -&gt; (&#39;o -&gt; &#39;a) -&gt;</span>
<span id="cb112-7"><a href="#cb112-7" aria-hidden="true" tabindex="-1"></a>              (&#39;x, &#39;o) alterning -&gt; &#39;a <span class="dt">list</span> =</span>
<span id="cb112-8"><a href="#cb112-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">fun</span> x2a o2a -&gt;</span>
<span id="cb112-9"><a href="#cb112-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">function</span></span>
<span id="cb112-10"><a href="#cb112-10" aria-hidden="true" tabindex="-1"></a>    | Stop -&gt; []</span>
<span id="cb112-11"><a href="#cb112-11" aria-hidden="true" tabindex="-1"></a>    | One (x, rest) -&gt; x2a x :: to_list o2a x2a rest</span>
<span id="cb112-12"><a href="#cb112-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-13"><a href="#cb112-13" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> to_choice_list alt =</span>
<span id="cb112-14"><a href="#cb112-14" aria-hidden="true" tabindex="-1"></a>  to_list (<span class="kw">fun</span> x -&gt; Left x) (<span class="kw">fun</span> o -&gt; Right o) alt</span>
<span id="cb112-15"><a href="#cb112-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-16"><a href="#cb112-16" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> it = to_choice_list</span>
<span id="cb112-17"><a href="#cb112-17" aria-hidden="true" tabindex="-1"></a>  (One (<span class="dv">1</span>, One (<span class="st">&quot;o&quot;</span>, One (<span class="dv">2</span>, One (<span class="st">&quot;oo&quot;</span>, Stop)))))</span></code></pre></div>
<p>Notice how the recursive call to <code>to_list</code> swaps
<code>o2a</code> and <code>x2a</code> – this is necessary because the
alternating structure swaps the type parameters at each level. The
polymorphic recursion annotation <code>'x 'o 'a.</code> tells OCaml that
we need to use <code>to_list</code> at different type instantiations
within its own definition.</p>
<h5 id="example-data-structural-bootstrapping">Example: Data-Structural
Bootstrapping</h5>
<p>Here is another powerful example of polymorphic recursion: a sequence
data structure that stores elements in exponentially increasing chunks.
This technique, known as <em>data-structural bootstrapping</em>,
achieves logarithmic-time random access – much faster than standard
lists which require linear time.</p>
<div class="sourceCode" id="cb113"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> &#39;a seq =</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>  | Nil</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>  | Zero <span class="kw">of</span> (&#39;a * &#39;a) seq</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>  | One <span class="kw">of</span> &#39;a * (&#39;a * &#39;a) seq</span></code></pre></div>
<p>The key insight is that this type is <em>non-uniform</em>: the
recursive occurrences use <code>('a * 'a) seq</code> rather than
<code>'a seq</code>. This means that as we go deeper into the structure,
elements get paired together, effectively doubling the “width” at each
level. We store a list of elements in exponentially increasing
chunks:</p>
<div class="sourceCode" id="cb114"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> example =</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>  One (<span class="dv">0</span>, One ((<span class="dv">1</span>,<span class="dv">2</span>), Zero (One ((((<span class="dv">3</span>,<span class="dv">4</span>),(<span class="dv">5</span>,<span class="dv">6</span>)), ((<span class="dv">7</span>,<span class="dv">8</span>),(<span class="dv">9</span>,<span class="dv">10</span>))), Nil))))</span></code></pre></div>
<p>The <code>cons</code> operation adds an element to the front.
Remarkably, appending an element to this data structure works exactly
like adding one to a binary number:</p>
<div class="sourceCode" id="cb115"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> cons : &#39;a. &#39;a -&gt; &#39;a seq -&gt; &#39;a seq =  <span class="co">(* Appending an element to the *)</span></span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">fun</span> x -&gt; <span class="kw">function</span>                           <span class="co">(* datastructure is like *)</span></span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>  | Nil -&gt; One (x, Nil)                       <span class="co">(* adding one to a binary number: 1+0=1 *)</span></span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a>  | Zero ps -&gt; One (x, ps)                    <span class="co">(* 1+...0=...1 *)</span></span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a>  | One (y, ps) -&gt; Zero (cons (x,y) ps)       <span class="co">(* 1+...1=[...+1]0 *)</span></span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-7"><a href="#cb115-7" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> lookup : &#39;a. <span class="dt">int</span> -&gt; &#39;a seq -&gt; &#39;a =</span>
<span id="cb115-8"><a href="#cb115-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">fun</span> i s -&gt; <span class="kw">match</span> i, s <span class="kw">with</span></span>
<span id="cb115-9"><a href="#cb115-9" aria-hidden="true" tabindex="-1"></a>  | _, Nil -&gt; <span class="dt">raise</span> <span class="dt">Not_found</span>                 <span class="co">(* Rather than returning None : &#39;a option *)</span></span>
<span id="cb115-10"><a href="#cb115-10" aria-hidden="true" tabindex="-1"></a>  | <span class="dv">0</span>, One (x, _) -&gt; x                        <span class="co">(* we raise exception, for convenience. *)</span></span>
<span id="cb115-11"><a href="#cb115-11" aria-hidden="true" tabindex="-1"></a>  | i, One (_, ps) -&gt; lookup (i<span class="dv">-1</span>) (Zero ps)</span>
<span id="cb115-12"><a href="#cb115-12" aria-hidden="true" tabindex="-1"></a>  | i, Zero ps -&gt;                             <span class="co">(* Random-access lookup works *)</span></span>
<span id="cb115-13"><a href="#cb115-13" aria-hidden="true" tabindex="-1"></a>      <span class="kw">let</span> x, y = lookup (i / <span class="dv">2</span>) ps <span class="kw">in</span>         <span class="co">(* in logarithmic time -- much faster than *)</span></span>
<span id="cb115-14"><a href="#cb115-14" aria-hidden="true" tabindex="-1"></a>      <span class="kw">if</span> i <span class="kw">mod</span> <span class="dv">2</span> = <span class="dv">0</span> <span class="kw">then</span> x <span class="kw">else</span> y            <span class="co">(* in standard lists. *)</span></span></code></pre></div>
<p>The <code>Zero</code> and <code>One</code> constructors correspond to
binary digits. A <code>Zero</code> means “no singleton element at this
level,” while <code>One</code> carries a singleton (or pair, or quad,
etc.) before recursing. The <code>lookup</code> function exploits this
structure: when looking up index <code>i</code> in a
<code>Zero ps</code>, it divides by 2 and looks in the paired structure,
then extracts the appropriate half of the pair.</p>
<h3 id="algebraic-specification">5.4 Algebraic Specification</h3>
<p>Now we turn to a fundamental question in computer science: how do we
formally describe what a data structure <em>is</em> and what it should
<em>do</em>? The mathematical answer is <em>algebraic
specification</em>.</p>
<p>The way we introduce a data structure, like complex numbers or
strings, in mathematics is by specifying an <em>algebraic
structure</em>. This approach gives us a precise language for describing
data structures independent of any particular implementation.</p>
<p>Algebraic structures consist of a set (or several sets, for so-called
<em>multisorted</em> algebras) and a bunch of functions (also known as
operations) over this set (or sets). Think of integers with addition and
multiplication, or strings with concatenation and character access.</p>
<p>A <em>signature</em> is a rough description of an algebraic
structure: it provides <em>sorts</em> – names for the sets (in the
multisorted case) – and names of the functions-operations together with
their arity (and what sorts of arguments they take). A signature tells
us what operations exist, but not how they behave.</p>
<p>We select a class of algebraic structures by providing axioms that
have to hold. We will call such classes <em>algebraic
specifications</em>. In mathematics, a rusty name for some algebraic
specifications is a <em>variety</em>; a more modern name is
<em>algebraic category</em>.</p>
<p>Here is the key connection to programming: algebraic structures
correspond to “implementations” and signatures to “interfaces” in
programming languages. We will say that an algebraic structure
<em>implements</em> an algebraic specification when all axioms of the
specification hold in the structure. An important point: all algebraic
specifications are implemented by multiple structures! This is precisely
what we want – it gives us the freedom to choose different
implementations with different performance characteristics while
maintaining the same interface.</p>
<p>We say that an algebraic structure does not have <em>junk</em> when
all its elements (i.e., elements in the sets corresponding to sorts) can
be built using operations in its signature. Junk-free structures are
“minimal” in some sense – they contain only the values that can be
constructed using the provided operations.</p>
<p>We allow parametric types as sorts. In that case, strictly speaking,
we define a family of algebraic specifications (a different
specification for each instantiation of the parametric type).</p>
<h4 id="algebraic-specifications-examples">Algebraic Specifications:
Examples</h4>
<p>Let us look at some concrete examples to make these abstract ideas
tangible. An algebraic specification can also use an earlier
specification, building up complexity layer by layer. In “impure”
languages like OCaml and F# we allow that the result of any operation be
an <span class="math inline">\text{error}</span>. In Haskell we would
use <code>Maybe</code> to explicitly model potential failure.</p>
<p><strong>Specification <span class="math inline">\text{nat}_p</span>
(bounded natural numbers):</strong></p>
<p>This specification describes natural numbers that wrap around at some
bound <span class="math inline">p</span> (like machine integers):</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr>
<th><span class="math inline">\text{nat}_p</span></th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">0 : \text{nat}_p</span></td>
</tr>
<tr>
<td><span class="math inline">\text{succ} : \text{nat}_p \rightarrow
\text{nat}_p</span></td>
</tr>
<tr>
<td><span class="math inline">+ : \text{nat}_p \rightarrow \text{nat}_p
\rightarrow \text{nat}_p</span></td>
</tr>
<tr>
<td><span class="math inline">* : \text{nat}_p \rightarrow \text{nat}_p
\rightarrow \text{nat}_p</span></td>
</tr>
<tr>
<td>Variables: <span class="math inline">n, m : \text{nat}_p</span></td>
</tr>
<tr>
<td>Axioms:</td>
</tr>
<tr>
<td><span class="math inline">0 + n = n</span>, <span
class="math inline">n + 0 = n</span></td>
</tr>
<tr>
<td><span class="math inline">m + \text{succ}(n) = \text{succ}(m +
n)</span></td>
</tr>
<tr>
<td><span class="math inline">0 * n = 0</span>, <span
class="math inline">n * 0 = 0</span></td>
</tr>
<tr>
<td><span class="math inline">m * \text{succ}(n) = m + (m *
n)</span></td>
</tr>
<tr>
<td><span
class="math inline">\underbrace{\text{succ}(\ldots\text{succ}(0))}_{\text{less
than } p \text{ times}} \neq 0</span></td>
</tr>
<tr>
<td><span
class="math inline">\underbrace{\text{succ}(\ldots\text{succ}(0))}_{p
\text{ times}} = 0</span></td>
</tr>
</tbody>
</table>
<p>The axioms define how addition and multiplication work recursively,
and the last two axioms capture the bounded nature: applying <span
class="math inline">\text{succ}</span> less than <span
class="math inline">p</span> times never gives zero, but exactly <span
class="math inline">p</span> times wraps around to zero.</p>
<p><strong>Specification <span
class="math inline">\text{string}_p</span> (bounded
strings):</strong></p>
<p>This specification describes strings with a maximum length <span
class="math inline">p</span>:</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr>
<th><span class="math inline">\text{string}_p</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>uses <span class="math inline">\text{char}</span>, <span
class="math inline">\text{nat}_p</span></td>
</tr>
<tr>
<td><code>""</code> <span class="math inline">:
\text{string}_p</span></td>
</tr>
<tr>
<td><code>"c"</code> <span class="math inline">: \text{char} \rightarrow
\text{string}_p</span></td>
</tr>
<tr>
<td><span class="math inline">\hat{\ } : \text{string}_p \rightarrow
\text{string}_p \rightarrow \text{string}_p</span></td>
</tr>
<tr>
<td><span class="math inline">\cdot[\cdot] : \text{string}_p \rightarrow
\text{nat}_p \rightarrow \text{char}</span></td>
</tr>
<tr>
<td>Variables: <span class="math inline">s : \text{string}_p</span>,
<span class="math inline">c, c_1, \ldots, c_p : \text{char}</span>,
<span class="math inline">n : \text{nat}_p</span></td>
</tr>
<tr>
<td>Axioms:</td>
</tr>
<tr>
<td><code>""</code> <span class="math inline">\hat{\ } s = s</span>,
<span class="math inline">s \hat{\ }</span> <code>""</code> <span
class="math inline">= s</span></td>
</tr>
<tr>
<td><span class="math inline">\underbrace{\text{``}c_1\text{&#39;&#39;}
\hat{\ } (\ldots \hat{\ } \text{``}c_p\text{&#39;&#39;})}_{p \text{
times}} = \text{error}</span></td>
</tr>
<tr>
<td><span class="math inline">r \hat{\ } (s \hat{\ } t) = (r \hat{\ } s)
\hat{\ } t</span></td>
</tr>
<tr>
<td><span class="math inline">(\text{``}c\text{&#39;&#39;} \hat{\ }
s)[0] = c</span></td>
</tr>
<tr>
<td><span class="math inline">(\text{``}c\text{&#39;&#39;} \hat{\ }
s)[\text{succ}(n)] = s[n]</span></td>
</tr>
<tr>
<td><code>""</code><span class="math inline">[n] =
\text{error}</span></td>
</tr>
</tbody>
</table>
<p>The axioms specify that concatenation is associative, that the empty
string is an identity for concatenation, that exceeding the length limit
produces an error, and that indexing works by stripping characters from
the front.</p>
<h3 id="homomorphisms">5.5 Homomorphisms</h3>
<p>When do two implementations of the same specification “behave the
same”? The mathematical answer involves <em>homomorphisms</em> –
structure-preserving mappings between algebraic structures.</p>
<p>Homomorphisms are mappings between algebraic structures with the same
signature that preserve operations. Intuitively, if you apply an
operation and then map, you get the same result as mapping first and
then applying the corresponding operation.</p>
<p>A <em>homomorphism</em> from algebraic structure <span
class="math inline">(A, \{f^A, g^A, \ldots\})</span> to <span
class="math inline">(B, \{f^B, g^B, \ldots\})</span> is a function <span
class="math inline">h : A \rightarrow B</span> such that: - <span
class="math inline">h(f^A(a_1, \ldots, a_{n_f})) = f^B(h(a_1), \ldots,
h(a_{n_f}))</span> for all <span class="math inline">(a_1, \ldots,
a_{n_f})</span> - <span class="math inline">h(g^A(a_1, \ldots, a_{n_g}))
= g^B(h(a_1), \ldots, h(a_{n_g}))</span> for all <span
class="math inline">(a_1, \ldots, a_{n_g})</span> - and so on for all
operations.</p>
<p>Two algebraic structures are <em>isomorphic</em> if there are
homomorphisms <span class="math inline">h_1 : A \rightarrow B</span>,
<span class="math inline">h_2 : B \rightarrow A</span> from one to the
other and back, that when composed in any order form identity: <span
class="math inline">\forall (b \in B) \ h_1(h_2(b)) = b</span> and <span
class="math inline">\forall (a \in A) \ h_2(h_1(a)) = a</span>.</p>
<p>An algebraic specification whose all implementations without junk are
isomorphic is called “<em>monomorphic</em>”. This means the
specification pins down the structure so precisely that there’s
essentially only one way to implement it (up to isomorphism).</p>
<p>We usually only add axioms that really matter to us to the
specification, so that the implementations have room for optimization.
For this reason, the resulting specifications will often not be
monomorphic in the above sense – and that’s intentional! A
non-monomorphic specification allows for multiple genuinely different
implementations, which may have different performance
characteristics.</p>
<h3 id="example-maps">5.6 Example: Maps</h3>
<p>Now let us look at a practical example that will guide the rest of
this chapter. A <em>map</em> (also called dictionary or associative
array) associates keys with values. This is one of the most fundamental
data structures in programming – think of Python’s dictionaries, Java’s
<code>HashMap</code>, or OCaml’s <code>Map</code> module.</p>
<p>Here is an algebraic specification that captures the essential
behavior of maps:</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr>
<th><span class="math inline">(\alpha, \beta) \ \text{map}</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>uses <span class="math inline">\text{bool}</span>, type parameters
<span class="math inline">\alpha, \beta</span></td>
</tr>
<tr>
<td><span class="math inline">\text{empty} : (\alpha, \beta) \
\text{map}</span></td>
</tr>
<tr>
<td><span class="math inline">\text{member} : \alpha \rightarrow
(\alpha, \beta) \ \text{map} \rightarrow \text{bool}</span></td>
</tr>
<tr>
<td><span class="math inline">\text{add} : \alpha \rightarrow \beta
\rightarrow (\alpha, \beta) \ \text{map} \rightarrow (\alpha, \beta) \
\text{map}</span></td>
</tr>
<tr>
<td><span class="math inline">\text{remove} : \alpha \rightarrow
(\alpha, \beta) \ \text{map} \rightarrow (\alpha, \beta) \
\text{map}</span></td>
</tr>
<tr>
<td><span class="math inline">\text{find} : \alpha \rightarrow (\alpha,
\beta) \ \text{map} \rightarrow \beta</span></td>
</tr>
<tr>
<td>Variables: <span class="math inline">k, k_2 : \alpha</span>, <span
class="math inline">v, v_2 : \beta</span>, <span class="math inline">m :
(\alpha, \beta) \ \text{map}</span></td>
</tr>
<tr>
<td>Axioms:</td>
</tr>
<tr>
<td><span class="math inline">\text{member}(k, \text{add}(k, v, m)) =
\text{true}</span></td>
</tr>
<tr>
<td><span class="math inline">\text{member}(k, \text{remove}(k, m)) =
\text{false}</span></td>
</tr>
<tr>
<td><span class="math inline">\text{member}(k, \text{add}(k_2, v, m)) =
\text{true} \wedge k \neq k_2 \Leftrightarrow \text{member}(k, m) =
\text{true} \wedge k \neq k_2</span></td>
</tr>
<tr>
<td><span class="math inline">\text{member}(k, \text{remove}(k_2, m)) =
\text{true} \wedge k \neq k_2 \Leftrightarrow \text{member}(k, m) =
\text{true} \wedge k \neq k_2</span></td>
</tr>
<tr>
<td><span class="math inline">\text{find}(k, \text{add}(k, v, m)) =
v</span></td>
</tr>
<tr>
<td><span class="math inline">\text{find}(k, \text{remove}(k, m)) =
\text{error}</span>, <span class="math inline">\text{find}(k,
\text{empty}) = \text{error}</span></td>
</tr>
<tr>
<td><span class="math inline">\text{find}(k, \text{add}(k_2, v_2, m)) =
v \wedge k \neq k_2 \Leftrightarrow \text{find}(k, m) = v \wedge k \neq
k_2</span></td>
</tr>
<tr>
<td><span class="math inline">\text{find}(k, \text{remove}(k_2, m)) = v
\wedge k \neq k_2 \Leftrightarrow \text{find}(k, m) = v \wedge k \neq
k_2</span></td>
</tr>
<tr>
<td><span class="math inline">\text{remove}(k, \text{empty}) =
\text{empty}</span></td>
</tr>
</tbody>
</table>
<p>The axioms capture the intuitive behavior: adding a key-value pair
makes that key findable, removing a key makes it unfindable, and
operations on different keys don’t interfere with each other. Notice how
the specification says nothing about <em>how</em> the map is implemented
– only about <em>what</em> behavior it must exhibit.</p>
<h3 id="modules-and-interfaces-signatures-syntax">5.7 Modules and
Interfaces (Signatures): Syntax</h3>
<p>How do we express algebraic specifications in OCaml? The answer is
the <em>module system</em>. In the ML family of languages, structures
are given names by <strong>module</strong> bindings, and signatures are
types of modules. From outside of a structure or signature, we refer to
the values or types it provides with a dot notation:
<code>Module.value</code>.</p>
<p>Module (and module type) names have to start with a capital letter
(in ML languages). Since modules and module types have names, there is a
convention to name the central type of a signature (the one that is
“specified” by the signature), for brevity, <code>t</code>. Module types
are often named with “all-caps” (all letters upper case).</p>
<p>Here is how we translate our map specification into an OCaml module
signature:</p>
<div class="sourceCode" id="cb116"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="kw">module</span> <span class="kw">type</span> MAP = <span class="kw">sig</span></span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> (&#39;a, &#39;b) t</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">val</span> empty : (&#39;a, &#39;b) t</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">val</span> member : &#39;a -&gt; (&#39;a, &#39;b) t -&gt; <span class="dt">bool</span></span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">val</span> add : &#39;a -&gt; &#39;b -&gt; (&#39;a, &#39;b) t -&gt; (&#39;a, &#39;b) t</span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">val</span> remove : &#39;a -&gt; (&#39;a, &#39;b) t -&gt; (&#39;a, &#39;b) t</span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">val</span> find : &#39;a -&gt; (&#39;a, &#39;b) t -&gt; &#39;b</span>
<span id="cb116-8"><a href="#cb116-8" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb116-9"><a href="#cb116-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-10"><a href="#cb116-10" aria-hidden="true" tabindex="-1"></a><span class="kw">module</span> ListMap : MAP = <span class="kw">struct</span></span>
<span id="cb116-11"><a href="#cb116-11" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> (&#39;a, &#39;b) t = (&#39;a * &#39;b) <span class="dt">list</span></span>
<span id="cb116-12"><a href="#cb116-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> empty = []</span>
<span id="cb116-13"><a href="#cb116-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> member = <span class="dt">List</span>.mem_assoc</span>
<span id="cb116-14"><a href="#cb116-14" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> add k v m = (k, v)::m</span>
<span id="cb116-15"><a href="#cb116-15" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> remove = <span class="dt">List</span>.remove_assoc</span>
<span id="cb116-16"><a href="#cb116-16" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> find = <span class="dt">List</span>.assoc</span>
<span id="cb116-17"><a href="#cb116-17" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code></pre></div>
<p>The <code>ListMap</code> module implements <code>MAP</code> using
OCaml’s built-in list functions for association lists. The type
annotation <code>: MAP</code> after the module name tells OCaml to check
that the implementation provides everything the signature requires, and
hides any additional details.</p>
<h3 id="implementing-maps-association-lists">5.8 Implementing Maps:
Association Lists</h3>
<p>Let us now build an implementation of maps from the ground up,
exploring different approaches and their trade-offs. The most
straightforward implementation… might not be what you expected:</p>
<div class="sourceCode" id="cb117"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="kw">module</span> TrivialMap : MAP = <span class="kw">struct</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> (&#39;a, &#39;b) t =</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>    | Empty</span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>    | Add <span class="kw">of</span> &#39;a * &#39;b * (&#39;a, &#39;b) t</span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a>    | Remove <span class="kw">of</span> &#39;a * (&#39;a, &#39;b) t</span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> empty = Empty</span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-9"><a href="#cb117-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> member k m =</span>
<span id="cb117-10"><a href="#cb117-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> m <span class="kw">with</span></span>
<span id="cb117-11"><a href="#cb117-11" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; <span class="kw">false</span></span>
<span id="cb117-12"><a href="#cb117-12" aria-hidden="true" tabindex="-1"></a>    | Add (k2, _, _) <span class="kw">when</span> k = k2 -&gt; <span class="kw">true</span></span>
<span id="cb117-13"><a href="#cb117-13" aria-hidden="true" tabindex="-1"></a>    | Remove (k2, _) <span class="kw">when</span> k = k2 -&gt; <span class="kw">false</span></span>
<span id="cb117-14"><a href="#cb117-14" aria-hidden="true" tabindex="-1"></a>    | Add (_, _, m2) -&gt; member k m2</span>
<span id="cb117-15"><a href="#cb117-15" aria-hidden="true" tabindex="-1"></a>    | Remove (_, m2) -&gt; member k m2</span>
<span id="cb117-16"><a href="#cb117-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-17"><a href="#cb117-17" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> add k v m = Add (k, v, m)</span>
<span id="cb117-18"><a href="#cb117-18" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> remove k m = Remove (k, m)</span>
<span id="cb117-19"><a href="#cb117-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-20"><a href="#cb117-20" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> find k m =</span>
<span id="cb117-21"><a href="#cb117-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> m <span class="kw">with</span></span>
<span id="cb117-22"><a href="#cb117-22" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; <span class="dt">raise</span> <span class="dt">Not_found</span></span>
<span id="cb117-23"><a href="#cb117-23" aria-hidden="true" tabindex="-1"></a>    | Add (k2, v, _) <span class="kw">when</span> k = k2 -&gt; v</span>
<span id="cb117-24"><a href="#cb117-24" aria-hidden="true" tabindex="-1"></a>    | Remove (k2, _) <span class="kw">when</span> k = k2 -&gt; <span class="dt">raise</span> <span class="dt">Not_found</span></span>
<span id="cb117-25"><a href="#cb117-25" aria-hidden="true" tabindex="-1"></a>    | Add (_, _, m2) -&gt; find k m2</span>
<span id="cb117-26"><a href="#cb117-26" aria-hidden="true" tabindex="-1"></a>    | Remove (_, m2) -&gt; find k m2</span>
<span id="cb117-27"><a href="#cb117-27" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code></pre></div>
<p>This “trivial” implementation is quite clever in its own way: it
simply records all operations as a log! The data structure itself is a
history of everything that has been done to it. The <code>add</code> and
<code>remove</code> operations are <span class="math inline">O(1)</span>
– they just prepend a new node. However, <code>member</code> and
<code>find</code> must traverse the entire history to determine the
current state, giving them <span class="math inline">O(n)</span>
complexity where <span class="math inline">n</span> is the number of
operations performed.</p>
<p>This implementation illustrates an important point: there are many
ways to satisfy the same specification, with very different performance
characteristics.</p>
<p>Here is a more conventional implementation based on association
lists, i.e., on lists of key-value pairs without the <code>Remove</code>
constructor:</p>
<div class="sourceCode" id="cb118"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="kw">module</span> MyListMap : MAP = <span class="kw">struct</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> (&#39;a, &#39;b) t = Empty | Add <span class="kw">of</span> &#39;a * &#39;b * (&#39;a, &#39;b) t</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> empty = Empty</span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-6"><a href="#cb118-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> member k m =</span>
<span id="cb118-7"><a href="#cb118-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> m <span class="kw">with</span></span>
<span id="cb118-8"><a href="#cb118-8" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; <span class="kw">false</span></span>
<span id="cb118-9"><a href="#cb118-9" aria-hidden="true" tabindex="-1"></a>    | Add (k2, _, _) <span class="kw">when</span> k = k2 -&gt; <span class="kw">true</span></span>
<span id="cb118-10"><a href="#cb118-10" aria-hidden="true" tabindex="-1"></a>    | Add (_, _, m2) -&gt; member k m2</span>
<span id="cb118-11"><a href="#cb118-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-12"><a href="#cb118-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> add k v m =</span>
<span id="cb118-13"><a href="#cb118-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> m <span class="kw">with</span></span>
<span id="cb118-14"><a href="#cb118-14" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; Add (k, v, Empty)</span>
<span id="cb118-15"><a href="#cb118-15" aria-hidden="true" tabindex="-1"></a>    | Add (k2, _, m) <span class="kw">when</span> k = k2 -&gt; Add (k, v, m)</span>
<span id="cb118-16"><a href="#cb118-16" aria-hidden="true" tabindex="-1"></a>    | Add (k2, v2, m) -&gt; Add (k2, v2, add k v m)</span>
<span id="cb118-17"><a href="#cb118-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-18"><a href="#cb118-18" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> remove k m =</span>
<span id="cb118-19"><a href="#cb118-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> m <span class="kw">with</span></span>
<span id="cb118-20"><a href="#cb118-20" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; Empty</span>
<span id="cb118-21"><a href="#cb118-21" aria-hidden="true" tabindex="-1"></a>    | Add (k2, _, m) <span class="kw">when</span> k = k2 -&gt; m</span>
<span id="cb118-22"><a href="#cb118-22" aria-hidden="true" tabindex="-1"></a>    | Add (k2, v, m) -&gt; Add (k2, v, remove k m)</span>
<span id="cb118-23"><a href="#cb118-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-24"><a href="#cb118-24" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> find k m =</span>
<span id="cb118-25"><a href="#cb118-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> m <span class="kw">with</span></span>
<span id="cb118-26"><a href="#cb118-26" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; <span class="dt">raise</span> <span class="dt">Not_found</span></span>
<span id="cb118-27"><a href="#cb118-27" aria-hidden="true" tabindex="-1"></a>    | Add (k2, v, _) <span class="kw">when</span> k = k2 -&gt; v</span>
<span id="cb118-28"><a href="#cb118-28" aria-hidden="true" tabindex="-1"></a>    | Add (_, _, m2) -&gt; find k m2</span>
<span id="cb118-29"><a href="#cb118-29" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code></pre></div>
<p>This implementation maintains the invariant that each key appears at
most once in the structure. The <code>add</code> function replaces an
existing key’s value rather than creating a duplicate, and
<code>remove</code> actually removes the key-value pair. All operations
are still <span class="math inline">O(n)</span> in the worst case, but
the structure stays cleaner.</p>
<h3 id="implementing-maps-binary-search-trees">5.9 Implementing Maps:
Binary Search Trees</h3>
<p>Can we do better than linear time? Yes, by using a smarter data
structure. Binary search trees are binary trees with elements stored at
the interior nodes, such that elements to the left of a node are smaller
than, and elements to the right bigger than, elements within a node.
This ordering property is what makes them efficient.</p>
<p>For maps, we store key-value pairs as elements in binary search
trees, and compare the elements by keys alone. The tree structure allows
us to use “divide-and-conquer” to search for the value associated with a
key.</p>
<p>On average, binary search trees are fast – <span
class="math inline">O(\log n)</span> complexity for all operations. At
each node, we can eliminate half the remaining elements from
consideration. However, in the worst case (when keys are inserted in
sorted order), the tree degenerates into a linked list and operations
become <span class="math inline">O(n)</span>.</p>
<p>A note on our design: the simple polymorphic signature for maps is
only possible because OCaml provides polymorphic comparison (and
equality) operators that work on elements of most types (but not on
functions). These operators may not behave as you expect for all types!
Our signature for polymorphic maps is not the standard approach because
of this limitation; it is just to keep things simple for pedagogical
purposes.</p>
<div class="sourceCode" id="cb119"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="kw">module</span> BTreeMap : MAP = <span class="kw">struct</span></span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> (&#39;a, &#39;b) t = Empty | T <span class="kw">of</span> (&#39;a, &#39;b) t * &#39;a * &#39;b * (&#39;a, &#39;b) t</span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> empty = Empty</span>
<span id="cb119-5"><a href="#cb119-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-6"><a href="#cb119-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> member k m =                    <span class="co">(* &quot;Divide and conquer&quot; search through the tree. *)</span></span>
<span id="cb119-7"><a href="#cb119-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> m <span class="kw">with</span></span>
<span id="cb119-8"><a href="#cb119-8" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; <span class="kw">false</span></span>
<span id="cb119-9"><a href="#cb119-9" aria-hidden="true" tabindex="-1"></a>    | T (_, k2, _, _) <span class="kw">when</span> k = k2 -&gt; <span class="kw">true</span></span>
<span id="cb119-10"><a href="#cb119-10" aria-hidden="true" tabindex="-1"></a>    | T (m1, k2, _, _) <span class="kw">when</span> k &lt; k2 -&gt; member k m1</span>
<span id="cb119-11"><a href="#cb119-11" aria-hidden="true" tabindex="-1"></a>    | T (_, _, _, m2) -&gt; member k m2</span>
<span id="cb119-12"><a href="#cb119-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-13"><a href="#cb119-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> add k v m =                     <span class="co">(* Searches the tree in the same way as member *)</span></span>
<span id="cb119-14"><a href="#cb119-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> m <span class="kw">with</span>                          <span class="co">(* but copies every node along the way. *)</span></span>
<span id="cb119-15"><a href="#cb119-15" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; T (Empty, k, v, Empty)</span>
<span id="cb119-16"><a href="#cb119-16" aria-hidden="true" tabindex="-1"></a>    | T (m1, k2, _, m2) <span class="kw">when</span> k = k2 -&gt; T (m1, k, v, m2)</span>
<span id="cb119-17"><a href="#cb119-17" aria-hidden="true" tabindex="-1"></a>    | T (m1, k2, v2, m2) <span class="kw">when</span> k &lt; k2 -&gt; T (add k v m1, k2, v2, m2)</span>
<span id="cb119-18"><a href="#cb119-18" aria-hidden="true" tabindex="-1"></a>    | T (m1, k2, v2, m2) -&gt; T (m1, k2, v2, add k v m2)</span>
<span id="cb119-19"><a href="#cb119-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-20"><a href="#cb119-20" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> split_rightmost m =             <span class="co">(* A helper function, it does not belong *)</span></span>
<span id="cb119-21"><a href="#cb119-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> m <span class="kw">with</span>                          <span class="co">(* to the &quot;exported&quot; signature. *)</span></span>
<span id="cb119-22"><a href="#cb119-22" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; <span class="dt">raise</span> <span class="dt">Not_found</span></span>
<span id="cb119-23"><a href="#cb119-23" aria-hidden="true" tabindex="-1"></a>    | T (Empty, k, v, Empty) -&gt; k, v, Empty   <span class="co">(* We remove one element, *)</span></span>
<span id="cb119-24"><a href="#cb119-24" aria-hidden="true" tabindex="-1"></a>    | T (m1, k, v, m2) -&gt;                 <span class="co">(* the one that is on the bottom right. *)</span></span>
<span id="cb119-25"><a href="#cb119-25" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> rk, rv, rm = split_rightmost m2 <span class="kw">in</span></span>
<span id="cb119-26"><a href="#cb119-26" aria-hidden="true" tabindex="-1"></a>        rk, rv, T (m1, k, v, rm)</span>
<span id="cb119-27"><a href="#cb119-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-28"><a href="#cb119-28" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> remove k m =</span>
<span id="cb119-29"><a href="#cb119-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> m <span class="kw">with</span></span>
<span id="cb119-30"><a href="#cb119-30" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; Empty</span>
<span id="cb119-31"><a href="#cb119-31" aria-hidden="true" tabindex="-1"></a>    | T (m1, k2, _, Empty) <span class="kw">when</span> k = k2 -&gt; m1</span>
<span id="cb119-32"><a href="#cb119-32" aria-hidden="true" tabindex="-1"></a>    | T (Empty, k2, _, m2) <span class="kw">when</span> k = k2 -&gt; m2</span>
<span id="cb119-33"><a href="#cb119-33" aria-hidden="true" tabindex="-1"></a>    | T (m1, k2, _, m2) <span class="kw">when</span> k = k2 -&gt;</span>
<span id="cb119-34"><a href="#cb119-34" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> rk, rv, rm = split_rightmost m1 <span class="kw">in</span></span>
<span id="cb119-35"><a href="#cb119-35" aria-hidden="true" tabindex="-1"></a>        T (rm, rk, rv, m2)</span>
<span id="cb119-36"><a href="#cb119-36" aria-hidden="true" tabindex="-1"></a>    | T (m1, k2, v, m2) <span class="kw">when</span> k &lt; k2 -&gt; T (remove k m1, k2, v, m2)</span>
<span id="cb119-37"><a href="#cb119-37" aria-hidden="true" tabindex="-1"></a>    | T (m1, k2, v, m2) -&gt; T (m1, k2, v, remove k m2)</span>
<span id="cb119-38"><a href="#cb119-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-39"><a href="#cb119-39" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> find k m =</span>
<span id="cb119-40"><a href="#cb119-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">match</span> m <span class="kw">with</span></span>
<span id="cb119-41"><a href="#cb119-41" aria-hidden="true" tabindex="-1"></a>    | Empty -&gt; <span class="dt">raise</span> <span class="dt">Not_found</span></span>
<span id="cb119-42"><a href="#cb119-42" aria-hidden="true" tabindex="-1"></a>    | T (_, k2, v, _) <span class="kw">when</span> k = k2 -&gt; v</span>
<span id="cb119-43"><a href="#cb119-43" aria-hidden="true" tabindex="-1"></a>    | T (m1, k2, _, _) <span class="kw">when</span> k &lt; k2 -&gt; find k m1</span>
<span id="cb119-44"><a href="#cb119-44" aria-hidden="true" tabindex="-1"></a>    | T (_, _, _, m2) -&gt; find k m2</span>
<span id="cb119-45"><a href="#cb119-45" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code></pre></div>
<p>The <code>member</code> and <code>find</code> functions use the
“divide-and-conquer” strategy: compare the target key with the key at
the current node, and recursively search in the appropriate subtree. The
<code>add</code> function searches the tree in the same way but copies
every node along the path to create the new tree (since we’re using
immutable data structures).</p>
<p>The <code>remove</code> function is trickier. When removing a node
with two children, we need to replace it with another value that
maintains the ordering property. The <code>split_rightmost</code> helper
function finds and removes the rightmost (largest) element from a
subtree – this element is guaranteed to be smaller than everything in
the right subtree and larger than everything remaining in the left
subtree, making it the perfect replacement.</p>
<h3 id="implementing-maps-red-black-trees">5.10 Implementing Maps:
Red-Black Trees</h3>
<p>The fatal weakness of ordinary binary search trees is that they can
become unbalanced. If keys arrive in sorted order, each insertion adds a
node at the bottom of a long chain, and we lose the logarithmic
performance guarantee. How can we maintain balance automatically?</p>
<p>This section is based on Wikipedia’s <a
href="http://en.wikipedia.org/wiki/Red-black_tree">Red-black tree
article</a>, Chris Okasaki’s “Purely Functional Data Structures” and
Matt Might’s excellent blog post on <a
href="http://matt.might.net/articles/red-black-delete/">red-black tree
deletion</a>.</p>
<p>Binary search trees are good when we encounter keys in random order,
because the cost of operations is limited by the depth of the tree which
is small relative to the number of nodes… unless the tree grows
unbalanced achieving large depth (which means there are sibling subtrees
of vastly different sizes on some path).</p>
<p>To remedy this, we <em>rebalance</em> the tree while building it –
i.e., while adding elements. The key insight is to detect when the tree
is becoming unbalanced and perform local rotations to restore
balance.</p>
<p>In <em>red-black trees</em> we achieve balance by: 1. Remembering one
of two colors (red or black) with each node 2. Keeping the same number
of black nodes on every path from the root to a leaf 3. Not allowing a
red node to have a red child</p>
<p>These invariants together guarantee that the tree cannot become too
unbalanced: the depth is at most twice the depth of a perfectly balanced
tree with the same number of nodes. Why? The “black height” (number of
black nodes on any root-to-leaf path) is the same everywhere, and red
nodes can only appear between black nodes, so the longest path can have
at most twice as many nodes as the shortest.</p>
<h4 id="b-trees-of-order-4-2-3-4-trees">B-trees of Order 4 (2-3-4
Trees)</h4>
<p>To understand where red-black trees come from, it helps to first
understand 2-3-4 trees (also known as B-trees of order 4).</p>
<p>How can we have perfectly balanced trees without worrying about
having exactly <span class="math inline">2^k - 1</span> elements? The
answer is to allow variable-width nodes. <strong>2-3-4 trees</strong>
can store from 1 to 3 elements in each node and have 2 to 4 subtrees
correspondingly. This flexibility lets us maintain perfect balance!</p>
<ul>
<li>A <strong>2-node</strong> contains one element and has two
children</li>
<li>A <strong>3-node</strong> contains two elements and has three
children</li>
<li>A <strong>4-node</strong> contains three elements and has four
children</li>
</ul>
<p>To insert into a 2-3-4 tree, we descend toward the appropriate leaf
position. But if we encounter a full node (4-node) along the way, we
“split” it: move the middle element up to the parent and split the
remaining two elements into separate 2-nodes. This maintains perfect
balance at all times – all leaves are at the same depth.</p>
<p>The remarkable fact is that red-black trees are just a clever way to
represent 2-3-4 trees as binary trees! To represent a 2-3-4 tree as a
binary tree with one element per node, we color the “primary” element of
each node black (the middle element of a 4-node, or the first element of
a 2-/3-node) and make it the parent of its neighbor elements colored
red. The red elements then become parents of the original subtrees. This
correspondence provides the deep intuition behind red-black trees: the
colors encode the structure of the underlying 2-3-4 tree.</p>
<h4 id="red-black-trees-without-deletion">Red-Black Trees, Without
Deletion</h4>
<p>Now let us implement red-black trees in OCaml. Red-black trees
maintain two invariants:</p>
<p><strong>Invariant 1.</strong> No red node has a red child. (No two
consecutive red nodes on any path.)</p>
<p><strong>Invariant 2.</strong> Every path from the root to an empty
node contains the same number of black nodes. (The “black height” is
uniform.)</p>
<p>For simplicity, we first implement red-black tree based <em>sets</em>
(not maps) without deletion. The implementation proceeds almost exactly
like for unbalanced binary search trees; we only need to add code to
restore the invariants after each insertion.</p>
<p>The beautiful insight of Okasaki’s approach is that by keeping
balance at each step of constructing a node, it is enough to check
<em>locally</em> (around the root of the subtree) whether a violation
has occurred. We never need to examine the entire tree. For an
understandable implementation of deletion, we need to introduce more
colors – see Matt Might’s post for details.</p>
<div class="sourceCode" id="cb120"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> color = R | B</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a><span class="kw">type</span> &#39;a t = E | T <span class="kw">of</span> color * &#39;a t * &#39;a * &#39;a t</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> empty = E</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> member x m =                     <span class="co">(* Like in unbalanced binary search tree. *)</span></span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">match</span> m <span class="kw">with</span></span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a>  | E -&gt; <span class="kw">false</span></span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a>  | T (_, _, y, _) <span class="kw">when</span> x = y -&gt; <span class="kw">true</span></span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a>  | T (_, a, y, _) <span class="kw">when</span> x &lt; y -&gt; member x a</span>
<span id="cb120-11"><a href="#cb120-11" aria-hidden="true" tabindex="-1"></a>  | T (_, _, _, b) -&gt; member x b</span>
<span id="cb120-12"><a href="#cb120-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-13"><a href="#cb120-13" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> balance = <span class="kw">function</span>                   <span class="co">(* Restoring the invariants. *)</span></span>
<span id="cb120-14"><a href="#cb120-14" aria-hidden="true" tabindex="-1"></a>  | B, T (R, T (R,a,x,b), y, c), z, d    <span class="co">(* On next figure: left, *)</span></span>
<span id="cb120-15"><a href="#cb120-15" aria-hidden="true" tabindex="-1"></a>  | B, T (R, a, x, T (R,b,y,c)), z, d    <span class="co">(* top, *)</span></span>
<span id="cb120-16"><a href="#cb120-16" aria-hidden="true" tabindex="-1"></a>  | B, a, x, T (R, T (R,b,y,c), z, d)    <span class="co">(* bottom, *)</span></span>
<span id="cb120-17"><a href="#cb120-17" aria-hidden="true" tabindex="-1"></a>  | B, a, x, T (R, b, y, T (R,c,z,d))    <span class="co">(* right, *)</span></span>
<span id="cb120-18"><a href="#cb120-18" aria-hidden="true" tabindex="-1"></a>      -&gt; T (R, T (B,a,x,b), y, T (B,c,z,d))    <span class="co">(* center tree. *)</span></span>
<span id="cb120-19"><a href="#cb120-19" aria-hidden="true" tabindex="-1"></a>  | color, a, x, b -&gt; T (color, a, x, b)       <span class="co">(* We allow red-red violation for now. *)</span></span>
<span id="cb120-20"><a href="#cb120-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-21"><a href="#cb120-21" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> insert x s =</span>
<span id="cb120-22"><a href="#cb120-22" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">rec</span> ins = <span class="kw">function</span>                 <span class="co">(* Like in unbalanced binary search tree, *)</span></span>
<span id="cb120-23"><a href="#cb120-23" aria-hidden="true" tabindex="-1"></a>    | E -&gt; T (R, E, x, E)                <span class="co">(* but fix violation above created node. *)</span></span>
<span id="cb120-24"><a href="#cb120-24" aria-hidden="true" tabindex="-1"></a>    | T (color, a, y, b) <span class="kw">as</span> s -&gt;</span>
<span id="cb120-25"><a href="#cb120-25" aria-hidden="true" tabindex="-1"></a>        <span class="kw">if</span> x &lt; y <span class="kw">then</span> balance (color, ins a, y, b)</span>
<span id="cb120-26"><a href="#cb120-26" aria-hidden="true" tabindex="-1"></a>        <span class="kw">else</span> <span class="kw">if</span> x &gt; y <span class="kw">then</span> balance (color, a, y, ins b)</span>
<span id="cb120-27"><a href="#cb120-27" aria-hidden="true" tabindex="-1"></a>        <span class="kw">else</span> s</span>
<span id="cb120-28"><a href="#cb120-28" aria-hidden="true" tabindex="-1"></a>  <span class="kw">in</span></span>
<span id="cb120-29"><a href="#cb120-29" aria-hidden="true" tabindex="-1"></a>  <span class="kw">match</span> ins s <span class="kw">with</span>                       <span class="co">(* We could still have red-red violation at root, *)</span></span>
<span id="cb120-30"><a href="#cb120-30" aria-hidden="true" tabindex="-1"></a>  | T (_, a, y, b) -&gt; T (B, a, y, b)     <span class="co">(* fixed by coloring it black. *)</span></span>
<span id="cb120-31"><a href="#cb120-31" aria-hidden="true" tabindex="-1"></a>  | E -&gt; <span class="dt">failwith</span> <span class="st">&quot;insert: impossible&quot;</span></span></code></pre></div>
<p>The <code>balance</code> function is the heart of the algorithm. It
handles four cases where a red-red violation occurs (a red node with a
red child). The four cases correspond to different positions of the
violation:</p>
<ul>
<li>A red left child with a red left grandchild</li>
<li>A red left child with a red right grandchild</li>
<li>A red right child with a red left grandchild</li>
<li>A red right child with a red right grandchild</li>
</ul>
<p>In each case, we perform a “rotation” that restructures the tree to
eliminate the violation while maintaining the binary search tree
property. Remarkably, all four cases produce the same balanced result: a
red root with two black children, with the subtrees <code>a</code>,
<code>b</code>, <code>c</code>, <code>d</code> properly distributed.</p>
<p>The <code>insert</code> function works like insertion into an
ordinary binary search tree, but calls <code>balance</code> after each
recursive step to fix any violations that may have been introduced. New
nodes are always created red (which might create a red-red violation
that <code>balance</code> will fix). At the very end, we color the root
black – this can never create a violation and ensures the root is always
black.</p>
<h3 id="exercises-4">Exercises</h3>
<p><strong>Exercise 1.</strong> Derive the equations and solve them to
find the type for:</p>
<div class="sourceCode" id="cb121"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> cadr l = <span class="dt">List</span>.hd (<span class="dt">List</span>.tl l) <span class="kw">in</span> cadr (<span class="dv">1</span>::<span class="dv">2</span>::[]), cadr (<span class="kw">true</span>::<span class="kw">false</span>::[])</span></code></pre></div>
<p>in environment <span class="math inline">\Gamma = \{ \text{List.hd} :
\forall \alpha . \alpha \ \text{list} \rightarrow \alpha ;
\text{List.tl} : \forall \alpha . \alpha \ \text{list} \rightarrow
\alpha \ \text{list} \}</span>. You can take “shortcuts” if it is too
many equations to write down.</p>
<p><strong>Exercise 2.</strong> <em>Terms</em> <span
class="math inline">t_1, t_2, \ldots \in T(\Sigma, X)</span> are built
out of variables <span class="math inline">x, y, \ldots \in X</span> and
function symbols <span class="math inline">f, g, \ldots \in
\Sigma</span> the way you build values out of functions:</p>
<ul>
<li><span class="math inline">X \subset T(\Sigma, X)</span> – variables
are terms; usually an infinite set,</li>
<li>for terms <span class="math inline">t_1, \ldots, t_n \in T(\Sigma,
X)</span> and a function symbol <span class="math inline">f \in
\Sigma_n</span> of arity <span class="math inline">n</span>, <span
class="math inline">f(t_1, \ldots, t_n) \in T(\Sigma, X)</span> – bigger
terms arise from applying function symbols to smaller terms; <span
class="math inline">\Sigma = \dot{\cup}_n \Sigma_n</span> is called a
signature.</li>
</ul>
<p>In OCaml, we can define terms as:
<code>type term = V of string | T of string * term list</code>, where
for example <code>V("x")</code> is a variable <span
class="math inline">x</span> and <code>T("f", [V("x"); V("y")])</code>
is the term <span class="math inline">f(x, y)</span>.</p>
<p>By <em>substitutions</em> <span class="math inline">\sigma, \rho,
\ldots</span> we mean finite sets of variable-term pairs which we can
write as <span class="math inline">\{x_1 \mapsto t_1, \ldots, x_k
\mapsto t_k\}</span> or <span class="math inline">[x_1 := t_1; \ldots;
x_k := t_k]</span>, but also functions from terms to terms <span
class="math inline">\sigma : T(\Sigma, X) \rightarrow T(\Sigma,
X)</span> related to the pairs as follows: if <span
class="math inline">\sigma = \{x_1 \mapsto t_1, \ldots, x_k \mapsto
t_k\}</span>, then</p>
<ul>
<li><span class="math inline">\sigma(x_i) = t_i</span> for <span
class="math inline">x_i \in \{x_1, \ldots, x_k\}</span>,</li>
<li><span class="math inline">\sigma(x) = x</span> for <span
class="math inline">x \in X \setminus \{x_1, \ldots, x_k\}</span>,</li>
<li><span class="math inline">\sigma(f(t_1, \ldots, t_n)) =
f(\sigma(t_1), \ldots, \sigma(t_n))</span>.</li>
</ul>
<p>In OCaml, we can define substitutions <span
class="math inline">\sigma</span> as:
<code>type subst = (string * term) list</code>, together with a function
<code>apply : subst -&gt; term -&gt; term</code> which computes <span
class="math inline">\sigma(\cdot)</span>.</p>
<p>We say that a substitution <span class="math inline">\sigma</span> is
<em>more general</em> than all substitutions <span
class="math inline">\rho \circ \sigma</span>, where <span
class="math inline">(\rho \circ \sigma)(x) = \rho(\sigma(x))</span>. In
type inference, we are interested in most general solutions.</p>
<p>A <em>unification problem</em> is a finite set of equations <span
class="math inline">S = \{s_1 =^? t_1, \ldots, s_n =^? t_n\}</span>. A
solution, or <em>unifier</em> of <span class="math inline">S</span>, is
a substitution <span class="math inline">\sigma</span> such that <span
class="math inline">\sigma(s_i) = \sigma(t_i)</span> for <span
class="math inline">i = 1, \ldots, n</span>. A <em>most general
unifier</em>, or <em>MGU</em>, is a most general such substitution.</p>
<ol type="1">
<li><p>Implement an algorithm that, given a set of equations represented
as a list of pairs of terms, computes an idempotent most general unifier
of the equations.</p></li>
<li><p>(Ex. 4.22 in Franz Baader and Tobias Nipkow “Term Rewriting and
All That”, p. 82.) Modify the implementation of unification to achieve
linear space complexity by working with what could be called iterated
substitutions.</p></li>
</ol>
<p><strong>Exercise 3.</strong></p>
<ol type="1">
<li>What does it mean that an implementation has junk (as an algebraic
structure for a given signature)? Is it bad?</li>
<li>Define a monomorphic algebraic specification (other than, but
similar to, <span class="math inline">\text{nat}_p</span> or <span
class="math inline">\text{string}_p</span>, some useful data type).</li>
<li>Discuss an example of a (monomorphic) algebraic specification where
it would be useful to drop some axioms (giving up monomorphicity) to
allow more efficient implementations.</li>
</ol>
<p><strong>Exercise 4.</strong></p>
<ol type="1">
<li><p>Does the example <code>ListMap</code> meet the requirements of
the algebraic specification for maps? Hint: here is the definition of
<code>List.remove_assoc</code>; <code>compare a x</code> equals
<code>0</code> if and only if <code>a = x</code>.</p>
<div class="sourceCode" id="cb122"><pre
class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> <span class="kw">rec</span> remove_assoc x = <span class="kw">function</span></span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>  | [] -&gt; []</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>  | (a, b <span class="kw">as</span> pair) :: l -&gt;</span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a>      <span class="kw">if</span> <span class="dt">compare</span> a x = <span class="dv">0</span> <span class="kw">then</span> l <span class="kw">else</span> pair :: remove_assoc x l</span></code></pre></div></li>
<li><p>Trick question: what is the computational complexity of
<code>ListMap</code> or <code>TrivialMap</code>?</p></li>
<li><p>(*) The implementation <code>MyListMap</code> is inefficient: it
performs a lot of copying and is not tail-recursive. Optimize it
(without changing the type definition).</p></li>
<li><p>Add (and specify) <span class="math inline">\text{isEmpty} :
(\alpha, \beta) \ \text{map} \rightarrow \text{bool}</span> to the
example algebraic specification of maps without increasing the burden on
its implementations. Hint: equational reasoning might be not enough;
consider an equivalence relation <span
class="math inline">\approx</span> meaning “have the same
keys”.</p></li>
</ol>
<p><strong>Exercise 5.</strong> Design an algebraic specification and
write a signature for first-in-first-out queues. Provide two
implementations: one straightforward using a list, and another one using
two lists: one for freshly added elements providing efficient queueing
of new elements, and “reversed” one for efficient popping of old
elements.</p>
<p><strong>Exercise 6.</strong> Design an algebraic specification and
write a signature for sets. Provide two implementations: one
straightforward using a list, and another one using a map into the unit
type.</p>
<p><strong>Exercise 7.</strong></p>
<ol type="1">
<li><p>(Ex. 2.2 in Chris Okasaki “Purely Functional Data Structures”) In
the worst case, <code>member</code> performs approximately <span
class="math inline">2d</span> comparisons, where <span
class="math inline">d</span> is the depth of the tree. Rewrite
<code>member</code> to take no more than <span class="math inline">d +
1</span> comparisons by keeping track of a candidate element that
<em>might</em> be equal to the query element (say, the last element for
which <span class="math inline">&lt;</span> returned false) and checking
for equality only when you hit the bottom of the tree.</p></li>
<li><p>(Ex. 3.10 in Chris Okasaki “Purely Functional Data Structures”)
The <code>balance</code> function currently performs several unnecessary
tests: when e.g. <code>ins</code> recurses on the left child, there are
no violations on the right child.</p>
<ul>
<li>Split <code>balance</code> into <code>lbalance</code> and
<code>rbalance</code> that test for violations of left resp. right child
only. Replace calls to <code>balance</code> appropriately.</li>
<li>One of the remaining tests on grandchildren is also unnecessary.
Rewrite <code>ins</code> so that it never tests the color of nodes not
on the search path.</li>
</ul></li>
</ol>
<p><strong>Exercise 8.</strong> (*) Implement maps (i.e. write a module
for the map signature) based on AVL trees. See
<code>http://en.wikipedia.org/wiki/AVL_tree</code>.</p>
<h2 id="chapter-6-folding-and-backtracking">Chapter 6: Folding and
Backtracking</h2>
<p>This chapter explores two fundamental programming paradigms in
functional programming: <strong>folding</strong> (also known as
reduction) and <strong>backtracking</strong>. We begin with the classic
<code>map</code> and <code>fold</code> higher-order functions, examine
how they generalize to trees and other data structures, then move on to
solving puzzles using backtracking with lists.</p>
<p>The material in this chapter draws from Martin Odersky’s “Functional
Programming Fundamentals,” Ralf Laemmel’s “Going Bananas,” Graham
Hutton’s “Programming in Haskell” (Chapter 11 on the Countdown Problem),
and Tomasz Wierzbicki’s Honey Islands Puzzle Solver.</p>
<h3 id="basic-generic-list-operations">6.1 Basic Generic List
Operations</h3>
<p>Functional programming emphasizes identifying common patterns and
abstracting them into reusable higher-order functions. Rather than
writing similar code repeatedly, we extract the common structure into a
single generic function. Let us see how this principle works in practice
through two motivating examples.</p>
<h4 id="the-map-function">The <code>map</code> Function</h4>
<p>How do we print a comma-separated list of integers? The
<code>String</code> module provides a function that joins strings with a
separator:</p>
<pre><code>val concat : string -&gt; string list -&gt; string</code></pre>
<p>But <code>String.concat</code> works on strings, not integers. So
first, we need to convert numbers into strings:</p>
<p>```ocaml env=ch6 let rec strings_of_ints = function | [] -&gt; [] |
hd::tl -&gt; string_of_int hd :: strings_of_ints tl</p>
<p>let comma_sep_ints = String.concat “,” -| strings_of_ints</p>
<pre><code>
Here is another common task: how do we sort strings from shortest to longest? We can pair each string with its length and then sort by the first component. First, let us compute the lengths:

```ocaml env=ch6
let rec strings_lengths = function
  | [] -&gt; []
  | hd::tl -&gt; (String.length hd, hd) :: strings_lengths tl

let by_size = List.sort compare -| strings_lengths</code></pre>
<p>Now, look carefully at <code>strings_of_ints</code> and
<code>strings_lengths</code>. Do you notice the common structure? Both
functions traverse a list and transform each element independently – one
applies <code>string_of_int</code>, the other applies a function that
pairs a string with its length. The recursive structure is identical;
only the transformation differs.</p>
<p>This is our cue to <em>extract the common pattern</em> into a generic
higher-order function. We call it <code>map</code>:</p>
<p><code>ocaml env=ch6 let rec list_map f = function   | [] -&gt; []   | hd::tl -&gt; f hd :: list_map f tl</code></p>
<p>Now we can rewrite our functions more concisely:</p>
<p>```ocaml env=ch6 let comma_sep_ints = String.concat “,” -| list_map
string_of_int</p>
<p>let by_size = List.sort compare -| list_map (fun s -&gt;
String.length s, s)</p>
<pre><code>
#### The `fold` Function

Now let us consider a different kind of pattern. How do we sum all the elements of a list?

```ocaml env=ch6
let rec balance = function
  | [] -&gt; 0
  | hd::tl -&gt; hd + balance tl</code></pre>
<p>And how do we multiply all the elements together (perhaps to compute
a cumulative ratio)?</p>
<p><code>ocaml env=ch6 let rec total_ratio = function   | [] -&gt; 1.   | hd::tl -&gt; hd *. total_ratio tl</code></p>
<p>Again, the recursive structure is the same. In both cases, we combine
each element with the result of processing the rest of the list. The
differences are: (1) what we return for the empty list (the “base case”
or “identity element”), and (2) how we combine the head with the
recursive result. This pattern is called <strong>folding</strong>:</p>
<p><code>ocaml env=ch6 let rec list_fold f base = function   | [] -&gt; base   | hd::tl -&gt; f hd (list_fold f base tl)</code></p>
<p><strong>Important:</strong> Note that <code>list_fold f base l</code>
equals <code>List.fold_right f l base</code>. The OCaml standard library
uses a different argument order, so be careful when using
<code>List.fold_right</code>.</p>
<p>The key insight is understanding the fundamental difference between
<code>map</code> and <code>fold</code>:</p>
<ul>
<li><strong><code>map</code></strong> alters the <em>contents</em> of a
data structure without changing its shape. The output list has the same
length as the input; we merely transform each element.</li>
<li><strong><code>fold</code></strong> <em>collapses</em> a data
structure down to a single value, using the structure itself as
scaffolding for the computation.</li>
</ul>
<p>Visually, consider what happens to the list
<code>[a; b; c; d]</code>:</p>
<ul>
<li><code>map f</code> transforms: <code>[a; b; c; d]</code> becomes
<code>[f a; f b; f c; f d]</code> – same structure, different
contents</li>
<li><code>fold f accu</code> collapses: <code>[a; b; c; d]</code>
becomes <code>f a (f b (f c (f d accu)))</code> – structure disappears,
single value remains</li>
</ul>
<h3 id="making-fold-tail-recursive">6.2 Making Fold Tail-Recursive</h3>
<p>Our <code>list_fold</code> function above is not tail-recursive: it
builds up a chain of deferred <code>f</code> applications on the call
stack. For very long lists, this can cause stack overflow. Can we make
folding tail-recursive?</p>
<p>Let us investigate some tail-recursive list functions to find a
pattern. Consider reversing a list:</p>
<p><code>ocaml env=ch6 let rec list_rev acc = function   | [] -&gt; acc   | hd::tl -&gt; list_rev (hd::acc) tl</code></p>
<p>The key technique here is the <em>accumulator</em> parameter
<code>acc</code>. Instead of building up work to do after the recursive
call returns, we do the work <em>before</em> the recursive call and pass
the intermediate result along.</p>
<p>Here is another example – computing an average by tracking both the
running sum and the count:</p>
<p><code>ocaml env=ch6 let rec average (sum, tot) = function   | [] when tot = 0. -&gt; 0.   | [] -&gt; sum /. tot   | hd::tl -&gt; average (hd +. sum, 1. +. tot) tl</code></p>
<p>Notice how these functions process elements from left to right,
threading an accumulator through the computation. This is the pattern of
<code>fold_left</code>:</p>
<p><code>ocaml env=ch6 let rec fold_left f accu = function   | [] -&gt; accu   | a::l -&gt; fold_left f (f accu a) l</code></p>
<p>With <code>fold_left</code>, expressing our earlier functions becomes
straightforward – we hide the accumulator inside the initial value:</p>
<p>```ocaml env=ch6 let list_rev l = fold_left (fun t h -&gt; h::t) []
l</p>
<p>let average = fold_left (fun (sum, tot) e -&gt; sum +. e, 1. +. tot)
(0., 0.)</p>
<pre><code>
Note that the `average` example is slightly trickier than `list_rev` because we need to track two values (sum and count) rather than one.

**Why the names `fold_right` and `fold_left`?** The names reflect the associativity of the combining operation:

- `fold_right f` makes `f` **right associative**, like the list constructor `::`:
  `List.fold_right f [a1; ...; an] b` is `f a1 (f a2 (... (f an b) ...))`

- `fold_left f` makes `f` **left associative**, like function application:
  `List.fold_left f a [b1; ...; bn]` is `f (... (f (f a b1) b2) ...) bn`

This &quot;backward&quot; structure of `fold_left` can be visualized by comparing the shape of the input list with the shape of the computation tree. The input list has a right-leaning spine (because `::` associates to the right), while `fold_left` produces a computation tree with a left-leaning spine:

::: {.figure}</code></pre>
<pre><code>Input list              Result computation

    ::                         f
   /  \                       / \
  a    ::                    f   d
      /  \                  / \
     b    ::               f   c
         /  \             / \
        c    ::          f   b
            /  \        / \
           d    []  accu   a</code></pre>
<pre><code>**Figure: List spine vs. fold_left computation tree**
:::

This reversal of structure is why `fold_left` naturally reverses lists when the combining operation is `cons`.

#### Useful Derived Functions

Many common list operations can be expressed elegantly using folds. List filtering selects elements satisfying a predicate -- naturally expressed using `fold_right` to preserve order:

```ocaml env=ch6
let list_filter p l =
  List.fold_right (fun h t -&gt; if p h then h::t else t) l []</code></pre>
<p>When we need a tail-recursive map and can tolerate reversed output,
<code>fold_left</code> gives us <code>rev_map</code>:</p>
<p><code>ocaml env=ch6 let list_rev_map f l =   List.fold_left (fun t h -&gt; f h :: t) [] l</code></p>
<h3 id="map-and-fold-for-trees-and-other-structures">6.3 Map and Fold
for Trees and Other Structures</h3>
<p>The <code>map</code> and <code>fold</code> patterns are not limited
to lists. They apply to any recursive data structure. The key insight is
that <code>map</code> preserves structure while transforming contents,
and <code>fold</code> collapses structure into a single value.</p>
<h4 id="binary-trees">Binary Trees</h4>
<p>Mapping binary trees is straightforward:</p>
<p>```ocaml env=ch6 type ’a btree = Empty | Node of ’a * ’a btree * ’a
btree</p>
<p>let rec bt_map f = function | Empty -&gt; Empty | Node (e, l, r)
-&gt; Node (f e, bt_map f l, bt_map f r)</p>
<p>let test = Node (3, Node (5, Empty, Empty), Node (7, Empty, Empty))
let _ = bt_map ((+) 1) test</p>
<pre><code>
**A note on terminology:** The `map` and `fold` functions we define here preserve and respect the structure of data. They are different from the `map` and `fold` operations you might find in abstract data type container libraries, which often behave more like `List.rev_map` and `List.fold_left` over container elements in arbitrary order. Here we are generalizing `List.map` and `List.fold_right` to other structures.

For binary trees, the most general form of `fold` processes each element together with the partial results already computed for its subtrees:

```ocaml env=ch6
let rec bt_fold f base = function
  | Empty -&gt; base
  | Node (e, l, r) -&gt;
    f e (bt_fold f base l) (bt_fold f base r)</code></pre>
<p>Here are two examples showing how <code>bt_fold</code> can compute
different properties of a tree:</p>
<p><code>ocaml env=ch6 let sum_els = bt_fold (fun i l r -&gt; i + l + r) 0 let depth t = bt_fold (fun _ l r -&gt; 1 + max l r) 1 t</code></p>
<p>The first computes the sum of all elements (the combining function
adds the current element to the sums of both subtrees). The second
computes the depth – we ignore the element value and take the maximum
depth of the subtrees, adding 1 for the current level.</p>
<h4 id="more-complex-structures-expressions">More Complex Structures:
Expressions</h4>
<p>Real-world data types often have more than two cases. To demonstrate
map and fold for more complex structures, let us recall the expression
type from Chapter 3:</p>
<p><code>ocaml env=ch6 type expression =     Const of float   | Var of string   | Sum of expression * expression    (* e1 + e2 *)   | Diff of expression * expression   (* e1 - e2 *)   | Prod of expression * expression   (* e1 * e2 *)   | Quot of expression * expression   (* e1 / e2 *)</code></p>
<p>The multitude of cases makes this datatype harder to work with than
binary trees. Fortunately, OCaml’s <em>or-patterns</em> help us handle
multiple similar cases together:</p>
<p><code>ocaml env=ch6 let rec vars = function   | Const _ -&gt; []   | Var x -&gt; [x]   | Sum (a,b) | Diff (a,b) | Prod (a,b) | Quot (a,b) -&gt;     vars a @ vars b</code></p>
<p>For a generic <code>map</code> and <code>fold</code> over
expressions, we need to specify behavior for each case. Since there are
many cases, we pack all the behaviors into records. This way, we can
define default behaviors and then override just the cases we care
about:</p>
<p>```ocaml env=ch6 type expression_map = { map_const : float -&gt;
expression; map_var : string -&gt; expression; map_sum : expression
-&gt; expression -&gt; expression; map_diff : expression -&gt;
expression -&gt; expression; map_prod : expression -&gt; expression
-&gt; expression; map_quot : expression -&gt; expression -&gt;
expression; }</p>
<p>(<em> Note: In expression_fold, we use ’a instead of expression
because fold produces values of arbitrary type, not necessarily
expressions. </em>) type ’a expression_fold = { fold_const : float -&gt;
’a; fold_var : string -&gt; ’a; fold_sum : ’a -&gt; ’a -&gt; ’a;
fold_diff : ’a -&gt; ’a -&gt; ’a; fold_prod : ’a -&gt; ’a -&gt; ’a;
fold_quot : ’a -&gt; ’a -&gt; ’a; }</p>
<pre><code>
Now we define standard &quot;default&quot; behaviors. The `identity_map` reconstructs the same expression (useful as a starting point when we only want to change one case), and `make_fold` creates a fold where all binary operators behave the same:

```ocaml env=ch6
let identity_map = {
  map_const = (fun c -&gt; Const c);
  map_var = (fun x -&gt; Var x);
  map_sum = (fun a b -&gt; Sum (a, b));
  map_diff = (fun a b -&gt; Diff (a, b));
  map_prod = (fun a b -&gt; Prod (a, b));
  map_quot = (fun a b -&gt; Quot (a, b));
}

let make_fold op base = {
  fold_const = (fun _ -&gt; base);
  fold_var = (fun _ -&gt; base);
  fold_sum = op; fold_diff = op;
  fold_prod = op; fold_quot = op;
}</code></pre>
<p>The actual <code>map</code> and <code>fold</code> functions:</p>
<p>```ocaml env=ch6 let rec expr_map emap = function | Const c -&gt;
emap.map_const c | Var x -&gt; emap.map_var x | Sum (a,b) -&gt;
emap.map_sum (expr_map emap a) (expr_map emap b) | Diff (a,b) -&gt;
emap.map_diff (expr_map emap a) (expr_map emap b) | Prod (a,b) -&gt;
emap.map_prod (expr_map emap a) (expr_map emap b) | Quot (a,b) -&gt;
emap.map_quot (expr_map emap a) (expr_map emap b)</p>
<p>let rec expr_fold efold = function | Const c -&gt; efold.fold_const c
| Var x -&gt; efold.fold_var x | Sum (a,b) -&gt; efold.fold_sum
(expr_fold efold a) (expr_fold efold b) | Diff (a,b) -&gt;
efold.fold_diff (expr_fold efold a) (expr_fold efold b) | Prod (a,b)
-&gt; efold.fold_prod (expr_fold efold a) (expr_fold efold b) | Quot
(a,b) -&gt; efold.fold_quot (expr_fold efold a) (expr_fold efold b)</p>
<pre><code>
Now here is the payoff. Using OCaml&#39;s `{record with field = value}` syntax, we can easily customize behaviors for specific uses by starting from the defaults and overriding just what we need:

```ocaml env=ch6
let prime_vars = expr_map
  {identity_map with map_var = fun x -&gt; Var (x ^ &quot;&#39;&quot;)}

let subst s =
  let apply x = try List.assoc x s with Not_found -&gt; Var x in
  expr_map {identity_map with map_var = apply}

let vars =
  expr_fold {(make_fold (@) []) with fold_var = fun x -&gt; [x]}

let size = expr_fold (make_fold (fun a b -&gt; 1 + a + b) 1)

let eval env = expr_fold {
  fold_const = id;
  fold_var = (fun x -&gt; List.assoc x env);
  fold_sum = (+.); fold_diff = (-.);
  fold_prod = ( *.); fold_quot = (/.);
}</code></pre>
<h3 id="point-free-programming">6.4 Point-Free Programming</h3>
<p>In 1977/78, John Backus – the designer of FORTRAN and BNF notation –
introduced <strong>FP</strong>, the first <em>function-level
programming</em> language. This was a radical departure from the
prevailing style: rather than manipulating variables and values,
programs were built entirely by combining functions. Over the next
decade, FP evolved into the <strong>FL</strong> language.</p>
<p>The philosophy behind function-level programming is captured in this
quote:</p>
<blockquote>
<p>“Clarity is achieved when programs are written at the function level
– that is, by putting together existing programs to form new ones,
rather than by manipulating objects and then abstracting from those
objects to produce programs.” – <em>The FL Project: The Design of a
Functional Language</em></p>
</blockquote>
<p>This style is sometimes called <strong>point-free</strong> or
<strong>tacit</strong> programming, because we never mention the
“points” (values) that functions operate on – we only talk about the
functions themselves and how they combine.</p>
<p>To write in this style, we need a toolkit of
<strong>combinators</strong> – higher-order functions that combine other
functions. Here are some common ones, similar to what you will find in
the <em>OCaml Batteries</em> library:</p>
<p><code>ocaml env=ch6 let const x _ = x let ( |- ) f g x = g (f x)          (* forward composition *) let ( -| ) f g x = f (g x)          (* backward composition *) let flip f x y = f y x let ( *** ) f g = fun (x,y) -&gt; (f x, g y) let ( &amp;&amp;&amp; ) f g = fun x -&gt; (f x, g x) let first f x = fst (f x) let second f x = snd (f x) let curry f x y = f (x,y) let uncurry f (x,y) = f x y</code></p>
<p>One way to understand point-free programming is to visualize the flow
of computation as a circuit. Values flow through the circuit, being
transformed by functions at each node. Cross-sections of the circuit can
be represented as tuples of intermediate values.</p>
<p>Consider this simple function that converts a character and an
integer to a string:</p>
<p><code>ocaml env=ch6 let print2 c i =   let a = Char.escaped c in   let b = string_of_int i in   a ^ b</code></p>
<p>We can visualize this as a circuit: <code>(c, i)</code> enters,
<code>c</code> flows through <code>Char.escaped</code>, <code>i</code>
flows through <code>string_of_int</code>, and the results meet at
<code>(^)</code>. In point-free style, we express this directly:</p>
<p><code>ocaml env=ch6 let print2 = curry   ((Char.escaped *** string_of_int) |- uncurry (^))</code></p>
<p>Here <code>***</code> applies two functions in parallel to the
components of a pair, <code>|-</code> is forward composition,
<code>uncurry</code> converts a curried function to take a pair, and
<code>curry</code> converts back.</p>
<p><strong>Why the name “currying”?</strong> Converting a C/Pascal-style
function (that takes all arguments as a tuple) into one that takes
arguments one at a time is called <em>currying</em>, after the logician
Haskell Brooks Curry. Since OCaml functions naturally take arguments one
at a time, we often need <code>uncurry</code> to interface with
tuple-based operations, and <code>curry</code> to convert back.</p>
<p>Another approach to point-free style avoids tuples entirely, using
function composition, <code>flip</code>, and the <strong>S</strong>
combinator:</p>
<p><code>ocaml env=ch6 let s x y z = x z (y z)</code></p>
<p>The S combinator allows us to pass one argument to two different
functions and combine their results. This can bring a particular
argument of a function to the “front” and pass it to another
function.</p>
<p>Here is an extended example showing step-by-step transformation of a
filter-map function into point-free style:</p>
<p><code>ocaml env=ch6 let func2 f g l = List.filter f (List.map g l) (* Step 1: Recognize that filter-after-map is composition *) let func2 f g = (-|) (List.filter f) (List.map g) (* Step 2: Eliminate l by composing with List.map *) let func2 f = (-|) (List.filter f) -| List.map (* Step 3: Rewrite without infix notation to see the structure *) let func2 f = (-|) ((-|) (List.filter f)) List.map (* Step 4: Use flip to rearrange arguments *) let func2 f = flip (-|) List.map ((-|) (List.filter f)) (* Step 5: Factor out f using composition *) let func2 f = (((|-) List.map) -| ((-|) -| List.filter)) f (* Step 6: Finally, f disappears (eta-reduction) *) let func2 = (|-) List.map -| ((-|) -| List.filter)</code></p>
<p>While point-free style can be elegant for simple cases, it can
quickly become obscure. Use it judiciously!</p>
<h3 id="reductions-and-more-higher-order-functions">6.5 Reductions and
More Higher-Order Functions</h3>
<p>Mathematics has a convenient notation for sums over intervals: <span
class="math inline">\sum_{n=a}^{b} f(n)</span>.</p>
<p>Can we express this in OCaml? The challenge is that OCaml does not
have a universal addition operator – <code>+</code> works only on
integers, <code>+.</code> only on floats. So we end up writing two
versions:</p>
<p>```ocaml env=ch6 let rec i_sum_fromto f a b = if a &gt; b then 0 else
f a + i_sum_fromto f (a+1) b</p>
<p>let rec f_sum_fromto f a b = if a &gt; b then 0. else f a +.
f_sum_fromto f (a+1) b</p>
<p>let pi2_over6 = f_sum_fromto (fun i -&gt; 1. /. float_of_int (i*i)) 1
5000</p>
<pre><code>
(The last example computes an approximation to $\pi^2/6$ using the Basel series.)

The natural generalization is to make the combining operation a parameter:

```ocaml env=ch6
let rec op_fromto op base f a b =
  if a &gt; b then base
  else op (f a) (op_fromto op base f (a+1) b)</code></pre>
<h4 id="collecting-results-concat_map">Collecting Results:
concat_map</h4>
<p>Sometimes a function produces not a single result but a
<em>collection</em> of results. In mathematics, such a function is
called a <strong>multifunction</strong> or set-valued function. If we
have a multifunction <span class="math inline">f</span> and want to
apply it to every element of a set <span class="math inline">A</span>,
we take the union of all results:</p>
<p><span class="math display">f(A) = \bigcup_{p \in A} f(p)</span></p>
<p>When we represent sets as lists, “union” becomes “append”. This gives
us the extremely useful <code>concat_map</code> operation:</p>
<p><code>ocaml env=ch6 let rec concat_map f = function   | [] -&gt; []   | a::l -&gt; f a @ concat_map f l</code></p>
<p>For better efficiency on long lists, here is a tail-recursive
version:</p>
<p><code>ocaml env=ch6 let concat_map f l =   let rec cmap_f accu = function     | [] -&gt; accu     | a::l -&gt; cmap_f (List.rev_append (f a) accu) l in   List.rev (cmap_f [] l)</code></p>
<p>The <code>concat_map</code> function is fundamental for backtracking
algorithms. We will use it extensively in the puzzle-solving sections
below.</p>
<h4 id="all-subsequences-of-a-list">All Subsequences of a List</h4>
<p>A classic example of a function that produces multiple results: given
a list, generate all its subsequences (subsets that preserve order). The
idea is simple: for each element, we either include it or exclude
it.</p>
<p><code>ocaml env=ch6 let rec subseqs l =   match l with     | [] -&gt; [[]]     | x::xs -&gt;       let pxs = subseqs xs in       List.map (fun px -&gt; x::px) pxs @ pxs</code></p>
<p>Tail-recursively:</p>
<p>```ocaml env=ch6 let rec rmap_append f accu = function | [] -&gt;
accu | a::l -&gt; rmap_append f (f a :: accu) l</p>
<p>let rec subseqs l = match l with | [] -&gt; [[]] | x::xs -&gt; let
pxs = subseqs xs in rmap_append (fun px -&gt; x::px) pxs pxs</p>
<pre><code>
#### Permutations and Choices

Generating all permutations of a list is another classic combinatorial problem. The key insight is the `interleave` function: given an element `x` and a list, it produces all ways of inserting `x` into the list:

```ocaml env=ch6
let rec interleave x = function
  | [] -&gt; [[x]]                 (* x can only go in one place: by itself *)
  | y::ys -&gt;
    (x::y::ys)                  (* x goes at the front, OR *)
    :: List.map (fun zs -&gt; y::zs) (interleave x ys)  (* x goes somewhere after y *)

let rec perms = function
  | [] -&gt; [[]]                  (* one way to permute empty list: empty list *)
  | x::xs -&gt; concat_map (interleave x) (perms xs)</code></pre>
<p>For example, <code>interleave 1 [2;3]</code> produces
<code>[[1;2;3]; [2;1;3]; [2;3;1]]</code> – all positions where 1 can be
inserted.</p>
<p>For the Countdown problem below, we will need all non-empty
subsequences with all their permutations – that is, all ways of choosing
and ordering elements from a list:</p>
<p><code>ocaml env=ch6 let choices l = concat_map perms (List.filter ((&lt;&gt;) []) (subseqs l))</code></p>
<h3 id="grouping-and-map-reduce">6.6 Grouping and Map-Reduce</h3>
<p>When processing large datasets, it is often useful to organize values
by some property – grouping all items with the same key together, then
processing each group. This pattern is so common it has a name:
<strong>map-reduce</strong> (popularized by Google for distributed
computing).</p>
<h4 id="collecting-by-key">Collecting by Key</h4>
<p>The first step is to collect elements from an association list,
grouping all values that share the same key:</p>
<p><code>ocaml env=ch6 let collect l =   match List.sort (fun x y -&gt; compare (fst x) (fst y)) l with   | [] -&gt; []                                (* Start with associations sorted by key *)   | (k0, v0)::tl -&gt;     let k0, vs, l = List.fold_left       (fun (k0, vs, l) (kn, vn) -&gt;           (* Collect values for current key *)         if k0 = kn then k0, vn::vs, l        (* Same key: add value to current group *)         else kn, [vn], (k0, List.rev vs)::l) (* New key: save current group, start new *)       (k0, [v0], []) tl in                   (* Why reverse? To preserve original order *)     List.rev ((k0, List.rev vs)::l)</code></p>
<p>Now we can group elements by an arbitrary property – we just need to
extract the property as the key:</p>
<p><code>ocaml env=ch6 let group_by p l = collect (List.map (fun e -&gt; p e, e) l)</code></p>
<h4 id="reduction-aggregation">Reduction (Aggregation)</h4>
<p>Grouping alone is often not enough – we want to <em>aggregate</em>
each group into a summary value, like SQL’s <code>SUM</code>,
<code>COUNT</code>, or <code>AVG</code>. This aggregation step is called
<strong>reduction</strong>:</p>
<p><code>ocaml env=ch6 let aggregate_by p red base l =   let ags = group_by p l in   List.map (fun (k, vs) -&gt; k, List.fold_right red vs base) ags</code></p>
<p>Using the <strong>feed-forward</strong> (pipe) operator
<code>let ( |&gt; ) x f = f x</code>:</p>
<p><code>ocaml env=ch6 let aggregate_by p redf base l =   group_by p l   |&gt; List.map (fun (k, vs) -&gt; k, List.fold_right redf vs base)</code></p>
<p>Often it is cleaner to extract both the key and the value we care
about upfront, before grouping. Since we first <strong>map</strong>
elements into key-value pairs, then group and <strong>reduce</strong>,
we call this pattern <code>map_reduce</code>:</p>
<p><code>ocaml env=ch6 let map_reduce mapf redf base l =   List.map mapf l   |&gt; collect   |&gt; List.map (fun (k, vs) -&gt; k, List.fold_right redf vs base)</code></p>
<h4 id="map-reduce-examples">Map-Reduce Examples</h4>
<p>Sometimes our mapping function produces multiple key-value pairs per
input (for example, when processing documents word by word). For this we
use <code>concat_reduce</code>, which uses <code>concat_map</code>
instead of <code>map</code>:</p>
<p><code>ocaml env=ch6 let concat_reduce mapf redf base l =   concat_map mapf l   |&gt; collect   |&gt; List.map (fun (k, vs) -&gt; k, List.fold_right redf vs base)</code></p>
<p><strong>Example 1: Word histogram.</strong> Count how many times each
word appears across a collection of documents:</p>
<p><code>ocaml env=ch6 let histogram documents =   let mapf doc =     Str.split (Str.regexp "[ \t.,;]+") doc     |&gt; List.map (fun word -&gt; word, 1) in   concat_reduce mapf (+) 0 documents</code></p>
<p><strong>Example 2: Inverted index.</strong> Build an index mapping
each word to the list of documents (identified by address) containing
it:</p>
<p>```ocaml env=ch6 let cons hd tl = hd::tl</p>
<p>let inverted_index documents = let mapf (addr, doc) = Str.split
(Str.regexp “[ ,;]+”) doc |&gt; List.map (fun word -&gt; word, addr) in
concat_reduce mapf cons [] documents</p>
<pre><code>
**Example 3: Simple search engine.** Once we have an inverted index, we can search for documents containing all of a given set of words. We need set intersection -- here implemented for sets represented as sorted lists:

```ocaml env=ch6
let intersect xs ys =                       (* Sets as sorted lists *)
  let rec aux acc = function
    | [], _ | _, [] -&gt; acc
    | (x::xs&#39; as xs), (y::ys&#39; as ys) -&gt;
      let c = compare x y in
      if c = 0 then aux (x::acc) (xs&#39;, ys&#39;)
      else if c &lt; 0 then aux acc (xs&#39;, ys)
      else aux acc (xs, ys&#39;) in
  List.rev (aux [] (xs, ys))</code></pre>
<p>Now we can build a simple search function that finds all documents
containing every word in a query:</p>
<p><code>ocaml env=ch6 let search index words =   match List.map (flip List.assoc index) words with   | [] -&gt; []   | idx::idcs -&gt; List.fold_left intersect idx idcs</code></p>
<h3 id="higher-order-functions-for-the-option-type">6.7 Higher-Order
Functions for the Option Type</h3>
<p>The <code>option</code> type is OCaml’s way of representing values
that might be absent. Rather than using null pointers (a common source
of bugs), we explicitly mark possibly-missing values with
<code>Some x</code> or <code>None</code>. Here are some useful
higher-order functions for working with options.</p>
<p>First, applying a function to an optional value:</p>
<p><code>ocaml env=ch6 let map_option f = function   | None -&gt; None   | Some e -&gt; f e</code></p>
<p>Second, mapping a partial function over a list and keeping only the
successful results:</p>
<p><code>ocaml env=ch6 let rec map_some f = function   | [] -&gt; []   | e::l -&gt; match f e with     | None -&gt; map_some f l     | Some r -&gt; r :: map_some f l</code></p>
<p>Tail-recursively:</p>
<p><code>ocaml env=ch6 let map_some f l =   let rec maps_f accu = function     | [] -&gt; accu     | a::l -&gt; maps_f (match f a with None -&gt; accu       | Some r -&gt; r::accu) l in   List.rev (maps_f [] l)</code></p>
<h3 id="the-countdown-problem-puzzle">6.8 The Countdown Problem
Puzzle</h3>
<p>Now we turn to solving puzzles, which will showcase the power of
backtracking with lists. The <strong>Countdown Problem</strong> is a
classic puzzle from a British TV game show:</p>
<ul>
<li>Using a given set of numbers and arithmetic operators +, -, *, /,
construct an expression with a given value.</li>
<li>All numbers, including intermediate results, must be positive
integers.</li>
<li>Each source number can be used at most once.</li>
</ul>
<p><strong>Example:</strong> - Source numbers: 1, 3, 7, 10, 25, 50 -
Target: 765 - One possible solution: (25-10) * (50+1) = 15 * 51 =
765</p>
<p>This example has 780 different solutions! Changing the target to 831
gives an example with no solutions at all.</p>
<p>Let us develop a solver step by step, starting with the data
types.</p>
<h4 id="data-types">Data Types</h4>
<p>```ocaml env=ch6 type op = Add | Sub | Mul | Div</p>
<p>let apply op x y = match op with | Add -&gt; x + y | Sub -&gt; x - y
| Mul -&gt; x * y | Div -&gt; x / y</p>
<p>let valid op x y = match op with | Add -&gt; true | Sub -&gt; x &gt;
y | Mul -&gt; true | Div -&gt; x mod y = 0</p>
<p>type expr = Val of int | App of op * expr * expr</p>
<p>let rec eval = function | Val n -&gt; if n &gt; 0 then Some n else
None | App (o, l, r) -&gt; eval l |&gt; map_option (fun x -&gt; eval r
|&gt; map_option (fun y -&gt; if valid o x y then Some (apply o x y)
else None))</p>
<p>let rec values = function | Val n -&gt; [n] | App (_, l, r) -&gt;
values l @ values r</p>
<p>let solution e ns n = list_diff (values e) ns = [] &amp;&amp;
is_unique (values e) &amp;&amp; eval e = Some n</p>
<pre><code>
#### Brute Force Solution

Our strategy is to generate all possible expressions from the source numbers, then filter for those that evaluate to the target. To build expressions, we need to split the numbers into two groups (for the left and right operands of an operator).

First, a helper to split a list into two non-empty parts in all possible ways:

```ocaml env=ch6
let split l =
  let rec aux lhs acc = function
    | [] | [_] -&gt; []
    | [y; z] -&gt; (List.rev (y::lhs), [z])::acc
    | hd::rhs -&gt;
      let lhs = hd::lhs in
      aux lhs ((List.rev lhs, rhs)::acc) rhs in
  aux [] [] l</code></pre>
<p>We introduce a convenient operator for working with multiple data
sources. The “bind” operator <code>|-&gt;</code> takes a list of values
and a function that produces a list from each value, then concatenates
all results:</p>
<p><code>ocaml env=ch6 let ( |-&gt; ) x f = concat_map f x</code></p>
<p>Now we can generate all expressions from a list of numbers. The
structure elegantly expresses the backtracking search:</p>
<p>```ocaml env=ch6 let combine l r = (* Combine two expressions using
each operator *) List.map (fun o -&gt; App (o, l, r)) [Add; Sub; Mul;
Div]</p>
<p>let rec exprs = function | [] -&gt; [] (* No expressions from empty
list <em>) | [n] -&gt; [Val n] (</em> Single number: just Val n <em>) |
ns -&gt; split ns |-&gt; (fun (ls, rs) -&gt; (</em> For each way to
split numbers… <em>) exprs ls |-&gt; (fun l -&gt; (</em> …for each
expression l from left half… <em>) exprs rs |-&gt; (fun r -&gt; (</em>
…for each expression r from right half… <em>) combine l r))) (</em>
…produce all l op r combinations *)</p>
<pre><code>
Read the nested `|-&gt;` as &quot;for each ... for each ... for each ...&quot;. This is the essence of backtracking: we explore all combinations systematically.

Finally, to find solutions, we try all choices of source numbers (all non-empty subsets with all orderings) and filter for expressions that evaluate to the target:

```ocaml env=ch6
let guard n =
  List.filter (fun e -&gt; eval e = Some n)

let solutions ns n =
  choices ns |-&gt; (fun ns&#39; -&gt;
    exprs ns&#39; |&gt; guard n)</code></pre>
<h4 id="optimization-fuse-generation-with-testing">Optimization: Fuse
Generation with Testing</h4>
<p>The brute force approach generates many invalid expressions (like
<code>5 - 7</code> which gives a negative result, or <code>5 / 3</code>
which is not an integer). We can do better by <em>fusing</em> generation
with evaluation: instead of generating an expression and then checking
if it is valid, we track the value alongside the expression and only
generate valid subexpressions.</p>
<p>The key insight is to work with pairs <code>(e, eval e)</code> so
that only valid subexpressions are ever generated:</p>
<p>```ocaml env=ch6 let combine’ (l, x) (r, y) = [Add; Sub; Mul; Div]
|&gt; List.filter (fun o -&gt; valid o x y) |&gt; List.map (fun o -&gt;
App (o, l, r), apply o x y)</p>
<p>let rec results = function | [] -&gt; [] | [n] -&gt; if n &gt; 0 then
[Val n, n] else [] | ns -&gt; split ns |-&gt; (fun (ls, rs) -&gt;
results ls |-&gt; (fun lx -&gt; results rs |-&gt; (fun ry -&gt; combine’
lx ry)))</p>
<p>let solutions’ ns n = choices ns |-&gt; (fun ns’ -&gt; results ns’
|&gt; List.filter (fun (e, m) -&gt; m = n) |&gt; List.map fst) (*
Discard memorized values *)</p>
<pre><code>
#### Eliminating Symmetric Cases

We can further improve performance by observing that addition and multiplication are commutative: `3 + 5` and `5 + 3` give the same result. Similarly, multiplying by 1 or adding/subtracting 0 are useless. We can eliminate these redundancies by strengthening the validity predicate:

```ocaml env=ch6
let valid op x y =
  match op with
  | Add -&gt; x &lt;= y
  | Sub -&gt; x &gt; y
  | Mul -&gt; x &lt;= y &amp;&amp; x &lt;&gt; 1 &amp;&amp; y &lt;&gt; 1
  | Div -&gt; x mod y = 0 &amp;&amp; y &lt;&gt; 1</code></pre>
<p>This eliminates symmetrical solutions on the <em>semantic</em> level
(based on values) rather than the <em>syntactic</em> level (based on
expression structure). This approach is both easier to implement and
more effective at pruning the search space.</p>
<h3 id="the-honey-islands-puzzle">6.9 The Honey Islands Puzzle</h3>
<p>Now let us tackle a different kind of puzzle that requires more
sophisticated backtracking.</p>
<p><strong>Be a bee!</strong> Imagine a honeycomb where you need to eat
honey from certain cells to prevent the remaining honey from going sour.
Sourness spreads through contact, so you want to divide the honey into
isolated “islands” – each small enough that it will be consumed before
spoiling.</p>
<p>More precisely: given a honeycomb with some cells initially marked
black (empty), mark additional cells as empty so that the remaining
(unmarked) cells form exactly <code>num_islands</code> disconnected
components, each with exactly <code>island_size</code> cells.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Task: 3 islands × 3 cells</th>
<th style="text-align: center;">Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img src="honey0.png"
style="width:45.0%" alt="Task" /></td>
<td style="text-align: center;"><img src="honey1.png"
style="width:45.0%" alt="Solution" /></td>
</tr>
</tbody>
</table>
<p>In the solution, yellow cells contain honey, black cells were
initially empty, and purple cells are the newly “eaten” cells that
separate the honey into 3 islands of 3 cells each.</p>
<h4 id="representing-the-honeycomb">Representing the Honeycomb</h4>
<p>We represent cells using Cartesian coordinates. The honeycomb
structure means that valid cells satisfy certain parity and boundary
constraints.</p>
<p>```ocaml env=ch6 type cell = int * int (* Cartesian coordinates
*)</p>
<p>module CellSet = (* Store cells in sets for efficient membership
tests *) Set.Make (struct type t = cell let compare = compare end)</p>
<p>type task = { (* For board size N, coordinates <em>) board_size :
int; (</em> range from (-2N, -N) to (2N, N) <em>) num_islands : int;
(</em> Required number of islands <em>) island_size : int; (</em>
Required cells per island <em>) empty_cells : CellSet.t; (</em>
Initially empty cells *) }</p>
<p>let cellset_of_list l = (* Convert list to set (inverse of
CellSet.elements) *) List.fold_right CellSet.add l CellSet.empty</p>
<pre><code>
**Neighborhood:** In a honeycomb, each cell has up to 6 neighbors. We filter out neighbors that are outside the board or already eaten:

```ocaml env=ch6
let even x = x mod 2 = 0

let inside_board n eaten (x, y) =
  even x = even y &amp;&amp; abs y &lt;= n &amp;&amp;
  abs x + abs y &lt;= 2*n &amp;&amp;
  not (CellSet.mem (x, y) eaten)

let neighbors n eaten (x, y) =
  List.filter
    (inside_board n eaten)
    [x-1,y-1; x+1,y-1; x+2,y;
     x+1,y+1; x-1,y+1; x-2,y]</code></pre>
<p><strong>Building the honeycomb:</strong> We generate all valid honey
cells by iterating over the coordinate range and filtering:</p>
<p><code>ocaml env=ch6 let honey_cells n eaten =   fromto (-2*n) (2*n) |-&gt; (fun x -&gt;     fromto (-n) n |-&gt; (fun y -&gt;      pred_guard (inside_board n eaten)         (x, y)))</code></p>
<h4 id="drawing-honeycombs">Drawing Honeycombs</h4>
<p>To visualize the honeycomb, we generate colored polygons. Each cell
is drawn as a hexagon by placing 6 points evenly spaced on a
circumcircle:</p>
<p><code>ocaml skip let draw_honeycomb ~w ~h task eaten =   let i2f = float_of_int in   let nx = i2f (4 * task.board_size + 2) in   let ny = i2f (2 * task.board_size + 2) in   let radius = min (i2f w /. nx) (i2f h /. ny) in   let x0 = w / 2 in   let y0 = h / 2 in   let dx = (sqrt 3. /. 2.) *. radius +. 1. in  (* Distance between *)   let dy = (3. /. 2.) *. radius +. 2. in       (* (x,y) and (x+1,y+1) *)   let draw_cell (x, y) =     Array.init 7                               (* Draw a closed polygon *)       (fun i -&gt;                                (* with 6 points evenly *)         let phi = float_of_int i *. pi /. 3. in   (* spaced on circumcircle *)         x0 + int_of_float (radius *. sin phi +. float_of_int x *. dx),         y0 + int_of_float (radius *. cos phi +. float_of_int y *. dy)) in   let honey =     honey_cells task.board_size (CellSet.union task.empty_cells                                    (cellset_of_list eaten))     |&gt; List.map (fun p -&gt; draw_cell p, (255, 255, 0)) in   (* Yellow cells *)   let eaten = List.map     (fun p -&gt; draw_cell p, (50, 0, 50)) eaten in           (* Purple: eaten *)   let old_empty = List.map     (fun p -&gt; draw_cell p, (0, 0, 0))                      (* Black: empty *)     (CellSet.elements task.empty_cells) in   honey @ eaten @ old_empty</code></p>
<p><strong>Drawing to SVG:</strong> We can render the polygons to an SVG
image file:</p>
<p><code>ocaml skip let draw_to_svg file ~w ~h ?title ?desc curves =   let f = open_out file in   Printf.fprintf f "&lt;?xml version=\"1.0\" standalone=\"no\"?&gt; &lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"   \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt; &lt;svg width=\"%d\" height=\"%d\" viewBox=\"0 0 %d %d\"     xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\"&gt; " w h w h;   (match title with None -&gt; ()   | Some title -&gt; Printf.fprintf f "  &lt;title&gt;%s&lt;/title&gt;\n" title);   (match desc with None -&gt; ()   | Some desc -&gt; Printf.fprintf f "  &lt;desc&gt;%s&lt;/desc&gt;\n" desc);   let draw_shape (points, (r, g, b)) =     uncurry (Printf.fprintf f "  &lt;path d=\"M %d %d") points.(0);     Array.iteri (fun i (x, y) -&gt;       if i &gt; 0 then Printf.fprintf f " L %d %d" x y) points;     Printf.fprintf f "\"\n       fill=\"rgb(%d, %d, %d)\" stroke-width=\"3\" /&gt;\n"       r g b in   List.iter draw_shape curves;   Printf.fprintf f "&lt;/svg&gt;%!"</code></p>
<p><strong>Drawing to screen:</strong> We can also draw interactively
using the <code>Graphics</code> library. In the toplevel, load it with
<code>#load "graphics.cma";;</code>. When compiling, provide
<code>graphics.cma</code> to the command.</p>
<p><code>ocaml skip let draw_to_screen ~w ~h curves =   Graphics.open_graph (" " ^ string_of_int w ^ "x" ^ string_of_int h);   Graphics.set_color (Graphics.rgb 50 50 0);   (* Brown background *)   Graphics.fill_rect 0 0 (Graphics.size_x ()) (Graphics.size_y ());   List.iter (fun (points, (r, g, b)) -&gt;     Graphics.set_color (Graphics.rgb r g b);     Graphics.fill_poly points) curves;   if Graphics.read_key () = 'q'                (* Wait so solutions can be seen *)   then failwith "User interrupted finding solutions.";   Graphics.close_graph ()</code></p>
<h4 id="testing-correctness">Testing Correctness</h4>
<p>Before generating solutions, let us write code to <em>test</em>
whether a proposed solution is correct. We walk through each island
counting its cells using depth-first search: having visited everything
reachable in one direction, we check whether any unvisited cells
remain.</p>
<p>```ocaml skip let check_correct n island_size num_islands empty_cells
= let honey = honey_cells n empty_cells in</p>
<p>let rec check_board been_islands unvisited visited = match unvisited
with | [] -&gt; been_islands = num_islands | cell::remaining when
CellSet.mem cell visited -&gt; check_board been_islands remaining
visited (* Keep looking <em>) | cell::remaining (</em> when not visited
<em>) -&gt; let (been_size, unvisited, visited) = check_island cell
(</em> Visit another island *) (1, remaining, CellSet.add cell visited)
in been_size = island_size &amp;&amp; check_board (been_islands+1)
unvisited visited</p>
<p>and check_island current state = neighbors n empty_cells current
|&gt; List.fold_left (* Walk into each direction <em>) (fun (been_size,
unvisited, visited as state) neighbor -&gt; if CellSet.mem neighbor
visited then state else let unvisited = remove neighbor unvisited in let
visited = CellSet.add neighbor visited in let been_size = been_size + 1
in check_island neighbor (been_size, unvisited, visited)) state in
(</em> Initial been_size is 1 *)</p>
<p>check_board 0 honey empty_cells</p>
<pre><code>
#### Multiple Results per Step: concat_fold

When processing lists, sometimes each step can produce multiple results (not just one as in `fold_left`, or many independent ones as in `concat_map`). We need a hybrid: process elements sequentially like `fold_left`, but allow multiple results at each step, collecting all the final states.

This is `concat_fold`:

```ocaml env=ch6
let rec concat_fold f a = function
  | [] -&gt; [a]
  | x::xs -&gt;
    f x a |-&gt; (fun a&#39; -&gt; concat_fold f a&#39; xs)</code></pre>
<h4 id="generating-solutions">Generating Solutions</h4>
<p>The key insight is that we can transform the <em>testing</em> code
into <em>generation</em> code by:</p>
<ol type="1">
<li>Passing around the current partial solution (the <code>eaten</code>
list)</li>
<li>Returning results in a list (empty list means no solutions from this
path)</li>
<li>At each neighbor cell, exploring <em>both</em> possibilities: eating
it (adding to <code>eaten</code>) or keeping it as honey (continuing to
walk the island)</li>
</ol>
<p>```ocaml skip let find_to_eat n island_size num_islands empty_cells =
let honey = honey_cells n empty_cells in</p>
<p>let rec find_board been_islands unvisited visited eaten = match
unvisited with | [] -&gt; if been_islands = num_islands then [eaten]
else [] | cell::remaining when CellSet.mem cell visited -&gt; find_board
been_islands remaining visited eaten | cell::remaining (* when not
visited <em>) -&gt; find_island cell (1, remaining, CellSet.add cell
visited, eaten) |-&gt; (</em> Concatenate solutions *) (fun (been_size,
unvisited, visited, eaten) -&gt; if been_size = island_size then
find_board (been_islands+1) unvisited visited eaten else [])</p>
<p>and find_island current state = neighbors n empty_cells current |&gt;
concat_fold (* Multiple results <em>) (fun neighbor (been_size,
unvisited, visited, eaten as state) -&gt; if CellSet.mem neighbor
visited then [state] else let unvisited = remove neighbor unvisited in
let visited = CellSet.add neighbor visited in (been_size, unvisited,
visited, neighbor::eaten):: (</em> solutions where neighbor is honey *)
find_island neighbor (been_size+1, unvisited, visited, eaten)) state
in</p>
<p>find_board 0 honey empty_cells []</p>
<pre><code>
#### Optimizations

The brute-force generation explores far too many possibilities. The key optimization principle is: **fail (drop solution candidates) as early as possible**.

Instead of blindly exploring all choices, we add guards to prune branches that cannot lead to solutions:

- Do not try to eat more cells if we have already eaten enough
- Do not add more cells to an island that is already full
- Track exactly how many cells still need to be eaten

```ocaml env=ch6
type state = {
  been_size: int;                           (* Honey cells in current island *)
  been_islands: int;                        (* Islands visited so far *)
  unvisited: cell list;                     (* Cells to visit *)
  visited: CellSet.t;                       (* Already visited *)
  eaten: cell list;                         (* Current solution candidate *)
  more_to_eat: int;                         (* Remaining cells to eat *)
}

let rec visit_cell s =
  match s.unvisited with
  | [] -&gt; None
  | c::remaining when CellSet.mem c s.visited -&gt;
    visit_cell {s with unvisited=remaining}
  | c::remaining (* when c not visited *) -&gt;
    Some (c, {s with
      unvisited=remaining;
      visited = CellSet.add c s.visited})

let eat_cell c s =
  {s with eaten = c::s.eaten;
    visited = CellSet.add c s.visited;
    more_to_eat = s.more_to_eat - 1}

let keep_cell c s =                         (* c is actually unused *)
  {s with been_size = s.been_size + 1;
    visited = CellSet.add c s.visited}

let fresh_island s =                        (* Increment been_size at start of find_island *)
  {s with been_size = 0;
    been_islands = s.been_islands + 1}

let init_state unvisited more_to_eat = {
  been_size = 0; been_islands = 0;
  unvisited; visited = CellSet.empty;
  eaten = []; more_to_eat;
}</code></pre>
<p>The optimized island loop only tries actions that make sense:</p>
<pre><code>  and find_island current s =
    let s = keep_cell current s in
    neighbors n empty_cells current
    |&gt; concat_fold
        (fun neighbor s -&gt;
          if CellSet.mem neighbor s.visited then [s]
          else
            let choose_eat =                (* Guard against failed actions *)
              if s.more_to_eat = 0 then []
              else [eat_cell neighbor s]
            and choose_keep =
              if s.been_size &gt;= island_size then []
              else find_island neighbor s in
            choose_eat @ choose_keep)
        s in
  (* Finally, compute the required eaten cells and start searching *)
  let cells_to_eat =
    List.length honey - island_size * num_islands in
  find_board (init_state honey cells_to_eat)</code></pre>
<h3 id="constraint-based-puzzles">6.10 Constraint-Based Puzzles</h3>
<p>Many puzzles can be understood in terms of <strong>constraint
satisfaction</strong>:</p>
<ol type="1">
<li>The puzzle defines the <em>general form</em> of solutions (what
variables need values)</li>
<li>The puzzle specifies <em>constraints</em> that valid solutions must
satisfy</li>
</ol>
<p>For example, in Sudoku, the variables are the 81 cells, each with
domain {1,…,9}, and the constraints require each row, column, and 3x3
box to contain all digits exactly once.</p>
<p>In the Honey Islands puzzle, we could view each cell as a variable
with domain {Honey, Empty}. The constraints specify which cells must be
empty initially, and the requirement of forming a specific number and
size of connected components.</p>
<h4 id="finite-domain-constraint-programming">Finite Domain Constraint
Programming</h4>
<p><strong>Constraint propagation</strong> is a powerful technique for
solving such puzzles efficiently. The key idea is to track <em>sets of
possible values</em> for each variable and systematically eliminate
impossibilities:</p>
<ol type="1">
<li><p><strong>Initialize:</strong> For each variable, start with the
full set of possible values (its domain). The current “partial solution”
is this collection of sets.</p></li>
<li><p><strong>Propagate and split:</strong> Repeat until all variables
have exactly one value:</p>
<ul>
<li><ol type="a">
<li><strong>Propagate constraints:</strong> If some value for a variable
is inconsistent with <em>all</em> possible values of related variables,
remove it</li>
</ol></li>
<li><ol start="2" type="a">
<li><strong>Prune failures:</strong> If any variable has an empty set of
possible values, this partial solution has no completions – abandon
it</li>
</ol></li>
<li><ol start="3" type="a">
<li><strong>Split:</strong> Select a variable with multiple possible
values. Create new partial solutions by partitioning its possibilities
(simplest: try each value separately, or split into “this value” vs “all
others”)</li>
</ol></li>
</ul></li>
<li><p><strong>Extract solutions:</strong> When all variables have
single values, we have found a solution.</p></li>
</ol>
<p>The efficiency comes from <em>early pruning</em>: constraint
propagation often eliminates many possibilities without explicitly
trying them, dramatically reducing the search space compared to
brute-force enumeration.</p>
<h3 id="exercises-5">6.11 Exercises</h3>
<ol type="1">
<li><p>Recall how we generated all subsequences of a list. Find
(generate) all:</p>
<ul>
<li>permutations of a list</li>
<li>ways of choosing without repetition from a list</li>
<li>combinations of K distinct objects chosen from N elements of a
list</li>
</ul></li>
<li><p>Using folding for the <code>expression</code> data type, compute
the degree of the corresponding polynomial.</p></li>
<li><p>Implement simplification of expressions using mapping for the
<code>expression</code> data type.</p></li>
<li><p>Express in terms of <code>fold_left</code> or
<code>fold_right</code>:</p>
<ul>
<li><code>indexed : 'a list -&gt; (int * 'a) list</code>, which pairs
elements with their indices</li>
<li><code>concat_fold</code> as used in Honey Islands</li>
<li>Run-length encoding of a list:
<code>encode ['a;'a;'a;'a;'b;'c;'c;'a;'a;'d] = [4,'a; 1,'b; 2,'c; 2,'a; 1,'d]</code></li>
</ul></li>
<li><p>Write more efficient variants:</p>
<ul>
<li><code>list_diff</code> computing difference of sets represented as
sorted lists</li>
<li><code>is_unique</code> in constant stack space</li>
</ul></li>
<li><p>Write functions <code>compose</code> and <code>perform</code>
that take a list of functions and return their composition:</p>
<ul>
<li><code>compose [f1; ...; fn] = x -&gt; f1 (... (fn x)...)</code></li>
<li><code>perform [f1; ...; fn] = x -&gt; fn (... (f1 x)...)</code></li>
</ul></li>
<li><p>Write a solver for the <em>Tents Puzzle</em>.</p></li>
<li><p><strong>Robot Squad</strong> (harder): Given a map with walls and
lidar readings (8 directions: E, NE, N, NW, W, SW, S, SE) for multiple
robots, determine possible robot positions.</p></li>
<li><p>Write a solver for the <em>Plinx Puzzle</em> (does not need to
solve all levels, but should handle initial ones).</p></li>
</ol>
<h2 id="chapter-7-laziness">Chapter 7: Laziness</h2>
<p><em>“Today’s lecture is about lazy evaluation. Thank you for coming,
goodbye!”</em></p>
<p>Well, perhaps you have some questions? This chapter explores one of
the most elegant ideas in functional programming: lazy evaluation. By
deferring computation until results are actually needed, we unlock
powerful techniques for working with infinite data structures, solving
differential equations symbolically, and building sophisticated
stream-processing pipelines.</p>
<p>We will examine different evaluation strategies, implement streams
and lazy lists, apply them to power series computation and differential
equations, build circular data structures, and develop a sophisticated
pipe-based pretty-printer. Along the way, we will see how laziness
transforms the way we think about computation itself.</p>
<h3 id="evaluation-strategies-and-parameter-passing">7.1 Evaluation
Strategies and Parameter Passing</h3>
<p><strong>Evaluation strategy</strong> is the order in which
expressions are computed – primarily, when arguments are computed.
Recall our problems with using <em>flow control</em> expressions like
<code>if_then_else</code> in examples from the lambda-calculus lecture.
There are many technical terms describing various evaluation
strategies:</p>
<p><strong>Strict evaluation</strong>: Arguments are always evaluated
completely before the function is applied.</p>
<p><strong>Non-strict evaluation</strong>: Arguments are not evaluated
unless they are actually used in the evaluation of the function
body.</p>
<p><strong>Eager evaluation</strong>: An expression is evaluated as soon
as it gets bound to a variable.</p>
<p><strong>Lazy evaluation</strong>: Non-strict evaluation which avoids
repeating computation.</p>
<p><strong>Call-by-value</strong>: The argument expression is evaluated,
and the resulting value is bound to the corresponding variable in the
function (frequently by copying the value into a new memory region).</p>
<p><strong>Call-by-reference</strong>: A function receives an implicit
reference to a variable used as argument, rather than a copy of its
value. In purely functional languages there is no difference between the
two strategies, so they are typically described as call-by-value even
though implementations use call-by-reference internally for efficiency.
Call-by-value languages like C and OCaml support explicit references
(objects that refer to other objects), and these can be used to simulate
call-by-reference.</p>
<p><strong>Normal order</strong>: Start computing function bodies before
evaluating their arguments. Do not even wait for arguments if they are
not needed.</p>
<p><strong>Call-by-name</strong>: Arguments are substituted directly
into the function body and then left to be evaluated whenever they
appear in the function. This means an argument might be evaluated
multiple times if it appears multiple times in the function body.</p>
<p><strong>Call-by-need</strong>: If the function argument is evaluated,
that value is stored for subsequent uses. This avoids the redundant
recomputation that can occur with call-by-name.</p>
<p>Almost all languages do not compute inside the body of an un-applied
function, but with curried functions you can pre-compute data before all
arguments are provided (recall the <code>search_bible</code> example
from earlier lectures, where preprocessing happened when the first
argument was supplied).</p>
<p>In eager / call-by-value languages we can simulate call-by-name by
taking a function to compute the value as an argument instead of the
value directly. “Our” languages have a <code>unit</code> type with a
single value <code>()</code> specifically for use as throw-away
arguments – we pass <code>fun () -&gt; expensive_computation</code>
instead of <code>expensive_computation</code> directly. Scala has
built-in support for call-by-name (i.e. direct, without the need to
build argument functions).</p>
<p>ML languages have built-in support for lazy evaluation, while Haskell
has built-in support for eager evaluation (to override the default
laziness). This reflects the different design philosophies: OCaml
defaults to strict evaluation with opt-in laziness, while Haskell
defaults to lazy evaluation with opt-in strictness.</p>
<h3 id="call-by-name-streams">7.2 Call-by-name: Streams</h3>
<p>Call-by-name is useful not only for implementing flow control.
Remember how we struggled to define <code>if_then_else</code> as a
regular function in the lambda calculus lecture? The problem was that
both branches would be evaluated before the function could choose
between them. With call-by-name simulation, we can finally make it
work:</p>
<p><code>ocaml env=ch7 let if_then_else cond e1 e2 =   match cond with   | true -&gt; e1 ()   | false -&gt; e2 ()</code></p>
<p>Here <code>e1</code> and <code>e2</code> are functions that compute
their respective branches only when called. But call-by-name is useful
for more than just flow control – it also enables lazy data
structures.</p>
<p><strong>Streams</strong> are lists with call-by-name tails:</p>
<p><code>ocaml env=ch7 type 'a stream = SNil | SCons of 'a * (unit -&gt; 'a stream)</code></p>
<p>The key insight is that the tail is not a stream directly, but a
<em>function</em> that produces a stream when called. This means the
tail is not computed until we actually need it. Reading from a stream
into a regular list forces evaluation of the requested elements:</p>
<p><code>ocaml env=ch7 let rec stake n = function   | SCons (a, s) when n &gt; 0 -&gt; a :: (stake (n-1) (s ()))   | _ -&gt; []</code></p>
<p>Notice how we call <code>s ()</code> to get the next portion of the
stream. This is where the “lazy” computation happens. Because of this
delayed evaluation, streams can easily be infinite:</p>
<p>```ocaml env=ch7 let rec s_ones = SCons (1, fun () -&gt; s_ones)</p>
<p>let rec s_from n = SCons (n, fun () -&gt; s_from (n+1))</p>
<pre><code>
The stream `s_ones` is an infinite sequence of 1s -- it refers to itself as its own tail! The stream `s_from n` produces all integers starting from `n`. These definitions would cause infinite loops in a strict language, but with streams, we only compute as much as we request.

#### Stream Operations

Just as we can define higher-order functions on lists, streams admit similar operations. The key difference is that we must wrap recursive calls in functions to maintain laziness:

```ocaml env=ch7
let rec smap f = function
  | SNil -&gt; SNil
  | SCons (a, s) -&gt; SCons (f a, fun () -&gt; smap f (s ()))

let rec szip = function
  | SNil, SNil -&gt; SNil
  | SCons (a1, s1), SCons (a2, s2) -&gt;
      SCons ((a1, a2), fun () -&gt; szip (s1 (), s2 ()))
  | _ -&gt; raise (Invalid_argument &quot;szip&quot;)</code></pre>
<p>Streams can provide scaffolding for recursive algorithms, enabling
elegant definitions that would be impossible with strict data
structures. Consider the Fibonacci sequence:</p>
<p><code>ocaml env=ch7 let rec sfib =   SCons (1, fun () -&gt; smap (fun (a,b) -&gt; a+b)     (szip (sfib, SCons (1, fun () -&gt; sfib))))</code></p>
<p>This remarkably concise definition creates a stream where each
element is computed by adding pairs from the current stream and itself
shifted by one position. The stream effectively “builds itself” by
referring to its own earlier elements:</p>
<table>
<thead>
<tr>
<th>sfib</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>5</th>
<th>8</th>
<th>13</th>
<th>…</th>
</tr>
</thead>
<tbody>
<tr>
<td>sfib</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>5</td>
<td>8</td>
<td>13</td>
<td>…</td>
</tr>
<tr>
<td>shifted</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>5</td>
<td>8</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>The <code>+</code> operation between corresponding elements produces
the next values.</p>
<h4 id="streams-and-input-output">Streams and Input-Output</h4>
<p>Streams can be used to read from files lazily, but there is a catch –
they are less functional than one might expect in the context of
input-output effects:</p>
<p><code>ocaml env=ch7 let file_stream name =   let ch = open_in name in   let rec ch_read_line () =     try SCons (input_line ch, ch_read_line)     with End_of_file -&gt; SNil in   ch_read_line ()</code></p>
<p>The problem is that reading from a file is a side effect. If you
traverse the stream twice, you will not get the same results – the file
handle advances with each read. This is why <em>OCaml Batteries</em>
uses a stream type <code>enum</code> for interfacing between various
sequence-like data types, with careful documentation about when streams
can be safely reused.</p>
<p>The safest way to use streams is in a <em>linear</em> or
<em>ephemeral</em> manner: every value used only once. Streams minimize
space consumption at the expense of time for recomputation – if you need
to traverse the data multiple times, you will recompute it each time.
For data that should be computed once and accessed multiple times, we
need lazy lists.</p>
<h3 id="lazy-values">7.3 Lazy Values</h3>
<p>Lazy evaluation is more general than call-by-need as any value can be
lazy, not only a function parameter. While streams give us call-by-name
semantics (recomputing on each access), lazy values give us call-by-need
semantics (computing once and caching the result).</p>
<p>A <em>lazy value</em> is a value that “holds” an expression until its
result is needed, and from then on it “holds” the result. It is also
called a <em>suspension</em>. If it holds the expression (not yet
evaluated), it is called a <em>thunk</em> – a placeholder waiting to
become a real value.</p>
<p>In OCaml, we build lazy values explicitly using the <code>lazy</code>
keyword. In Haskell, all values are lazy by default, but functions can
have call-by-value parameters which “need” (force evaluation of) the
argument.</p>
<p>To create a lazy value: <code>lazy expr</code> – where
<code>expr</code> is the suspended computation. The expression
<code>expr</code> is not evaluated when the lazy value is created; it is
stored for later.</p>
<p>There are two ways to use a lazy value. Be careful to understand when
the result is computed! - In expressions: <code>Lazy.force l_expr</code>
– explicitly forces evaluation - In patterns:
<code>match l_expr with lazy v -&gt; ...</code> – forces evaluation
during pattern matching - Syntactically <code>lazy</code> behaves like a
data constructor, which is why it can appear in patterns.</p>
<h4 id="lazy-lists">Lazy Lists</h4>
<p>Lazy lists are the “memoizing” version of streams. Instead of a
function that recomputes the tail each time, we use a lazy value that
computes it once:</p>
<p><code>ocaml env=ch7 type 'a llist = LNil | LCons of 'a * 'a llist Lazy.t</code></p>
<p>The tail is of type <code>'a llist Lazy.t</code> – a lazy value that
will produce the rest of the list when forced. Reading from a lazy list
into a regular list forces evaluation of just the elements we need:</p>
<p><code>ocaml env=ch7 let rec ltake n = function   | LCons (a, lazy l) when n &gt; 0 -&gt; a :: (ltake (n-1) l)   | _ -&gt; []</code></p>
<p>Notice the <code>lazy l</code> pattern – this forces evaluation of
the lazy tail and binds the result to <code>l</code>. Lazy lists can
easily be infinite, just like streams:</p>
<p>```ocaml env=ch7 let rec l_ones = LCons (1, lazy l_ones)</p>
<p>let rec l_from n = LCons (n, lazy (l_from (n+1)))</p>
<pre><code>
The crucial difference from streams is that lazy lists support &quot;read once, access multiple times&quot; semantics. Once a portion of the list has been computed, subsequent accesses return the cached result:

```ocaml env=ch7
let file_llist name =
  let ch = open_in name in
  let rec ch_read_line () =
    try LCons (input_line ch, lazy (ch_read_line ()))
    with End_of_file -&gt; LNil in
  ch_read_line ()</code></pre>
<p>With <code>file_llist</code>, you can traverse the resulting list
multiple times and get the same data each time (as long as you keep a
reference to the head of the list). The file is read lazily, but each
line is cached after being read.</p>
<h4 id="lazy-list-operations">Lazy List Operations</h4>
<p>We can define the familiar higher-order functions on lazy lists.
Notice the subtle but important difference from streams – we must use
<code>Lazy.force</code> to access the lazy tail before passing it to
recursive calls:</p>
<p>```ocaml env=ch7 let rec lzip = function | LNil, LNil -&gt; LNil |
LCons (a1, ll1), LCons (a2, ll2) -&gt; LCons ((a1, a2), lazy ( lzip
(Lazy.force ll1, Lazy.force ll2))) | _ -&gt; raise (Invalid_argument
“lzip”)</p>
<p>let rec lmap f = function | LNil -&gt; LNil | LCons (a, ll) -&gt;
LCons (f a, lazy (lmap f (Lazy.force ll)))</p>
<pre><code>
Using these operations, we can define the factorial sequence in a beautifully self-referential way:

```ocaml env=ch7
let posnums = l_from 1

let rec lfact =
  LCons (1, lazy (lmap (fun (a,b) -&gt; a*b)
                    (lzip (lfact, posnums))))</code></pre>
<p>This produces: 1, 1, 2, 6, 24, 120, … The definition is elegant: each
factorial is the product of the previous factorial and the corresponding
positive integer. The lazy list <code>lfact</code> refers to itself to
get the previous factorials!</p>
<table>
<thead>
<tr>
<th>lfact</th>
<th>1</th>
<th>1</th>
<th>2</th>
<th>6</th>
<th>24</th>
<th>120</th>
<th>…</th>
</tr>
</thead>
<tbody>
<tr>
<td>lfact</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>6</td>
<td>24</td>
<td>120</td>
<td>…</td>
</tr>
<tr>
<td>posnums</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>The <code>*</code> operation between corresponding elements produces
the next values.</p>
<h3 id="power-series-and-differential-equations">7.4 Power Series and
Differential Equations</h3>
<p>This section presents a fascinating application of lazy lists:
computing power series and solving differential equations symbolically.
The differential equations idea is due to Henning Thielemann, and
demonstrates the expressive power of lazy evaluation.</p>
<p>The expression <span class="math inline">P(x) = \sum_{i=0}^{n} a_i
x^i</span> defines a polynomial when <span class="math inline">n &lt;
\infty</span> and a power series when <span class="math inline">n =
\infty</span>. We can represent both as lazy lists of coefficients <span
class="math inline">[a_0; a_1; a_2; \ldots]</span>.</p>
<p>If we define:</p>
<p><code>ocaml env=ch7 let rec lfold_right f l base =   match l with     | LNil -&gt; base     | LCons (a, lazy l) -&gt; f a (lfold_right f l base)</code></p>
<p>then we can compute polynomials using Horner’s method. Horner’s
method evaluates polynomials efficiently by factoring out powers of
<span class="math inline">x</span>: instead of computing <span
class="math inline">a_0 + a_1 x + a_2 x^2 + \ldots</span>, we compute
<span class="math inline">a_0 + x(a_1 + x(a_2 + \ldots))</span>:</p>
<p><code>ocaml env=ch7 let horner x l =   lfold_right (fun c sum -&gt; c +. x *. sum) l 0.</code></p>
<p>But this will not work for infinite power series! Two natural
questions arise: - Does it make sense to compute the value at <span
class="math inline">x</span> of a power series? - Does it make sense to
fold an infinite list?</p>
<p>The answer to both is “yes, sometimes.” If the power series converges
for <span class="math inline">x &gt; 1</span>, then when the elements
<span class="math inline">a_n</span> get small, the remaining sum <span
class="math inline">\sum_{i=n}^{\infty} a_i x^i</span> is also small. We
can truncate the computation when the contribution becomes
negligible.</p>
<p>The problem is that <code>lfold_right</code> falls into an infinite
loop on infinite lists – it tries to reach the end before computing
anything. We need call-by-name / call-by-need semantics for the argument
function <code>f</code>, so it can decide to stop early:</p>
<p><code>ocaml env=ch7 let rec lazy_foldr f l base =   match l with     | LNil -&gt; base     | LCons (a, ll) -&gt;       f a (lazy (lazy_foldr f (Lazy.force ll) base))</code></p>
<p>Now we need a stopping condition in the Horner algorithm step. We
stop when the coefficient becomes small enough that further terms are
negligible:</p>
<p>```ocaml env=ch7 let lhorner x l = (* This is a bit of a hack: <em>)
let upd c sum = (</em> we hope to “hit” the interval (0, epsilon]. <em>)
if c = 0. || abs_float c &gt; epsilon_float then c +. x </em>.
Lazy.force sum else 0. in (* Stop when c is tiny but nonzero. *)
lazy_foldr upd l 0.</p>
<p>let inv_fact = lmap (fun n -&gt; 1. /. float_of_int n) lfact let e =
lhorner 1. inv_fact</p>
<pre><code>
The `inv_fact` list contains $[1/0!; 1/1!; 1/2!; \ldots]$, which is the power series for $e^x$. Evaluating `lhorner 1. inv_fact` computes $e^1 = e$.

#### Power Series / Polynomial Operations

To work with power series, we need to define arithmetic operations on lazy lists of coefficients. For floating-point coefficients, we first need a float-based version of positive numbers:

```ocaml env=ch7
let rec l_from_f n = LCons (n, lazy (l_from_f (n +. 1.)))
let posnums_f = l_from_f 1.

(* Unary negation for series *)
let (~-:) = lmap (fun x -&gt; -.x)</code></pre>
<p>Now we can define the basic arithmetic operations on power series.
Addition and subtraction work coefficient-wise:</p>
<p>```ocaml env=ch7 let rec add xs ys = match xs, ys with | LNil, _
-&gt; ys | _, LNil -&gt; xs | LCons (x,xs), LCons (y,ys) -&gt; LCons (x
+. y, lazy (add (Lazy.force xs) (Lazy.force ys)))</p>
<p>let rec sub xs ys = match xs, ys with | LNil, _ -&gt; lmap (fun x
-&gt; -.x) ys | _, LNil -&gt; xs | LCons (x,xs), LCons (y,ys) -&gt;
LCons (x -. y, lazy (add (Lazy.force xs) (Lazy.force ys)))</p>
<p>let scale s = lmap (fun x -&gt; s *. x)</p>
<p>let rec shift n xs = if n = 0 then xs else if n &gt; 0 then LCons
(0., lazy (shift (n-1) xs)) (* Multiply by x^n <em>) else match xs with
(</em> Divide by x^|n| *) | LNil -&gt; LNil | LCons (0., lazy xs) -&gt;
shift (n+1) xs | _ -&gt; failwith “shift: fractional division”</p>
<p>(* Multiplication uses the convolution formula *) let rec mul xs =
function | LNil -&gt; LNil | LCons (y, ys) -&gt; add (scale y xs) (LCons
(0., lazy (mul xs (Lazy.force ys))))</p>
<p>(* Division is like long division of polynomials <em>) let rec div xs
ys = match xs, ys with | LNil, _ -&gt; LNil | LCons (0., xs’), LCons
(0., ys’) -&gt; (</em> Both start with zero: cancel x <em>) div
(Lazy.force xs’) (Lazy.force ys’) | LCons (x, xs’), LCons (y, ys’) -&gt;
let q = x /. y in (</em> Leading coefficient of quotient *) LCons (q,
lazy (div (sub (Lazy.force xs’) (scale q (Lazy.force ys’))) ys)) | LCons
_, LNil -&gt; failwith “div: division by zero”</p>
<p>(* Integration: integral of a_0 + a_1<em>x + a_2</em>x^2 + … is c +
a_0<em>x + a_1</em>x^2/2 + a_2<em>x^3/3 + … </em>) let integrate c xs =
LCons (c, lazy (lmap (uncurry (/.)) (lzip (xs, posnums_f))))</p>
<p>let ltail = function | LNil -&gt; invalid_arg “ltail” | LCons (_,
lazy tl) -&gt; tl</p>
<p>(* Differentiation: derivative of a_0 + a_1<em>x + a_2</em>x^2 + … is
a_1 + 2<em>a_2</em>x + 3<em>a_3</em>x^2 + … <em>) let differentiate xs =
lmap (uncurry ( </em>.)) (lzip (ltail xs, posnums_f))</p>
<pre><code>
#### Differential Equations

Now for the remarkable part: we can solve differential equations by representing the solutions as power series! Consider the differential equations for sine and cosine:

$$\frac{d \sin x}{dx} = \cos x, \quad \frac{d \cos x}{dx} = -\sin x, \quad \sin 0 = 0, \quad \cos 0 = 1$$

We will solve the corresponding integral equations. Why integral equations rather than differential equations? Because integration gives us a way to build up the solution coefficient by coefficient, starting from the initial conditions.

Our first attempt might be to define them by direct recursion:
</code></pre>
<p>let (~-:) = lmap (fun x -&gt; -.x) (* Unary negation for series
*)</p>
<p>let rec sin = integrate (of_int 0) cos and cos = integrate (of_int 1)
(~-:sin)</p>
<pre><code>
Unfortunately this fails with: `Error: This kind of expression is not allowed as right-hand side of &#39;let rec&#39;`

The problem is that OCaml&#39;s `let rec` requires the right-hand side to be a &quot;static&quot; value -- something like a function or a data constructor applied to arguments. Even changing the second argument of `integrate` to call-by-need does not help, because OCaml cannot represent the values that `sin` and `cos` refer to at the point of their definition.

The solution is to inline a bit of `integrate` so that OCaml knows how to start building the recursive structure. We provide the first coefficient explicitly:

```ocaml env=ch7
let integ xs = lmap (uncurry (/.)) (lzip (xs, posnums_f))

let rec sin = LCons (of_int 0, lazy (integ cos))
and cos = LCons (of_int 1, lazy (integ (~-:sin)))</code></pre>
<p>Now the <code>let rec</code> works because each right-hand side is
just <code>LCons</code> applied to a value and a lazy expression. The
lazy expressions are not evaluated during the definition, so there is no
problem with the mutual recursion. When we force the lazy tails, the
computation proceeds coefficient by coefficient.</p>
<p>The complete example would look much more elegant in Haskell, where
all values are lazy by default – we would not need the explicit
<code>LCons</code> and <code>lazy</code> wrappers.</p>
<p>Although this approach is not limited to linear equations, equations
like Lotka-Volterra or Lorentz are not “solvable” this way – the
computed coefficients quickly grow instead of quickly falling, so the
series does not converge well.</p>
<p>Drawing functions work like in the previous lecture, but with open
curves:</p>
<p><code>ocaml env=ch7 let plot_1D f ~w ~scale ~t_beg ~t_end =   let dt = (t_end -. t_beg) /. of_int w in   Array.init w (fun i -&gt;     let y = lhorner (dt *. of_int i) f in     i, to_int (scale *. y))</code></p>
<h3 id="arbitrary-precision-computation">7.5 Arbitrary Precision
Computation</h3>
<p>Putting together the power series computation with floating-point
numbers reveals drastic numerical errors for large <span
class="math inline">x</span>. There are two problems: 1. Floating-point
numbers have limited precision, so intermediate calculations accumulate
errors. 2. We break out of Horner method computations too quickly – the
stopping condition based on <code>epsilon_float</code> may stop before
we have enough precision.</p>
<figure>
<img src="sin_cos_1.png" style="width:70.0%"
alt="Numerical errors in sine/cosine computation" />
<figcaption aria-hidden="true">Numerical errors in sine/cosine
computation</figcaption>
</figure>
<p>For infinite precision on rational numbers we can use the
<code>nums</code> library, but it does not help by itself – the stopping
condition still causes us to truncate the computation prematurely.</p>
<p>The key insight is that instead of computing a single approximate
value, we should generate a <em>sequence of approximations</em> to the
power series limit at <span class="math inline">x</span>. Then we can
watch the sequence until it converges:</p>
<p><code>ocaml env=ch7 let infhorner x l =   let upd c sum =     LCons (c, lazy (lmap (fun apx -&gt; c +. x *. apx)                       (Lazy.force sum))) in   lazy_foldr upd l (LCons (of_int 0, lazy LNil))</code></p>
<p>The function <code>infhorner</code> returns a lazy list of partial
sums. Each element is a better approximation than the previous one. Now
we need to find where the series has converged to the precision we
need:</p>
<p><code>ocaml env=ch7 let rec exact f = function           (* We arbitrarily decide that convergence is *)   | LNil -&gt; assert false             (* when three consecutive results are the same. *)   | LCons (x0, lazy (LCons (x1, lazy (LCons (x2, _)))))       when f x0 = f x1 &amp;&amp; f x0 = f x2 -&gt; f x0   | LCons (_, lazy tl) -&gt; exact f tl</code></p>
<p>The function <code>exact</code> applies a test function
<code>f</code> to the approximations and stops when three consecutive
results give the same answer. Why three? Because some power series (like
those for sine and cosine) have alternating terms, and we want to be
sure the result has stabilized.</p>
<p>Draw the pixels of the graph at exact coordinates:</p>
<p><code>ocaml env=ch7 let plot_1D f ~w ~h0 ~scale ~t_beg ~t_end =   let dt = (t_end -. t_beg) /. of_int w in   let eval = exact (fun y -&gt; to_int (scale *. y)) in   Array.init w (fun i -&gt;     let y = infhorner (t_beg +. dt *. of_int i) f in     i, h0 + eval y)</code></p>
<p>If a power series had every third term contributing (zeros in a
regular pattern), we would have to check more terms in the function
<code>exact</code>. We could also use a different stopping criterion
like <code>f x0 = f x1 &amp;&amp; not (x0 =. x1)</code> (stop when the
transformed values match but the raw values are still changing), similar
to what we did in <code>lhorner</code>.</p>
<h4 id="example-nuclear-chain-reaction">Example: Nuclear Chain
Reaction</h4>
<p>Consider a nuclear chain reaction where substance A decays into B,
which then decays into C. This is a classic problem in nuclear physics.
The differential equations are:</p>
<p><span class="math display">\frac{dN_A}{dt} = -\lambda_A N_A, \quad
\frac{dN_B}{dt} = \lambda_A N_A - \lambda_B N_B</span></p>
<p>Here <span class="math inline">\lambda_A</span> and <span
class="math inline">\lambda_B</span> are the decay constants, and <span
class="math inline">N_A</span>, <span class="math inline">N_B</span> are
the amounts of each substance. Substance A decays at a rate proportional
to its amount. Substance B is produced by A’s decay and itself decays
into C.</p>
<p>We can solve these equations using the same technique as for sine and
cosine:</p>
<pre><code>let n_chain ~nA0 ~nB0 ~lA ~lB =
  let rec nA =
    LCons (nA0, lazy (integ (~-.lA *:. nA)))
  and nB =
    LCons (nB0, lazy (integ (~-.lB *:. nB +: lA *:. nA))) in
  nA, nB</code></pre>
<figure>
<img src="chain_reaction.png" style="width:70.0%"
alt="Nuclear chain reaction: A decays into B decays into C" />
<figcaption aria-hidden="true">Nuclear chain reaction: A decays into B
decays into C</figcaption>
</figure>
<p>(See <a
href="http://en.wikipedia.org/wiki/Radioactive_decay#Chain-decay_processes">Radioactive
decay chain processes</a> for more information.)</p>
<h3 id="circular-data-structures-double-linked-lists">7.6 Circular Data
Structures: Double-Linked Lists</h3>
<p>Without delayed computation, the ability to define data structures
with referential cycles is very limited. In a strict language, you
cannot create a structure that refers to itself – the reference would
have to exist before the structure is created.</p>
<p>Double-linked lists are a classic example of structures with inherent
cycles. Even if the list itself is not circular (it has a beginning and
an end), each pair of adjacent nodes forms a cycle: node A points
forward to node B, and node B points backward to node A:</p>
<pre><code>+--------+     +--------+     +--------+     +--------+     +--------+
| DLNil  | &lt;-&gt; |   a1   | &lt;-&gt; |   a2   | &lt;-&gt; |   a3   | &lt;-&gt; | DLNil  |
+--------+     +--------+     +--------+     +--------+     +--------+</code></pre>
<p>To represent such structures in OCaml, we need to “break” the cycles
by making some links lazy. The backward links will be lazy, allowing us
to construct the structure one node at a time:</p>
<p><code>ocaml env=ch7 type 'a dllist =   DLNil | DLCons of 'a dllist Lazy.t * 'a * 'a dllist</code></p>
<p>The type has three components: a lazy backward link, the element, and
a (strict) forward link. The backward link is lazy because when we
create a node, its predecessor may not exist yet.</p>
<p>We can navigate forward through the list, dropping elements from the
front:</p>
<p><code>ocaml env=ch7 let rec dldrop n l =   match l with     | DLCons (_, x, xs) when n &gt; 0 -&gt;        dldrop (n-1) xs     | _ -&gt; l</code></p>
<p>The tricky part is constructing a double-linked list from a regular
list. Each cell must know its predecessor, but the predecessor is
created first. We use a recursive lazy value to tie the knot:</p>
<p><code>ocaml env=ch7 let dllist_of_list l =   let rec dllist prev l =     match l with       | [] -&gt; DLNil       | x::xs -&gt;         let rec cell =           lazy (DLCons (prev, x, dllist cell xs)) in         Lazy.force cell in   dllist (lazy DLNil) l</code></p>
<p>The key trick is
<code>let rec cell = lazy (DLCons (prev, x, dllist cell xs))</code>. The
lazy value <code>cell</code> refers to itself! When we force
<code>cell</code>, it creates a <code>DLCons</code> node whose forward
link (<code>dllist cell xs</code>) receives <code>cell</code> as the
predecessor for the next node. This is only possible because the
backward link is lazy – when we create the next node, we do not need to
evaluate <code>cell</code>, just store a reference to it.</p>
<p>Taking elements going forward is straightforward:</p>
<p><code>ocaml env=ch7 let rec dltake n l =   match l with     | DLCons (_, x, xs) when n &gt; 0 -&gt;        x :: dltake (n-1) xs     | _ -&gt; []</code></p>
<p>Taking elements going backward shows the power of the double-linked
structure – we can traverse in either direction:</p>
<p><code>ocaml env=ch7 let rec dlbackwards n l =   match l with     | DLCons (lazy xs, x, _) when n &gt; 0 -&gt;       x :: dlbackwards (n-1) xs     | _ -&gt; []</code></p>
<h3 id="input-output-streams">7.7 Input-Output Streams</h3>
<p>Let us return to streams and generalize them. The stream type we
defined earlier used a throwaway argument to make a suspension:</p>
<p><code>ocaml env=ch7 type 'a stream = SNil | SCons of 'a * (unit -&gt; 'a stream)</code></p>
<p>The <code>unit</code> argument serves only to delay computation. But
what if we take a <em>real</em> argument – one that provides input to
the stream? This leads to a more powerful abstraction:</p>
<p><code>ocaml env=ch7 type ('a, 'b) iostream =   EOS | More of 'b * ('a -&gt; ('a, 'b) iostream)</code></p>
<p>This is an <em>interactive</em> stream: it produces an output value
of type <code>'b</code>, and when given an input value of type
<code>'a</code>, produces the rest of the stream. The stream alternates
between producing output and consuming input.</p>
<p><code>ocaml env=ch7 type 'a istream = (unit, 'a) iostream  (* Input stream produces output when "asked". *) type 'a ostream = ('a, unit) iostream  (* Output stream consumes provided input. *)</code></p>
<p>The terminology can be confusing. An “input stream”
(<code>istream</code>) is one that produces output when asked (like
reading from a file). An “output stream” (<code>ostream</code>) is one
that consumes input (like writing to a file). The confusion arises from
adapting the <em>input file / output file</em> terminology.</p>
<p>The power of this abstraction is that we can compose streams,
directing the output of one to the input of another:</p>
<p><code>ocaml env=ch7 let rec compose sf sg =   match sg with   | EOS -&gt; EOS                              (* No more output from sg. *)   | More (z, g) -&gt;     match sf with     | EOS -&gt; More (z, fun _ -&gt; EOS)         (* No more input from sf. *)     | More (y, f) -&gt;       let update x = compose (f x) (g y) in (* Feed sf's output y to sg. *)       More (z, update)</code></p>
<p>Think of it as connecting boxes with wires: every box has one
incoming wire and one outgoing wire. When composing <code>sf</code> and
<code>sg</code>, the output of <code>sf</code> becomes the input of
<code>sg</code>. Notice that the output stream is “ahead” of the input
stream – <code>sg</code> can produce its first output <code>z</code>
before <code>sf</code> has produced anything.</p>
<h3 id="pipes">7.8 Pipes</h3>
<p>The <code>iostream</code> type has a limitation: it must alternate
strictly between producing output and consuming input. In many
real-world scenarios, we need more flexibility: - A transformation might
consume several inputs before producing a single output (like computing
an average). - A transformation might produce several outputs from a
single input (like splitting a string). - A transformation might produce
output without needing any input (like a constant source).</p>
<p>Following the Haskell tradition, we call this more flexible data
structure a <code>pipe</code>:</p>
<p><code>ocaml env=ch7 type ('a, 'b) pipe =   EOP                                       (* End of pipe -- done processing *) | Yield of 'b * ('a, 'b) pipe               (* Produce output b, then continue *) | Await of ('a -&gt; ('a, 'b) pipe)            (* Wait for input a, then continue *)</code></p>
<p>A pipe can be in one of three states: finished (<code>EOP</code>),
ready to produce output (<code>Yield</code>), or waiting for input
(<code>Await</code>). The key insight is that <code>Yield</code>
includes the continuation pipe directly (not wrapped in a function), so
multiple outputs can be produced in sequence without requiring input.
For incremental processing where outputs should be lazy, you would
change <code>Yield</code> to hold a lazy pipe instead.</p>
<p>Again, we can specialize to input-only and output-only pipes:</p>
<p><code>ocaml env=ch7 type 'a ipipe = (unit, 'a) pipe type void type 'a opipe = ('a, void) pipe</code></p>
<p>Why <code>void</code> rather than <code>unit</code>, and why only for
<code>opipe</code>? Because an output pipe never yields values – if it
used <code>unit</code> as the output type, it could still yield
<code>()</code> values. But <code>void</code> is an abstract type with
no values, making it impossible for an <code>opipe</code> to yield
anything. This is a type-level guarantee that output pipes only
consume.</p>
<h4 id="pipe-composition">Pipe Composition</h4>
<p>Composition of pipes is like “concatenating them in space” or
connecting boxes. We plug the output of pipe <code>pf</code> into the
input of pipe <code>pg</code>:</p>
<p>```ocaml env=ch7 let rec compose pf pg = match pg with | EOP -&gt;
EOP (* pg is done – composition is done. <em>) | Yield (z, pg’) -&gt;
Yield (z, compose pf pg’) (</em> pg has output ready – pass it through.
<em>) | Await g -&gt; (</em> pg needs input – try to get it from pf.
<em>) match pf with | EOP -&gt; EOP (</em> pf is done – no more input
for pg. <em>) | Yield (y, pf’) -&gt; compose pf’ (g y) (</em> pf has
output – feed it to pg. <em>) | Await f -&gt; (</em> Both are waiting –
wait for external input. *) let update x = compose (f x) pg in Await
update</p>
<p>let (&gt;-&gt;) pf pg = compose pf pg</p>
<pre><code>
The `&gt;-&gt;` operator lets us chain pipes together like Unix pipes: `source &gt;-&gt; transform &gt;-&gt; sink`.

Appending pipes means &quot;concatenating them in time&quot; rather than in space. When the first pipe finishes, we continue with the second:

```ocaml env=ch7
let rec append pf pg =
  match pf with
  | EOP -&gt; pg                               (* pf is exhausted -- continue with pg. *)
  | Yield (z, pf&#39;) -&gt; Yield (z, append pf&#39; pg)  (* pf has output -- pass it through. *)
  | Await f -&gt;                              (* pf awaits input -- pass it through. *)
    let update x = append (f x) pg in
    Await update</code></pre>
<p>We can also append a list of ready results in front of a pipe. This
is useful for producing multiple outputs at once:</p>
<p><code>ocaml env=ch7 let rec yield_all l tail =   match l with   | [] -&gt; tail   | x::xs -&gt; Yield (x, yield_all xs tail)</code></p>
<p>Finally, the <code>iterate</code> function creates a pipe that
repeatedly applies a side-effecting function to its inputs. This is
<strong>not functional</strong> (it performs side effects), but it is
useful for output:</p>
<p><code>ocaml env=ch7 let rec iterate f : 'a opipe =   Await (fun x -&gt; let () = f x in iterate f)</code></p>
<h3 id="example-pretty-printing">7.9 Example: Pretty-Printing</h3>
<p>Now let us apply pipes to a substantial example: pretty-printing. The
goal is to print a hierarchically organized document with a limited line
width. When a group of text fits on the current line, we keep it
together; when it does not fit, we break it across multiple lines.</p>
<p><code>ocaml env=ch7 type doc =   Text of string | Line | Cat of doc * doc | Group of doc</code></p>
<p>The document type has four constructors: - <code>Text s</code> –
literal text - <code>Line</code> – a potential line break (rendered as a
space if the group fits, or a newline if it does not) -
<code>Cat (d1, d2)</code> – concatenation - <code>Group d</code> – a
group that should be kept together if possible</p>
<p>Some convenient operators for building documents:</p>
<p>```ocaml env=ch7 let (++) d1 d2 = Cat (d1, Cat (Line, d2)) let (!) s
= Text s</p>
<p>let test_doc = Group (!“Document” ++ Group (!“First part” ++ !“Second
part”))</p>
<pre><code>
The pretty-printer should produce different outputs depending on the available width:
</code></pre>
<h1 id="let-print_endline-pretty-30-test_doc">let () = print_endline
(pretty 30 test_doc);;</h1>
<p>Document First part Second part</p>
<h1 id="let-print_endline-pretty-20-test_doc">let () = print_endline
(pretty 20 test_doc);;</h1>
<p>Document First part Second part</p>
<h1 id="let-print_endline-pretty-60-test_doc">let () = print_endline
(pretty 60 test_doc);;</h1>
<p>Document First part Second part</p>
<pre><code>
#### Straightforward Solution

Before diving into pipes, let us implement a straightforward recursive solution:

```ocaml env=ch7
let pretty w d =                     (* Allowed width of line w. *)
  let rec width = function           (* Compute total length of subdocument. *)
    | Text z -&gt; String.length z
    | Line -&gt; 1                      (* A line break takes 1 character (space or newline). *)
    | Cat (d1, d2) -&gt; width d1 + width d2
    | Group d -&gt; width d in
  let rec format f r = function      (* f: flatten (no breaks)? r: remaining space. *)
    | Text z -&gt; z, r - String.length z
    | Line when f -&gt; &quot; &quot;, r-1        (* Flatten mode: render as space. *)
    | Line -&gt; &quot;\n&quot;, w                (* Break mode: newline, reset remaining to full width. *)
    | Cat (d1, d2) -&gt;
      let s1, r = format f r d1 in
      let s2, r = format f r d2 in
      s1 ^ s2, r
    | Group d -&gt; format (f || width d &lt;= r) r d  (* Flatten if group fits. *)
  in
  fst (format false w d)             (* Start outside any group (not flattening). *)</code></pre>
<p>The <code>format</code> function takes a boolean <code>f</code> (are
we in “flatten” mode?) and the remaining space <code>r</code>. When we
enter a <code>Group</code>, we check if the whole group fits in the
remaining space. If so, we format it in flatten mode (all
<code>Line</code>s become spaces).</p>
<h4 id="stream-based-solution">Stream-Based Solution</h4>
<p>The straightforward solution works, but it has a problem: for each
group, we compute <code>width</code> by traversing the entire subtree,
potentially doing redundant work. The stream-based solution processes
the document incrementally, computing positions as we go.</p>
<p>First, we define a type for document elements that can carry
annotations:</p>
<p><code>ocaml env=ch7 type ('a, 'b) doc_e =                (* Annotated nodes, special for group beginning. *)   TE of 'a * string | LE of 'a | GBeg of 'b | GEnd of 'a</code></p>
<p>The type parameters <code>'a</code> and <code>'b</code> allow
different annotations for different elements. <code>GBeg</code> (group
beginning) has a different type because it will eventually carry the end
position of the group.</p>
<p>Normalize a subdocument to remove empty groups:</p>
<p><code>ocaml env=ch7 let rec norm = function   | Group d -&gt; norm d   | Text "" -&gt; None   | Cat (Text "", d) -&gt; norm d   | d -&gt; Some d</code></p>
<p>Generate the stream of document elements by infix traversal:</p>
<p><code>ocaml env=ch7 let rec gen = function   | Text z -&gt; Yield (TE ((),z), EOP)   | Line -&gt; Yield (LE (), EOP)   | Cat (d1, d2) -&gt; append (gen d1) (gen d2)   | Group d -&gt;     match norm d with     | None -&gt; EOP     | Some d -&gt;       Yield (GBeg (),              append (gen d) (Yield (GEnd (), EOP)))</code></p>
<p>The next pipe computes the position (character count from the
beginning) of each element:</p>
<p>```ocaml env=ch7 let rec docpos curpos = Await (function (* Input
from a doc_e pipe, *) | TE (_, z) -&gt; Yield (TE (curpos, z), (* output
doc_e annotated with position. <em>) docpos (curpos + String.length z))
| LE _ -&gt; (</em> Spaces and line breaks: 1 character. <em>) Yield (LE
curpos, docpos (curpos + 1)) | GBeg _ -&gt; (</em> Groups themselves
have no width. *) Yield (GBeg curpos, docpos curpos) | GEnd _ -&gt;
Yield (GEnd curpos, docpos curpos))</p>
<p>let docpos = docpos 0 (* The whole document starts at position 0.
*)</p>
<pre><code>
Now comes the tricky part. We want to annotate each `GBeg` with the position where the group *ends*, so we can decide whether the group fits on the line. But we see `GBeg` before we see `GEnd`! We need to buffer elements until we see the end of each group:

```ocaml env=ch7
let rec grends grstack =
  Await (function
  | TE _ | LE _ as e -&gt;
    (match grstack with
    | [] -&gt; Yield (e, grends [])          (* No groups waiting -- yield immediately. *)
    | gr::grs -&gt; grends ((e::gr)::grs))   (* Inside a group -- buffer the element. *)
  | GBeg _ -&gt; grends ([]::grstack)        (* Start a new group: push empty buffer. *)
  | GEnd endp -&gt;
    match grstack with                    (* End the group on top of stack. *)
    | [] -&gt; failwith &quot;grends: unmatched group end marker&quot;
    | [gr] -&gt;                             (* Outermost group -- yield everything now. *)
      yield_all
        (GBeg endp::List.rev (GEnd endp::gr))  (* Annotate GBeg with end position. *)
        (grends [])
    | gr::par::grs -&gt;                     (* Nested group -- add to parent&#39;s buffer. *)
      let par = GEnd endp::gr @ [GBeg endp] @ par in
      grends (par::grs))                  (* Could use catenable lists for efficiency. *)</code></pre>
<p>This works, but it has a problem: we wait until the entire group is
processed before yielding anything. For large groups (or groups that
exceed the line width), this is wasteful. We can optimize by flushing
the buffer when a group clearly exceeds the line width – if we know a
group will not fit, there is no need to remember where it ends:</p>
<p>```ocaml skip type grp_pos = Pos of int | Too_far</p>
<p>let rec grends w grstack = let flush tail = (* When a group exceeds
width w, <em>) yield_all (</em> flush the stack – yield everything
buffered. <em>) (rev_concat_map ~prep:(GBeg Too_far) snd grstack) tail
in (</em> Mark flushed groups as Too_far. *) Await (function | TE (curp,
_) | LE curp as e -&gt; (match grstack with (* Track beginning position
of each group. <em>) | [] -&gt; Yield (e, grends w []) (</em> No groups
– yield immediately. <em>) | (begp, <em>)::</em> when curp-begp &gt; w
-&gt; flush (Yield (e, grends w [])) (</em> Group too wide – flush and
yield. <em>) | (begp, gr)::grs -&gt; grends w ((begp, e::gr)::grs))
(</em> Buffer element. <em>) | GBeg begp -&gt; grends w ((begp,
[])::grstack) (</em> New group: remember start position. <em>) | GEnd
endp as e -&gt; match grstack with (</em> No longer fail when stack is
empty – <em>) | [] -&gt; Yield (e, grends w []) (</em> could have been
flushed earlier. <em>) | (begp, <em>)::</em> when endp-begp &gt; w -&gt;
flush (Yield (e, grends w [])) (</em> Group exceeded width – flush.
<em>) | [_, gr] -&gt; (</em> Group fits – annotate with end position. *)
yield_all (GBeg (Pos endp)::List.rev (GEnd endp::gr)) (grends w []) |
(_, gr)::(par_begp, par)::grs -&gt; (* Nested group fits – add to
parent. *) let par = GEnd endp::gr @ [GBeg (Pos endp)] @ par in grends w
((par_begp, par)::grs))</p>
<p>let grends w = grends w [] (* Initial stack is empty. *)</p>
<pre><code>
Finally, the `format` pipe produces the resulting stream of strings. It maintains a stack of booleans indicating which groups are being &quot;flattened&quot; (rendered inline), and the position where the current line would end:

```ocaml skip
let rec format w (inline, endlpos as st) =  (* inline: stack of &quot;flatten this group?&quot; *)
  Await (function                           (* endlpos: position where line ends *)
  | TE (_, z) -&gt; Yield (z, format w st)     (* Text: output directly. *)
  | LE p when List.hd inline -&gt;
    Yield (&quot; &quot;, format w st)                (* In flatten mode: line break -&gt; space. *)
  | LE p -&gt; Yield (&quot;\n&quot;, format w (inline, p+w))  (* Break mode: newline, update endlpos. *)
  | GBeg Too_far -&gt;                         (* Group too wide -- don&#39;t flatten. *)
    format w (false::inline, endlpos)
  | GBeg (Pos p) -&gt;                         (* Group fits if it ends before endlpos. *)
    format w ((p&lt;=endlpos)::inline, endlpos)
  | GEnd _ -&gt; format w (List.tl inline, endlpos))  (* Pop the inline stack. *)

let format w = format w ([false], w)        (* Start with no flattening, full line width. *)</code></pre>
<p>Put the pipes together into a complete pipeline:</p>
<pre><code>+--------+     +-------+     +---------+     +--------+     +----------------+
| gen doc| --&gt; |docpos | --&gt; |grends w | --&gt; |format w| --&gt; |iterate print_s |
+--------+     +-------+     +---------+     +--------+     +----------------+</code></pre>
<p>The data flows from left to right: <code>gen</code> produces document
elements, <code>docpos</code> annotates them with positions,
<code>grends</code> annotates group beginnings with their end positions,
<code>format</code> decides where to break lines and produces strings,
and <code>iterate print_string</code> prints the strings.</p>
<h4 id="factored-solution">Factored Solution</h4>
<p>For maximum flexibility, we can factorize <code>format</code> into
two parts: one that decides where to break lines (producing annotated
document elements), and one that converts those to strings. This allows
different line breaking strategies to be plugged in:</p>
<p>```ocaml skip (* breaks: decides where to break, outputs annotated
doc_e elements <em>) let rec breaks w (inline, endlpos as st) = Await
(function | TE _ as e -&gt; Yield (e, breaks w st) (</em> Pass through
text. <em>) | LE p when List.hd inline -&gt; Yield (TE (p, ” “), breaks
w st) (</em> Flatten: convert to space. <em>) | LE p as e -&gt; Yield
(e, breaks w (inline, p+w)) (</em> Break: keep as LE. *) | GBeg Too_far
as e -&gt; Yield (e, breaks w (false::inline, endlpos)) | GBeg (Pos p)
as e -&gt; Yield (e, breaks w ((p&lt;=endlpos)::inline, endlpos)) | GEnd
_ as e -&gt; Yield (e, breaks w (List.tl inline, endlpos)))</p>
<p>let breaks w = breaks w ([false], w)</p>
<p>(* emit: converts doc_e elements to strings *) let rec emit = Await
(function | TE (_, z) -&gt; Yield (z, emit) (* Text: output directly.
<em>) | LE _ -&gt; Yield (“”, emit) (</em> Line break: output newline.
<em>) | GBeg _ | GEnd _ -&gt; emit) (</em> Group markers: skip. *)</p>
<p>let pretty_print w doc = gen doc &gt;-&gt; docpos &gt;-&gt; grends w
&gt;-&gt; breaks w &gt;-&gt; emit &gt;-&gt; iterate print_string</p>
<pre><code>
Now `breaks` can be replaced with a different strategy (for example, one that adds indentation), and `emit` stays the same. The full pipeline reads like a description of what happens: generate elements, compute positions, annotate groups with their ends, decide where to break, convert to strings, and print.

### 7.10 Exercises

**Exercise 1:** My first impulse was to define lazy list functions as follows:

```ocaml env=ch7
let rec wrong_lzip = function
  | LNil, LNil -&gt; LNil
  | LCons (a1, lazy l1), LCons (a2, lazy l2) -&gt;
      LCons ((a1, a2), lazy (wrong_lzip (l1, l2)))
  | _ -&gt; raise (Invalid_argument &quot;lzip&quot;)

let rec wrong_lmap f = function
  | LNil -&gt; LNil
  | LCons (a, lazy l) -&gt; LCons (f a, lazy (wrong_lmap f l))</code></pre>
<p>What is wrong with these definitions – for which edge cases do they
not work as intended?</p>
<p><strong>Exercise 2:</strong> Cyclic lazy lists.</p>
<ol type="1">
<li><p>Implement a function <code>cycle : 'a list -&gt; 'a llist</code>
that creates a lazy list with elements from a standard list, and the
whole list as the tail after the last element from the input list:
<code>[a1; a2; ...; aN]</code> maps to a cyclic structure where
<code>aN</code> points back to <code>a1</code>. Your function
<code>cycle</code> can either return <code>LNil</code> or fail for an
empty list as argument.</p></li>
<li><p>Note that <code>inv_fact</code> from the lecture defines the
power series for the <span class="math inline">\exp(\cdot)</span>
function (<span class="math inline">\exp(x) = e^x</span>). Using
<code>cycle</code> and <code>inv_fact</code>, define the power series
for <span class="math inline">\sin(\cdot)</span> and <span
class="math inline">\cos(\cdot)</span>, and draw their graphs using
helper functions from the lecture script <code>Lec7.ml</code>.</p></li>
</ol>
<p><strong>Exercise 3:</strong> Modify one of the puzzle solving
programs (either from the previous lecture or from your previous
homework) to work with lazy lists. Implement the necessary higher-order
lazy list functions. Check that indeed displaying only the first
solution when there are multiple solutions in the result takes shorter
than computing solutions by the original program.</p>
<p><strong>Exercise 4:</strong> <em>Hamming’s problem</em>. Generate in
increasing order the numbers of the form <span
class="math inline">2^{a_1} 3^{a_2} 5^{a_3} \ldots p_k^{a_k}</span>,
that is numbers not divisible by prime numbers greater than the <span
class="math inline">k</span>th prime number.</p>
<p>In the original Hamming’s problem posed by Dijkstra, <span
class="math inline">k = 3</span>, which is related to <a
href="http://en.wikipedia.org/wiki/Regular_number">regular
numbers</a>.</p>
<p>Starter code is available in the lecture script
<code>Lec7.ml</code>:</p>
<p>```ocaml env=ch7 let rec lfilter f = function | LNil -&gt; LNil |
LCons (n, ll) -&gt; if f n then LCons (n, lazy (lfilter f (Lazy.force
ll))) else lfilter f (Lazy.force ll)</p>
<p>let primes = let rec sieve = function | LCons(p, nf) -&gt; LCons(p,
lazy (sieve (sift p (Lazy.force nf)))) | LNil -&gt; failwith
“Impossible! Internal error.” and sift p = lfilter (fun n -&gt; n mod p
&lt;&gt; 0) in sieve (l_from 2)</p>
<p>let times ll n = lmap (fun i -&gt; i * n) ll</p>
<p>let rec merge xs ys = match xs, ys with | LCons (x, lazy xr), LCons
(y, lazy yr) -&gt; if x &lt; y then LCons (x, lazy (merge xr ys)) else
if x &gt; y then LCons (y, lazy (merge xs yr)) else LCons (x, lazy
(merge xr yr)) | r, LNil | LNil, r -&gt; r</p>
<p>let hamming k = let _pr = ltake k primes in (* TODO: use primes to
generate smooth numbers <em>) let rec h = LCons (1, lazy ( (</em> TODO
*)h )) in h</p>
<pre><code>
**Exercise 5:** Modify `format` and/or `breaks` to use just a single number instead of a stack of booleans to keep track of what groups should be inlined.

**Exercise 6:** Add **indentation** to the pretty-printer for groups: if a group does not fit in a single line, its consecutive lines are indented by a given amount `tab` of spaces deeper than its parent group lines would be. For comparison, let&#39;s do several implementations.

1. Modify the straightforward implementation of `pretty`.
2. Modify the first pipe-based implementation of `pretty` by modifying the `format` function.
3. Modify the second pipe-based implementation of `pretty` by modifying the `breaks` function. Recover the positions of elements -- the number of characters from the beginning of the document -- by keeping track of the growing offset.
4. (Harder) Modify a pipe-based implementation to provide a different style of indentation: indent the first line of a group, when the group starts on a new line, at the same level as the consecutive lines (rather than at the parent level of indentation).

**Exercise 7:** Write a pipe that takes document elements annotated with linear position, and produces document elements annotated with (line, column) coordinates.

Write another pipe that takes so annotated elements and adds a line number indicator in front of each line. Do not update the column coordinate. Test the pipes by plugging them before the `emit` pipe.
</code></pre>
<p>1: first line 2: second line, etc.</p>
<pre><code>
**Exercise 8:** Write a pipe that consumes document elements `doc_e` and yields the toplevel subdocuments `doc` which would generate the corresponding elements.

You can modify the definition of documents to allow annotations, so that the element annotations are preserved (`gen` should ignore annotations to keep things simple):

```ocaml skip
type &#39;a doc =
  Text of &#39;a * string | Line of &#39;a | Cat of &#39;a doc * &#39;a doc | Group of &#39;a * &#39;a doc</code></pre>
<p><strong>Exercise 9:</strong> (Harder) Design and implement a way to
duplicate arrows outgoing from a pipe-box, that would memoize the
stream, i.e. not recompute everything “upstream” for the composition of
pipes. Such duplicated arrows would behave nicely with pipes reading
from files.</p>
<h2 id="chapter-8-monads">Chapter 8: Monads</h2>
<p>This chapter explores one of functional programming’s most powerful
abstractions: monads. We begin with list comprehensions as a motivating
example, then introduce monadic concepts and examine the monad laws. We
explore the monad-plus extension that adds non-determinism, then work
through various monad instances including the lazy, list, state,
exception, and probability monads. We conclude with monad transformers
for combining monads and cooperative lightweight threads for
concurrency.</p>
<p>The material draws on several excellent resources: Jeff Newbern’s
“All About Monads,” Martin Erwig and Steve Kollmansberger’s
“Probabilistic Functional Programming in Haskell,” and Jerome Vouillon’s
“Lwt: a Cooperative Thread Library.”</p>
<h3 id="list-comprehensions">8.1 List Comprehensions</h3>
<p>Recall the somewhat awkward syntax we used in the Countdown Problem
example from earlier chapters. The nested callback style, while
functional, is hard to read and understand at a glance. The brute-force
generation of expressions looked like this:</p>
<p>```ocaml env=ch8 let combine l r = List.map (fun o -&gt; App (o, l,
r)) [Add; Sub; Mul; Div]</p>
<p>let rec exprs = function | [] -&gt; [] | [n] -&gt; [Val n] | ns -&gt;
split ns |-&gt; (fun (ls, rs) -&gt; exprs ls |-&gt; (fun l -&gt; exprs
rs |-&gt; (fun r -&gt; combine l r)))</p>
<pre><code>
Notice how the nested callbacks pile up: each `|-&gt;` introduces another level of indentation. The generate-and-test scheme used similar nesting:

```ocaml env=ch8
let guard p e = if p e then [e] else []

let solutions ns n =
  choices ns |-&gt; (fun ns&#39; -&gt;
  exprs ns&#39; |-&gt;
    guard (fun e -&gt; eval e = Some n))</code></pre>
<p>The key insight is that we introduced the operator
<code>|-&gt;</code> defined as:</p>
<p><code>ocaml env=ch8 let ( |-&gt; ) x f = concat_map f x</code></p>
<p>This pattern of “for each element in a list, apply a function that
returns a list, then flatten the results” is so common that many
languages provide special syntax for it. We can express such
computations much more elegantly with <em>list comprehensions</em>, a
syntax extension that originated in languages like Haskell and
Python.</p>
<p>In older versions of OCaml with Camlp4, list comprehensions were
loaded via:</p>
<pre><code>#load &quot;dynlink.cma&quot;;;
#load &quot;camlp4o.cma&quot;;;
#load &quot;Camlp4Parsers/Camlp4ListComprehension.cmo&quot;;;</code></pre>
<p>With list comprehensions, we can write expressions that read almost
like set-builder notation in mathematics:</p>
<pre><code>let test = [i * 2 | i &lt;- from_to 2 22; i mod 3 = 0]</code></pre>
<p>This reads as: “the list of <code>i * 2</code> for each
<code>i</code> drawn from <code>from_to 2 22</code> where
<code>i mod 3 = 0</code>.” The <code>&lt;-</code> arrow draws elements
from a generator, and conditions filter which elements are kept.</p>
<p>The translation rules that define list comprehension semantics are
straightforward:</p>
<ul>
<li><code>[expr | ]</code> translates to <code>[expr]</code> – the base
case, a singleton list</li>
<li><code>[expr | v &lt;- generator; more]</code> translates to
<code>generator |-&gt; (fun v -&gt; [expr | more])</code> – draw from a
generator, then recurse</li>
<li><code>[expr | condition; more]</code> translates to
<code>if condition then [expr | more] else []</code> – filter by a
condition</li>
</ul>
<h4 id="revisiting-countdown-with-list-comprehensions">Revisiting
Countdown with List Comprehensions</h4>
<p>Now let us revisit the Countdown Problem code with list
comprehensions. The brute-force generation becomes dramatically cleaner
– compare this to the deeply nested version above:</p>
<pre><code>let rec exprs = function
  | [] -&gt; []
  | [n] -&gt; [Val n]
  | ns -&gt;
      [App (o, l, r) | (ls, rs) &lt;- split ns;
       l &lt;- exprs ls; r &lt;- exprs rs;
       o &lt;- [Add; Sub; Mul; Div]]</code></pre>
<p>The intent is immediately clear: we split the numbers, recursively
build expressions for left and right parts, and try each operator. The
generate-and-test scheme becomes equally elegant:</p>
<pre><code>let solutions ns n =
  [e | ns&#39; &lt;- choices ns;
   e &lt;- exprs ns&#39;; eval e = Some n]</code></pre>
<p>The guard condition <code>eval e = Some n</code> filters out
expressions that do not evaluate to the target value.</p>
<h4 id="more-list-comprehension-examples">More List Comprehension
Examples</h4>
<p>List comprehensions shine when expressing combinatorial algorithms.
Here is computing all subsequences of a list (note that this generates
some intermediate garbage, but the intent is clear):</p>
<pre><code>let rec subseqs l =
  match l with
  | [] -&gt; [[]]
  | x::xs -&gt; [ys | px &lt;- subseqs xs; ys &lt;- [px; x::px]]</code></pre>
<p>For each element <code>x</code>, we recursively compute subsequences
of the tail, then for each such subsequence we include both the version
without <code>x</code> and the version with <code>x</code>
prepended.</p>
<p>Computing permutations can be done via insertion – inserting an
element at every possible position:</p>
<pre><code>let rec insert x = function
  | [] -&gt; [[x]]
  | y::ys&#39; as ys -&gt;
      (x::ys) :: [y::zs | zs &lt;- insert x ys&#39;]

let rec ins_perms = function
  | [] -&gt; [[]]
  | x::xs -&gt; [zs | ys &lt;- ins_perms xs; zs &lt;- insert x ys]</code></pre>
<p>The <code>insert</code> function generates all ways to insert
<code>x</code> into a list. Then <code>ins_perms</code> recursively
permutes the tail and inserts the head at every position.</p>
<p>Alternatively, we can compute permutations via selection – repeatedly
choosing which element comes first:</p>
<pre><code>let rec select = function
  | [x] -&gt; [x, []]
  | x::xs -&gt; (x, xs) :: [y, x::ys | y, ys &lt;- select xs]

let rec sel_perms = function
  | [] -&gt; [[]]
  | xs -&gt; [x::ys | x, xs&#39; &lt;- select xs; ys &lt;- sel_perms xs&#39;]</code></pre>
<p>The <code>select</code> function returns all ways to pick one element
from a list, along with the remaining elements. Then
<code>sel_perms</code> chooses a first element and recursively permutes
the rest.</p>
<h3 id="generalized-comprehensions-binding-operators">8.2 Generalized
Comprehensions: Binding Operators</h3>
<p>The pattern we saw with list comprehensions is remarkably general. In
fact, the same <code>|-&gt;</code> pattern (applying a function that
returns a container, then flattening) works for many types beyond lists.
This is the essence of monads.</p>
<p>OCaml 5 introduced <strong>binding operators</strong> that provide a
clean, native syntax for such computations. Instead of external syntax
extensions like the old Camlp4-based <code>pa_monad</code>, we can now
define custom <code>let*</code> and <code>let+</code> operators that
integrate naturally with the language.</p>
<p>For the list monad, we define these binding operators:</p>
<p><code>ocaml env=ch8 let ( let* ) x f = concat_map f x      (* bind: sequence computations *) let ( let+ ) x f = List.map f x        (* map: apply pure function *) let ( and* ) x y = concat_map (fun a -&gt; List.map (fun b -&gt; (a, b)) y) x let ( and+ ) = ( and* )                (* parallel binding *) let return x = [x]                     (* inject a value into the monad *) let fail = []                          (* the empty computation *)</code></p>
<p>The <code>let*</code> operator is the key: it sequences computations
where each step can produce multiple results. The <code>and*</code>
operator allows binding multiple values in parallel. With these
operators, the expression generation code becomes:</p>
<pre><code>let rec exprs = function
  | [] -&gt; []
  | [n] -&gt; [Val n]
  | ns -&gt;
      let* (ls, rs) = split ns in
      let* l = exprs ls in
      let* r = exprs rs in
      let* o = [Add; Sub; Mul; Div] in
      [App (o, l, r)]</code></pre>
<p>Each <code>let*</code> introduces a binding: the variable on the left
is bound to each value produced by the expression on the right, and the
computation continues with <code>in</code>. This is much more readable
than the nested callbacks we started with.</p>
<p>However, the <code>let*</code> syntax does not directly support
guards (conditions that filter results). If we try to write:</p>
<pre><code>let solutions ns n =
  let* ns&#39; = choices ns in
  let* e = exprs ns&#39; in
  eval e = Some n;  (* Error! *)
  e</code></pre>
<p>We get a type error: the expression expects a list, but
<code>eval e = Some n</code> is a boolean. What can we do?</p>
<p>One approach is to explicitly decide whether to return anything:</p>
<pre><code>let solutions ns n =
  let* ns&#39; = choices ns in
  let* e = exprs ns&#39; in
  if eval e = Some n then [e] else []</code></pre>
<p>But what if we want to check a condition earlier in the computation,
or check multiple conditions? We need a general “guard check” function.
The key insight is that we can use the monad itself to represent success
or failure:</p>
<p><code>ocaml env=ch8 let guard p = if p then [()] else []</code></p>
<p>When the condition <code>p</code> is true, <code>guard</code> returns
<code>[()]</code> – a list with one element (the unit value). When
false, it returns <code>[]</code> – an empty list. Now we can use it in
a binding:</p>
<pre><code>let solutions ns n =
  let* ns&#39; = choices ns in
  let* e = exprs ns&#39; in
  let* () = guard (eval e = Some n) in
  [e]</code></pre>
<p>Why does this work? When the guard succeeds,
<code>let* () = [()]</code> binds unit and continues. When it fails,
<code>let* () = []</code> produces no results – the empty list – so the
rest of the computation is never reached for that branch. This is
exactly the filtering behavior we want!</p>
<h3 id="monads">8.3 Monads</h3>
<p>Now we are ready to define monads properly. A <strong>monad</strong>
is a polymorphic type <code>'a monad</code> (or <code>'a Monad.t</code>)
that supports at least two operations:</p>
<ul>
<li><code>bind : 'a monad -&gt; ('a -&gt; 'b monad) -&gt; 'b monad</code>
– sequence two computations, passing the result of the first to the
second</li>
<li><code>return : 'a -&gt; 'a monad</code> – inject a pure value into
the monad</li>
<li>The infix <code>&gt;&gt;=</code> is commonly used for
<code>bind</code>: <code>let (&gt;&gt;=) a b = bind a b</code></li>
</ul>
<p>The <code>bind</code> operation is the heart of the monad: it takes a
computation that produces an <code>'a</code>, and a function that takes
an <code>'a</code> and produces a new computation yielding
<code>'b</code>. The result is a combined computation that yields
<code>'b</code>.</p>
<p>With OCaml 5’s binding operators, we define <code>let*</code> as an
alias for <code>bind</code>:</p>
<p>```ocaml env=ch8 let bind a b = concat_map b a let return x = [x] let
( let* ) = bind</p>
<p>let solutions ns n = let* ns’ = choices ns in let* e = exprs ns’ in
let* () = guard (eval e = Some n) in return e</p>
<pre><code>
But why does `guard` look the way it does? Let us examine more carefully:

```ocaml env=ch8
let fail = []
let guard p = if p then return () else fail</code></pre>
<p>Steps in monadic computation are composed with <code>let*</code> (or
<code>&gt;&gt;=</code>, which is like <code>|-&gt;</code> for lists).
The key insight is understanding what happens when we bind with an empty
list versus a singleton:</p>
<ul>
<li><code>let* _ = [] in ...</code> does not produce anything – the
continuation is never called, so the computation fails (produces no
results)</li>
<li><code>let* _ = [()] in ...</code> calls the continuation once with
<code>()</code>, which simply continues the computation unchanged</li>
</ul>
<p>This is why <code>guard</code> works: returning <code>[()]</code>
means “succeed with unit” and returning <code>[]</code> means “fail with
no results.” The unit value itself is a dummy – we only care whether the
list is empty or not.</p>
<p>Throwing away the binding argument is a common pattern. With binding
operators, we use <code>let* () = ...</code> or
<code>let* _ = ...</code> to indicate we do not need the bound
value:</p>
<p><code>ocaml env=ch8 let (&gt;&gt;=) a b = bind a b let (&gt;&gt;) m f = m &gt;&gt;= (fun _ -&gt; f)</code></p>
<p>The <code>&gt;&gt;</code> operator (called “sequence” or “then”) is
useful when you want to perform a computation for its effect but discard
its result.</p>
<h4 id="the-binding-operator-syntax">The Binding Operator Syntax</h4>
<p>For reference, OCaml 5’s binding operators translate as follows:</p>
<table>
<colgroup>
<col style="width: 38%" />
<col style="width: 61%" />
</colgroup>
<thead>
<tr>
<th>Source</th>
<th>Translation</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>let* x = exp in body</code></td>
<td><code>bind exp (fun x -&gt; body)</code></td>
</tr>
<tr>
<td><code>let+ x = exp in body</code></td>
<td><code>map (fun x -&gt; body) exp</code></td>
</tr>
<tr>
<td><code>let* () = exp in body</code></td>
<td><code>bind exp (fun () -&gt; body)</code></td>
</tr>
<tr>
<td><code>let* x = e1 and* y = e2 in body</code></td>
<td><code>bind (and* e1 e2) (fun (x, y) -&gt; body)</code></td>
</tr>
</tbody>
</table>
<p>The binding operators <code>let*</code>, <code>let+</code>,
<code>and*</code>, and <code>and+</code> must be defined in scope. These
are regular OCaml operators and require no syntax extensions – a
significant improvement over the old Camlp4 approach.</p>
<p>Note: For pattern matching in bindings, if the pattern is refutable
(can fail to match), the monadic operation should handle the failure
appropriately. For example, <code>let* Some x = e in body</code>
requires a way to handle the <code>None</code> case.</p>
<h3 id="monad-laws">8.4 Monad Laws</h3>
<p>Not every type with <code>bind</code> and <code>return</code>
operations is a proper monad. A parametric data type is a monad only if
its <code>bind</code> and <code>return</code> operations meet three
fundamental axioms:</p>
<p><span class="math display">
\begin{aligned}
\text{bind}\ (\text{return}\ a)\ f &amp;\approx f\ a &amp; \text{(left
identity)} \\
\text{bind}\ a\ (\lambda x.\text{return}\ x) &amp;\approx a &amp;
\text{(right identity)} \\
\text{bind}\ (\text{bind}\ a\ (\lambda x.b))\ (\lambda y.c) &amp;\approx
\text{bind}\ a\ (\lambda x.\text{bind}\ b\ (\lambda y.c)) &amp;
\text{(associativity)}
\end{aligned}
</span></p>
<p>Let us understand what these laws mean:</p>
<ul>
<li><strong>Left identity</strong>: If you inject a value with
<code>return</code> and immediately bind it to a function, you get the
same result as just applying the function. The <code>return</code>
operation should not add any extra “effects.”</li>
<li><strong>Right identity</strong>: If you bind a computation to
<code>return</code>, you get back the same computation. The
<code>return</code> operation is neutral.</li>
<li><strong>Associativity</strong>: Binding is associative – it does not
matter how you group nested binds. This means
<code>let* x = (let* y = a in b) in c</code> is equivalent to
<code>let* y = a in let* x = b in c</code> (when <code>x</code> does not
appear free in <code>b</code>).</li>
</ul>
<p>You should verify that these laws hold for our list monad:</p>
<p><code>ocaml env=ch8 let bind a b = concat_map b a let return x = [x]</code></p>
<p>For example, to verify left identity: <code>bind (return a) f</code>
= <code>bind [a] f</code> = <code>concat_map f [a]</code> =
<code>f a</code>. The other laws can be verified similarly.</p>
<h3 id="monoid-laws-and-monad-plus">8.5 Monoid Laws and Monad-Plus</h3>
<p>The list monad has an additional structure beyond just
<code>bind</code> and <code>return</code>: it supports combining
multiple computations and representing failure. This leads us to the
concept of a <strong>monoid</strong>.</p>
<p>A monoid is a type with at least two operations:</p>
<ul>
<li><code>mzero : 'a monoid</code> – an identity element (think: zero,
or the empty container)</li>
<li><code>mplus : 'a monoid -&gt; 'a monoid -&gt; 'a monoid</code> – a
combining operation (think: addition, or concatenation)</li>
</ul>
<p>These operations must meet the standard monoid laws:</p>
<p><span class="math display">
\begin{aligned}
\text{mplus}\ \text{mzero}\ a &amp;\approx a &amp; \text{(left
identity)} \\
\text{mplus}\ a\ \text{mzero} &amp;\approx a &amp; \text{(right
identity)} \\
\text{mplus}\ a\ (\text{mplus}\ b\ c) &amp;\approx \text{mplus}\
(\text{mplus}\ a\ b)\ c &amp; \text{(associativity)}
\end{aligned}
</span></p>
<p>We define <code>fail</code> as a synonym for <code>mzero</code> and
infix <code>++</code> for <code>mplus</code>. For lists,
<code>mzero</code> is <code>[]</code> and <code>mplus</code> is
<code>@</code> (append).</p>
<p>Fusing monads and monoids gives the most popular general flavor of
monads, which we call <strong>monad-plus</strong> after Haskell. A
monad-plus is a monad that also has monoid structure, with additional
axioms relating the “addition” (<code>mplus</code>) and “multiplication”
(<code>bind</code>):</p>
<p><span class="math display">
\begin{aligned}
\text{bind}\ \text{mzero}\ f &amp;\approx \text{mzero} \\
\text{bind}\ m\ (\lambda x.\text{mzero}) &amp;\approx \text{mzero}
\end{aligned}
</span></p>
<p>These laws say that <code>mzero</code> acts like a “zero” for
<code>bind</code>: binding from zero produces zero, and binding to a
function that always returns zero also produces zero. This is analogous
to how <span class="math inline">0 \times x = 0</span> and <span
class="math inline">x \times 0 = 0</span> in arithmetic.</p>
<p>Using infix notation with <span class="math inline">\oplus</span> for
<code>mplus</code>, <span class="math inline">\mathbf{0}</span> for
<code>mzero</code>, <span class="math inline">\triangleright</span> for
<code>bind</code>, and <span class="math inline">\mathbf{1}</span> for
<code>return</code>, the complete monad-plus axioms are:</p>
<p><span class="math display">
\begin{aligned}
\mathbf{0} \oplus a &amp;\approx a \\
a \oplus \mathbf{0} &amp;\approx a \\
a \oplus (b \oplus c) &amp;\approx (a \oplus b) \oplus c \\
\mathbf{1}\ x \triangleright f &amp;\approx f\ x \\
a \triangleright \lambda x.\mathbf{1}\ x &amp;\approx a \\
(a \triangleright \lambda x.b) \triangleright \lambda y.c &amp;\approx a
\triangleright (\lambda x.b \triangleright \lambda y.c) \\
\mathbf{0} \triangleright f &amp;\approx \mathbf{0} \\
a \triangleright (\lambda x.\mathbf{0}) &amp;\approx \mathbf{0}
\end{aligned}
</span></p>
<p>The list type has a natural monad and monoid structure:</p>
<p><code>ocaml env=ch8 let mzero = [] let mplus = (@) let bind a b = concat_map b a let return a = [a]</code></p>
<p>Given any monad-plus, we can define useful derived operations:</p>
<p><code>ocaml env=ch8 let fail = mzero let failwith _ = fail let (++) = mplus let (&gt;&gt;=) a b = bind a b let guard p = if p then return () else fail</code></p>
<p>Now we can see that <code>guard</code> is defined in terms of the
monad-plus structure: it returns the identity element
(<code>return ()</code>) on success, or the zero element
(<code>fail</code>) on failure.</p>
<h3 id="backtracking-computation-with-choice">8.6 Backtracking:
Computation with Choice</h3>
<p>We have seen <code>mzero</code> (i.e., <code>fail</code>) in the
countdown problem – it represents a computation that produces no
results. But what about <code>mplus</code>? The <code>mplus</code>
operation combines two computations, giving us a way to express
<em>choice</em>: try this computation, or try that one.</p>
<p>Here is an example from a puzzle solver where <code>mplus</code>
creates a choice point:</p>
<p>```ocaml skip let find_to_eat n island_size num_islands empty_cells =
let honey = honey_cells n empty_cells in</p>
<p>let rec find_board s = match visit_cell s with | None -&gt; let* () =
guard (s.been_islands = num_islands) in return s.eaten | Some (cell, s)
-&gt; let* s = find_island cell (fresh_island s) in let* () = guard
(s.been_size = island_size) in find_board s</p>
<p>and find_island current s = let s = keep_cell current s in neighbors
n empty_cells current |&gt; foldM (fun neighbor s -&gt; if CellSet.mem
neighbor s.visited then return s else let choose_eat = if s.more_to_eat
&lt;= 0 then fail else return (eat_cell neighbor s) and choose_keep = if
s.been_size &gt;= island_size then fail else find_island neighbor s in
mplus choose_eat choose_keep) (* Choice point! *) s in</p>
<p>let cells_to_eat = List.length honey - island_size * num_islands in
find_board (init_state honey cells_to_eat)</p>
<pre><code>
The line `mplus choose_eat choose_keep` creates a choice point: the algorithm can either eat the cell (removing it from consideration) or keep it as part of the current island. When we use the list monad as our monad-plus, this explores *all* possible choices, collecting all solutions. The monad-plus structure handles the bookkeeping of backtracking automatically -- we just express the choices declaratively.

### 8.7 Monad Flavors

Monads &quot;wrap around&quot; a type, but some monads need an additional type parameter. For example, a state monad might be parameterized by the type of state it carries. Usually the additional type does not change while within a monad, so we stick to `&#39;a monad` rather than `(&#39;s, &#39;a) monad`.

As monad-plus shows, things get interesting when we add more operations to a basic monad. Different &quot;flavors&quot; of monads provide different capabilities. Here are the most common ones:

**Monads with access:**
</code></pre>
<p>access : ’a monad -&gt; ’a</p>
<pre><code>
An `access` operation lets you extract the value from the monad. Not all monads support this -- some only allow you to &quot;run&quot; the monad at the top level. Example: the lazy monad, where `access` is `Lazy.force`.

**Monad-plus (non-deterministic computation):**
</code></pre>
<p>mzero : ’a monad mplus : ’a monad -&gt; ’a monad -&gt; ’a monad</p>
<pre><code>
We have already seen this. The monad-plus flavor supports failure and choice, enabling backtracking search.

**Monads with state (parameterized by type `store`):**
</code></pre>
<p>get : store monad put : store -&gt; unit monad</p>
<pre><code>
These operations let you read and write a piece of state that is threaded through the computation. There is a &quot;canonical&quot; state monad we will examine later. Related monads include:
- The **writer monad**: has `tell` (append to a log) and `listen` (read the log)
- The **reader monad**: has `ask` (read an environment) and `local` to modify the environment for a sub-computation:
</code></pre>
<p>local : (store -&gt; store) -&gt; ’a monad -&gt; ’a monad</p>
<pre><code>
**Exception/error monads (parameterized by type `excn`):**
</code></pre>
<p>throw : excn -&gt; ’a monad catch : ’a monad -&gt; (excn -&gt; ’a
monad) -&gt; ’a monad</p>
<pre><code>
These provide structured error handling within the monad. The `throw` operation raises an exception; `catch` handles it.

**Continuation monad:**
</code></pre>
<p>callCC : ((’a -&gt; ’b monad) -&gt; ’a monad) -&gt; ’a monad</p>
<pre><code>
The continuation monad gives you access to the &quot;rest of the computation&quot; as a first-class value. This is powerful but complex; we will not cover continuations in detail here.

**Probabilistic computation:**
</code></pre>
<p>choose : float -&gt; ’a monad -&gt; ’a monad -&gt; ’a monad</p>
<pre><code>
The `choose p a b` operation selects `a` with probability `p` and `b` with probability `1-p`. This enables reasoning about probability distributions. The laws ensure that probability behaves correctly:

$$
\begin{aligned}
a \oplus_0 b &amp;\approx b \\
a \oplus_p b &amp;\approx b \oplus_{1-p} a \\
a \oplus_p (b \oplus_q c) &amp;\approx (a \oplus_{\frac{p}{p+q-pq}} b) \oplus_{p+q-pq} c \\
a \oplus_p a &amp;\approx a
\end{aligned}
$$

**Parallel computation (monad with access and parallel bind):**
</code></pre>
<p>parallel : ’a monad -&gt; ’b monad -&gt; (’a -&gt; ’b -&gt; ’c monad)
-&gt; ’c monad</p>
<pre><code>
The `parallel` operation runs two computations concurrently and combines their results. Example: lightweight threads like in the Lwt library.

### 8.8 Interlude: The Module System

Before we implement various monads, we need to understand OCaml&#39;s module system, which provides the infrastructure for defining monads in a reusable, generic way. This section provides a brief overview of the key concepts.

Modules collect related type definitions and operations together. Module values are introduced with `struct ... end` (called *structures*), and module types with `sig ... end` (called *signatures*). A structure is a package of definitions; a signature is an interface that specifies what a structure must provide.

A source file `source.ml` defines a module `Source`. A file `source.mli` defines its type.

In the module level, modules are defined with `module ModuleName = ...` or `module ModuleName : MODULE_TYPE = ...`, and module types with `module type MODULE_TYPE = ...`.

Locally in expressions, modules are defined with `let module M = ... in ...`.

The content of a module is made visible with `open Module`. Module `Pervasives` (now `Stdlib`) is initially visible.

Content of a module is included into another module with `include Module`.

**Functors** are module functions -- functions from modules to modules. They are the key to writing generic code that works with any monad:
</code></pre>
<p>module Funct = functor (Arg : sig … end) -&gt; struct … end (* Or
equivalently: *) module Funct (Arg : sig … end) = struct … end</p>
<pre><code>
Functors can return functors, and modules can be parameterized by multiple modules. Functor application always uses parentheses: `Funct (struct ... end)`.

A signature `MODULE_TYPE with type t_name = ...` is like `MODULE_TYPE` but with `t_name` made more specific. This is useful when you want to expose the concrete type after applying a functor. We can also include signatures with `include MODULE_TYPE`.

Finally, we can pass around modules in normal functions using first-class modules:

```ocaml env=ch8
module type T = sig val g : int -&gt; int end

let f mod_v x =
  let module M = (val mod_v : T) in
  M.g x
(* val f : (module T) -&gt; int -&gt; int = &lt;fun&gt; *)

let test = f (module struct let g i = i*i end : T)
(* val test : int -&gt; int = &lt;fun&gt; *)</code></pre>
<h3 id="the-two-metaphors">8.9 The Two Metaphors</h3>
<p>Monads are abstract, but two complementary metaphors can help build
intuition for what they are and how they work.</p>
<h4 id="monads-as-containers">Monads as Containers</h4>
<p>The first metaphor views a monad as a <strong>quarantine
container</strong>. Think of it like a sealed box:</p>
<ul>
<li>We can put something into the container with <code>return</code> –
this “seals” a pure value inside the monad</li>
<li>We can operate on the contents, but the result must stay in the
container – we cannot simply extract values</li>
</ul>
<p>The <code>lift</code> function applies a pure function to the
contents of a monad, keeping the result wrapped:</p>
<p><code>ocaml env=ch8 let lift f m =   let* x = m in   return (f x) (* val lift : ('a -&gt; 'b) -&gt; 'a monad -&gt; 'b monad *)</code></p>
<p>We can also “flatten” nested containers. If we have a monad
containing another monad, <code>join</code> unwraps one layer – but the
result is still in a monad, so the quarantine is not broken:</p>
<p><code>ocaml env=ch8 let join m =   let* x = m in   x (* val join : ('a monad) monad -&gt; 'a monad *)</code></p>
<p>The quarantine container for a <strong>monad-plus</strong> is more
like a collection: it can be empty (failure), contain one element
(success), or contain multiple elements (multiple solutions).</p>
<p>Monads with access allow us to extract the resulting element from the
container. Other monads provide a <code>run</code> operation that
exposes “what really happened behind the quarantine” – for example, the
state monad’s <code>run</code> takes an initial state and returns both
the final value and the final state.</p>
<h4 id="monads-as-computation">Monads as Computation</h4>
<p>The second metaphor views a monad as a way to structure computation.
Each <code>let*</code> binding is a step in a sequence, and the monad
controls how steps are connected. The physical metaphor is an
<strong>assembly line</strong>:</p>
<pre><code>let assemblyLine w =
  let* c = makeChopsticks w in    (* Worker makes chopsticks *)
  let* c&#39; = polishChopsticks c in (* Worker polishes them *)
  let* c&#39;&#39; = wrapChopsticks c&#39; in (* Worker wraps them *)
  return c&#39;&#39;                       (* Final product goes out *)</code></pre>
<p>Each worker (operation) takes material from the previous step and
produces something for the next step. The monad defines what happens
between steps – for lists, it means “do this for each element”; for
state, it means “thread the state through”; for exceptions, it means
“propagate errors.”</p>
<p>Any expression can be systematically translated into a monadic form.
For lambda-terms:</p>
<p><span class="math display">
\begin{aligned}
[\![ N ]\!] &amp;= \text{return}\ N &amp; \text{(constant)} \\
[\![ x ]\!] &amp;= \text{return}\ x &amp; \text{(variable)} \\
[\![ \lambda x.a ]\!] &amp;= \text{return}\ (\lambda x.[\![ a ]\!])
&amp; \text{(function)} \\
[\![ \text{let}\ x = a\ \text{in}\ b ]\!] &amp;= \text{bind}\ [\![ a
]\!]\ (\lambda x.[\![ b ]\!]) &amp; \text{(local definition)} \\
[\![ a\ b ]\!] &amp;= \text{bind}\ [\![ a ]\!]\ (\lambda
v_a.\text{bind}\ [\![ b ]\!]\ (\lambda v_b.v_a\ v_b)) &amp;
\text{(application)}
\end{aligned}
</span></p>
<p>This translation inserts <code>bind</code> at every point where
execution flows from one subexpression to another. The beauty of this
approach is that once an expression is spread over a monad, its
computation can be monitored, logged, or affected without modifying the
expression itself. This is the key to implementing effects like state,
exceptions, or non-determinism in a purely functional way.</p>
<h3 id="monad-classes-and-instances">8.10 Monad Classes and
Instances</h3>
<p>Now we will see how to implement monads in OCaml using the module
system. To implement a monad, we need to provide the implementation
type, <code>return</code>, and <code>bind</code> operations. Here is the
minimal signature:</p>
<p><code>ocaml env=ch8 module type MONAD = sig   type 'a t   val return : 'a -&gt; 'a t   val bind : 'a t -&gt; ('a -&gt; 'b t) -&gt; 'b t end</code></p>
<p>This is the “class” that all monads must implement. Alternatively, we
could start from <code>return</code>, <code>lift</code>, and
<code>join</code> operations – these are mathematically equivalent
starting points.</p>
<p>The power of functors is that we can define a suite of
general-purpose functions that work for <em>any</em> monad, just based
on these two operations:</p>
<p>```ocaml env=ch8 module type MONAD_OPS = sig type ’a monad include
MONAD with type ’a t := ’a monad val ( let* ) : ’a monad -&gt; (’a -&gt;
’b monad) -&gt; ’b monad val ( let+ ) : ’a monad -&gt; (’a -&gt; ’b)
-&gt; ’b monad val ( &gt;&gt;= ) : ’a monad -&gt; (’a -&gt; ’b monad)
-&gt; ’b monad val foldM : (’a -&gt; ’b -&gt; ’a monad) -&gt; ’a -&gt;
’b list -&gt; ’a monad val whenM : bool -&gt; unit monad -&gt; unit
monad val lift : (’a -&gt; ’b) -&gt; ’a monad -&gt; ’b monad val
(&gt;&gt;|) : ’a monad -&gt; (’a -&gt; ’b) -&gt; ’b monad val join : ’a
monad monad -&gt; ’a monad val ( &gt;=&gt;) : (’a -&gt; ’b monad) -&gt;
(’b -&gt; ’c monad) -&gt; ’a -&gt; ’c monad end</p>
<p>module MonadOps (M : MONAD) = struct open M type ‘a monad = ’a t let
run x = x let ( let* ) a b = bind a b let ( let+ ) a f = bind a (fun x
-&gt; return (f x)) let (&gt;&gt;=) a b = bind a b let rec foldM f a =
function | [] -&gt; return a | x::xs -&gt; let* a’ = f a x in foldM f a’
xs let whenM p s = if p then s else return () let lift f m = let* x = m
in return (f x) let (&gt;&gt;|) a b = lift b a let join m = let* x = m
in x let (&gt;=&gt;) f g = fun x -&gt; let* y = f x in g y end</p>
<pre><code>
We make the monad &quot;safe&quot; by keeping its type abstract. The `run` function exposes the underlying representation -- &quot;what really happened behind the scenes&quot;:

```ocaml env=ch8
module Monad (M : MONAD) : sig
  include MONAD_OPS
  val run : &#39;a monad -&gt; &#39;a M.t
end = struct
  include M
  include MonadOps(M)
end</code></pre>
<p>The pattern here is important: we take a minimal implementation
(<code>M : MONAD</code>) and produce a full-featured monad module with
all the derived operations.</p>
<h4 id="monad-plus-classes">Monad-Plus Classes</h4>
<p>The monad-plus class extends the basic monad with failure and choice.
Implementations need to provide <code>mzero</code> and
<code>mplus</code> in addition to <code>return</code> and
<code>bind</code>:</p>
<p>```ocaml env=ch8 module type MONAD_PLUS = sig include MONAD val mzero
: ’a t val mplus : ’a t -&gt; ’a t -&gt; ’a t end</p>
<p>module type MONAD_PLUS_OPS = sig include MONAD_OPS val mzero : ’a
monad val mplus : ’a monad -&gt; ’a monad -&gt; ’a monad val fail : ’a
monad val (++) : ’a monad -&gt; ’a monad -&gt; ’a monad val guard : bool
-&gt; unit monad val msum_map : (’a -&gt; ’b monad) -&gt; ’a list -&gt;
’b monad end</p>
<p>module MonadPlusOps (M : MONAD_PLUS) = struct open M include
MonadOps(M) let fail = mzero let (++) a b = mplus a b let guard p = if p
then return () else fail let msum_map f l = List.fold_right (fun a acc
-&gt; mplus (f a) acc) l mzero end</p>
<p>module MonadPlus (M : MONAD_PLUS) : sig include MONAD_PLUS_OPS val
run : ’a monad -&gt; ’a M.t end = struct include M include
MonadPlusOps(M) end</p>
<pre><code>
We also need a class for computations with state. This signature will be included in state monads:

```ocaml env=ch8
module type STATE = sig
  type store
  type &#39;a t
  val get : store t
  val put : store -&gt; unit t
end</code></pre>
<h3 id="monad-instances">8.11 Monad Instances</h3>
<p>Now let us see concrete implementations of various monads.</p>
<h4 id="the-lazy-monad">The Lazy Monad</h4>
<p>If you find OCaml’s laziness notation (with <code>lazy</code> and
<code>Lazy.force</code> everywhere) too heavy, you can use a monad! The
lazy monad wraps lazy computations:</p>
<p>```ocaml env=ch8 module LazyM = Monad (struct type ’a t = ’a Lazy.t
let bind a b = lazy (Lazy.force (b (Lazy.force a))) let return a = lazy
a end)</p>
<p>let laccess m = Lazy.force (LazyM.run m)</p>
<pre><code>
The `bind` operation creates a new lazy value that, when forced, forces `a`, passes the result to `b`, and forces the result. The `laccess` function forces the final lazy value to get the result.

#### The List Monad

Our familiar list monad is a monad-plus, supporting non-deterministic computation:

```ocaml env=ch8
module ListM = MonadPlus (struct
  type &#39;a t = &#39;a list
  let bind a b = concat_map b a
  let return a = [a]
  let mzero = []
  let mplus = List.append
end)</code></pre>
<h4 id="backtracking-parameterized-by-monad-plus">Backtracking
Parameterized by Monad-Plus</h4>
<p>Here is the power of abstraction: we can write the Countdown solver
parameterized by <em>any</em> monad-plus. The same code works with lists
(exploring all solutions), lazy lists (computing solutions on demand),
or any other monad-plus implementation:</p>
<p>```ocaml env=ch8 module Countdown (M : MONAD_PLUS_OPS) = struct open
M (* Open the module to make monad operations visible *)</p>
<p>let rec insert x = function (* All choice-introducing operations
<em>) | [] -&gt; return [x] (</em> need to happen in the monad <em>) |
y::ys as xs -&gt; let</em> xys = insert x ys in return (x::xs) ++ return
(y::xys)</p>
<p>let rec choices = function | [] -&gt; return [] | x::xs -&gt; let*
cxs = choices xs in (* Choosing which numbers in what order <em>) return
cxs ++ insert x cxs (</em> and now whether with or without x *)</p>
<p>type op = Add | Sub | Mul | Div</p>
<p>let apply op x y = match op with | Add -&gt; x + y | Sub -&gt; x - y
| Mul -&gt; x * y | Div -&gt; x / y</p>
<p>let valid op x y = match op with | Add -&gt; x &lt;= y | Sub -&gt; x
&gt; y | Mul -&gt; x &lt;= y &amp;&amp; x &lt;&gt; 1 &amp;&amp; y
&lt;&gt; 1 | Div -&gt; x mod y = 0 &amp;&amp; y &lt;&gt; 1</p>
<p>type expr = Val of int | App of op * expr * expr</p>
<p>let op2str = function | Add -&gt; “+” | Sub -&gt; “-” | Mul -&gt; “*”
| Div -&gt; “/”</p>
<p>let rec expr2str = function (* We will provide solutions as strings
*) | Val n -&gt; string_of_int n | App (op, l, r) -&gt; “(” ^ expr2str l
^ op2str op ^ expr2str r ^ “)”</p>
<p>let combine (l, x) (r, y) o = (* Try out an operator <em>) let</em>
() = guard (valid o x y) in return (App (o, l, r), apply o x y)</p>
<p>let split l = (* Another choice: which numbers go into which argument
<em>) let rec aux lhs = function | [] | [_] -&gt; fail (</em> Both
arguments need numbers *) | [y; z] -&gt; return (List.rev (y::lhs), [z])
| hd::rhs -&gt; let lhs = hd::lhs in return (List.rev lhs, rhs) ++ aux
lhs rhs in aux [] l</p>
<p>let rec results = function (* Build possible expressions once numbers
<em>) | [] -&gt; fail (</em> have been picked <em>) | [n] -&gt; let</em>
() = guard (n &gt; 0) in return (Val n, n) | ns -&gt; let* (ls, rs) =
split ns in let* lx = results ls in let* ly = results rs in (* Collect
solutions using each operator *) msum_map (combine lx ly) [Add; Sub;
Mul; Div]</p>
<p>let solutions ns n = (* Solve the problem: <em>) let</em> ns’ =
choices ns in (* pick numbers and their order, <em>) let</em> (e, m) =
results ns’ in (* build possible expressions, <em>) let</em> () = guard
(m = n) in (* check if the expression gives target value, <em>) return
(expr2str e) (</em> “print” the solution *) end</p>
<pre><code>
#### Understanding Laziness

Now let us explore a practical question: what if we only want *one* solution, not all of them? With the list monad, we compute all solutions even if we only look at the first one. Can laziness help?

Let us measure execution times to find out:

```ocaml env=ch8
let time f =
  let tbeg = Unix.gettimeofday () in
  let res = f () in
  let tend = Unix.gettimeofday () in
  tend -. tbeg, res</code></pre>
<p>With the list monad:</p>
<p><code>ocaml env=ch8 module ListCountdown = Countdown (ListM) let test1 () = ListM.run (ListCountdown.solutions [1;3;7;10;25;50] 765) let t1, sol1 = time test1 (* val t1 : float = 2.28... *) (* val sol1 : string list = ["((25-(3+7))*(1+50))"; "(((25-3)-7)*(1+50))"; ...] *)</code></p>
<p>Finding all 49 solutions takes about 2.3 seconds. What if we want
only one solution? Laziness to the rescue!</p>
<p>Our first attempt uses an “odd lazy list” – a list where the tail is
lazy but the head is strict:</p>
<p>```ocaml env=ch8 type ’a llist = LNil | LCons of ’a * ’a llist
Lazy.t</p>
<p>let rec ltake n = function | LCons (a, lazy l) when n &gt; 0 -&gt;
a::(ltake (n-1) l) | _ -&gt; []</p>
<p>let rec lappend l1 l2 = match l1 with | LNil -&gt; l2 | LCons (hd,
tl) -&gt; LCons (hd, lazy (lappend (Lazy.force tl) l2))</p>
<p>let rec lconcat_map f = function | LNil -&gt; LNil | LCons (a, lazy
l) -&gt; lappend (f a) (lconcat_map f l)</p>
<p>module LListM = MonadPlus (struct type ’a t = ’a llist let bind a b =
lconcat_map b a let return a = LCons (a, lazy LNil) let mzero = LNil let
mplus = lappend end)</p>
<pre><code>
But testing shows disappointing results: the odd lazy list still takes about 2.5 seconds just to create the lazy list! The elements are almost all computed by the time we get the first one.

Why? Because whenever we pattern match on `LCons (hd, tl)`, we have already evaluated the head. And when building lists with `mplus`, the head of the first list is computed immediately.

What about using the **option monad** to find just the first solution?

```ocaml env=ch8
module OptionM = MonadPlus (struct
  type &#39;a t = &#39;a option
  let bind a b =
    match a with None -&gt; None | Some x -&gt; b x
  let return a = Some a
  let mzero = None
  let mplus a b = match a with None -&gt; b | Some _ -&gt; a
end)</code></pre>
<p>This very quickly computes… nothing! The option monad returns
<code>None</code>.</p>
<p>Why? The <code>OptionM</code> monad (Haskell’s <code>Maybe</code>
monad) is good for computations that might fail, but it does not
<em>search</em> – its <code>mplus</code> just picks the first
non-<code>None</code> value. Since our search often needs to backtrack
when a choice leads to failure, option gives up too early.</p>
<p>Our odd lazy list type is not lazy <em>enough</em>. Whenever we
“make” a choice with <code>a ++ b</code> or <code>msum_map</code>, it
computes the first candidate for each choice path immediately. We need
<strong>even lazy lists</strong> – lists where even the outermost
constructor is wrapped in <code>lazy</code>:</p>
<p>```ocaml env=ch8 type ’a lazy_list = ’a lazy_list_ Lazy.t and ’a
lazy_list_ = LazNil | LazCons of ’a * ’a lazy_list</p>
<p>let rec laztake n = function | lazy (LazCons (a, l)) when n &gt; 0
-&gt; a::(laztake (n-1) l) | _ -&gt; []</p>
<p>let rec append_aux l1 l2 = match l1 with | lazy LazNil -&gt;
Lazy.force l2 | lazy (LazCons (hd, tl)) -&gt; LazCons (hd, lazy
(append_aux tl l2))</p>
<p>let lazappend l1 l2 = lazy (append_aux l1 l2)</p>
<p>let rec concat_map_aux f = function | lazy LazNil -&gt; LazNil | lazy
(LazCons (a, l)) -&gt; append_aux (f a) (lazy (concat_map_aux f l))</p>
<p>let lazconcat_map f l = lazy (concat_map_aux f l)</p>
<p>module LazyListM = MonadPlus (struct type ’a t = ’a lazy_list let
bind a b = lazconcat_map b a let return a = lazy (LazCons (a, lazy
LazNil)) let mzero = lazy LazNil let mplus = lazappend end)</p>
<pre><code>
Now the first solution takes only about 0.37 seconds -- considerably less time than the 2.3 seconds for all solutions! The next 9 solutions are almost computed once the first one is (just 0.23 seconds more). But computing all 49 solutions takes about 4 seconds -- nearly twice as long as without laziness. This is the price we pay for lazy computation: overhead when we do need all results.

The lesson: even lazy lists enable true lazy search, but they come with overhead. Choose the right monad for your use case.

#### The Exception Monad

OCaml has built-in exceptions that are efficient and flexible. However, monadic exceptions have advantages in certain situations:

- They are safer in multi-threading contexts (no risk of unhandled exceptions escaping)
- They compose well with other monads (via monad transformers)
- They make the possibility of failure explicit in the type

The monadic lightweight-thread library Lwt has `throw` (called `fail` there) and `catch` operations in its monad for exactly these reasons.

```ocaml env=ch8
module ExceptionM (Excn : sig type t end) : sig
  type excn = Excn.t
  type &#39;a t = OK of &#39;a | Bad of excn
  include MONAD_OPS
  val run : &#39;a monad -&gt; &#39;a t
  val throw : excn -&gt; &#39;a monad
  val catch : &#39;a monad -&gt; (excn -&gt; &#39;a monad) -&gt; &#39;a monad
end = struct
  type excn = Excn.t
  module M = struct
    type &#39;a t = OK of &#39;a | Bad of excn
    let return a = OK a
    let bind m b = match m with
      | OK a -&gt; b a
      | Bad e -&gt; Bad e
  end
  include M
  include MonadOps(M)
  let throw e = Bad e
  let catch m handler = match m with
    | OK _ -&gt; m
    | Bad e -&gt; handler e
end</code></pre>
<h4 id="the-state-monad">The State Monad</h4>
<p>The state monad threads a piece of mutable state through a
computation without actually using mutation. The key insight is that a
stateful computation can be represented as a <em>function</em> from the
current state to a pair of (result, new state):</p>
<p><code>ocaml env=ch8 module StateM (Store : sig type t end) : sig   type store = Store.t   type 'a t = store -&gt; 'a * store  (* A stateful computation *)   include MONAD_OPS   include STATE with type 'a t := 'a monad                  and type store := store   val run : 'a monad -&gt; 'a t end = struct   type store = Store.t   module M = struct     type 'a t = store -&gt; 'a * store     let return a = fun s -&gt; a, s     (* Return value, keep state unchanged *)     let bind m b = fun s -&gt; let a, s' = m s in b a s'   end                          (* Run m, then pass result and new state to b *)   include M   include MonadOps(M)   let get = fun s -&gt; s, s            (* Return the current state *)   let put s' = fun _ -&gt; (), s'       (* Replace the state, return unit *) end</code></p>
<p>The <code>bind</code> operation sequences two stateful computations:
it runs the first one with the initial state, then passes both the
result and the new state to the second computation.</p>
<p>The state monad is useful to hide the threading of a “current” value
through a computation. Here is an example that renames variables in
lambda-terms to eliminate potential name clashes (alpha-conversion):</p>
<p>```ocaml skip type term = | Var of string | Lam of string * term |
App of term * term</p>
<p>let (!) x = Var x let (|-&gt;) x t = Lam (x, t) let (@) t1 t2 = App
(t1, t2) let test = “x” |-&gt; (“x” |-&gt; !“y” @ !“x”) @ !“x”</p>
<p>module S = StateM (struct type t = int * (string * string) list end)
open S</p>
<p>let rec alpha_conv = function | Var x as v -&gt; (* Function from
terms to StateM monad <em>) let</em> (<em>, env) = get in (* Seeing a
variable does not change state <em>) let v = try Var (List.assoc x env)
(</em> but we need its new name <em>) with Not_found -&gt; v in (</em>
Free variables don’t change name <em>) return v | Lam (x, t) -&gt;
(</em> We rename each bound variable <em>) let</em> (fresh, env) = get
in (* We need a fresh number <em>) let x’ = x ^ string_of_int fresh in
let</em> () = put (fresh+1, (x, x’)::env) in (* Remember new name,
update number <em>) let</em> t’ = alpha_conv t in let* (fresh’, </em>) =
get in (* We need to restore names, <em>) let</em> () = put (fresh’,
env) in (* but keep the number fresh <em>) return (Lam (x’, t’)) | App
(t1, t2) -&gt; let</em> t1 = alpha_conv t1 in (* Passing around of names
<em>) let</em> t2 = alpha_conv t2 in (* and the currently fresh number
<em>) return (App (t1, t2)) (</em> is done by the monad *)</p>
<p>(* val test : term = Lam (“x”, App (Lam (“x”, App (Var “y”, Var
“x”)), Var “x”)) <em>) (</em> # StateM.run (alpha_conv test) (5, []);; -
: term * (int * (string * string) list) = (Lam (“x5”, App (Lam (“x6”,
App (Var “y”, Var “x6”)), Var “x5”)), (7, [])) *)</p>
<pre><code>
The state consists of a fresh counter and an environment mapping old names to new names. The `get` and `put` operations access and modify this state, while `let*` sequences the operations. Without the state monad, we would have to explicitly pass the state through every recursive call -- tedious and error-prone.

Note: This alpha-conversion does not make a lambda-term safe for multiple steps of beta-reduction. Can you find a counter-example?

### 8.12 Monad Transformers

Sometimes we need the capabilities of multiple monads at the same time. For example, we might want both state (to track information) and non-determinism (to explore choices). The straightforward idea is to nest one monad within another: either `&#39;a AM.monad BM.monad` or `&#39;a BM.monad AM.monad`. But this does not work well -- we want a single monad that has operations of *both* `AM` and `BM`.

The solution is a **monad transformer**. A monad transformer `AT` takes a monad `BM` and produces a new monad `AT(BM)` that has operations of both. The transformed monad wraps around `BM` in a specific way to make the operations interact correctly.

We will develop a monad transformer `StateT` which adds state to any monad-plus. The resulting monad has all the operations: `return`, `bind`, `mzero`, `mplus`, `put`, `get`, and all their derived functions.

Why do we need monad transformers in OCaml? Because &quot;monads are contagious&quot;: although we have built-in state and exceptions, we need to use *monadic* state and exceptions when we are inside a monad. For example, using OCaml&#39;s native `ref` cells inside a list monad would give the wrong semantics for backtracking. This is also why Lwt is both a concurrency monad and an exception monad -- it needs monadic exceptions to interact correctly with its concurrency model.

To understand how the transformer works, let us compare the regular state monad with the transformed version. The regular state monad uses ordinary OCaml binding:
</code></pre>
<p>type ’a state = store -&gt; (’a * store)</p>
<p>let return (a : ’a) : ’a state = fun s -&gt; (a, s)</p>
<p>let bind (u : ‘a state) (f : ’a -&gt; ’b state) : ’b state = fun s
-&gt; let (a, s’) = u s in f a s’</p>
<pre><code>
The transformed version wraps everything in the underlying monad `M`:
</code></pre>
<p>(* Monad M transformed to add state, in pseudo-code: <em>) type ’a
stateT(M) = store -&gt; (’a </em> store) M (* Note: this is store -&gt;
(’a * store) M, not (’a M) state *)</p>
<p>let return (a : ’a) : ’a stateT(M) = fun s -&gt; M.return (a, s) (*
Use M.return instead of just returning *)</p>
<p>let bind (u : ‘a stateT(M)) (f : ’a -&gt; ’b stateT(M)) : ’b
stateT(M) = fun s -&gt; M.bind (u s) (fun (a, s’) -&gt; f a s’) (* Use
M.bind instead of let *)</p>
<pre><code>
The key insight is that the result type is `(&#39;a * store) M` -- the result and state are wrapped *together* in the underlying monad. This ensures that backtracking (in a monad-plus) correctly restores the state.

#### State Transformer Implementation

```ocaml env=ch8
module StateT (MP : MONAD_PLUS_OPS) (Store : sig type t end) : sig
  type store = Store.t
  type &#39;a t = store -&gt; (&#39;a * store) MP.monad
  include MONAD_PLUS_OPS         (* Exporting all monad-plus operations *)
  include STATE with type &#39;a t := &#39;a monad
                 and type store := store  (* and state operations *)
  val run : &#39;a monad -&gt; &#39;a t     (* Expose &quot;what happened&quot; -- resulting states *)
  val runT : &#39;a monad -&gt; store -&gt; &#39;a MP.monad
end = struct                     (* Run the state transformer -- get resulting values *)
  type store = Store.t
  module M = struct
    type &#39;a t = store -&gt; (&#39;a * store) MP.monad
    let return a = fun s -&gt; MP.return (a, s)
    let bind m b = fun s -&gt;
      MP.bind (m s) (fun (a, s&#39;) -&gt; b a s&#39;)
    let mzero = fun _ -&gt; MP.mzero            (* Lift the monad-plus operations *)
    let mplus ma mb = fun s -&gt; MP.mplus (ma s) (mb s)
  end
  include M
  include MonadPlusOps(M)
  let get = fun s -&gt; MP.return (s, s)        (* Instead of just returning, *)
  let put s&#39; = fun _ -&gt; MP.return ((), s&#39;)   (* MP.return *)
  let runT m s = MP.lift fst (m s)
end</code></pre>
<h4 id="backtracking-with-state">Backtracking with State</h4>
<p>Now we can combine backtracking with state for our puzzle solver. The
state tracks which cells have been visited, eaten, and how many islands
we have found. The monad-plus structure handles the backtracking when a
choice leads to a dead end:</p>
<p>```ocaml skip module HoneyIslands (M : MONAD_PLUS_OPS) = struct type
state = { been_size : int; been_islands : int; unvisited : cell list;
visited : CellSet.t; eaten : cell list; more_to_eat : int; }</p>
<p>let init_state unvisited more_to_eat = { been_size = 0; been_islands
= 0; unvisited; visited = CellSet.empty; eaten = []; more_to_eat; }</p>
<p>module BacktrackingM = StateT (M) (struct type t = state end) open
BacktrackingM</p>
<p>let rec visit_cell () = (* State update actions <em>) let</em> s =
get in match s.unvisited with | [] -&gt; return None | c::remaining when
CellSet.mem c s.visited -&gt; let* () = put {s with unvisited=remaining}
in visit_cell () (* Throwaway argument because of recursion <em>) |
c::remaining -&gt; let</em> () = put {s with unvisited=remaining;
visited = CellSet.add c s.visited} in return (Some c) (* This action
returns a value *)</p>
<p>let eat_cell c = let* s = get in let* () = put {s with eaten =
c::s.eaten; visited = CellSet.add c s.visited; more_to_eat =
s.more_to_eat - 1} in return () (* Remaining state update actions just
affect the state *)</p>
<p>let keep_cell c = let* s = get in let* () = put {s with visited =
CellSet.add c s.visited; been_size = s.been_size + 1} in return ()</p>
<p>let fresh_island = let* s = get in let* () = put {s with been_size =
0; been_islands = s.been_islands + 1} in return ()</p>
<p>let find_to_eat n island_size num_islands empty_cells = let honey =
honey_cells n empty_cells in let rec find_board () = let* cell =
visit_cell () in match cell with | None -&gt; let* s = get in let* () =
guard (s.been_islands = num_islands) in return s.eaten | Some cell -&gt;
let* () = fresh_island in let* () = find_island cell in let* s = get in
let* () = guard (s.been_size = island_size) in find_board ()</p>
<pre><code>and find_island current =
  let* () = keep_cell current in
  neighbors n empty_cells current
  |&gt; foldM
       (fun () neighbor -&gt;
          let* s = get in
          whenM (not (CellSet.mem neighbor s.visited))
            (let choose_eat =
               let* () = guard (s.more_to_eat &gt; 0) in
               eat_cell neighbor
             and choose_keep =
               let* () = guard (s.been_size &lt; island_size) in
               find_island neighbor in
             choose_eat ++ choose_keep)) () in

let cells_to_eat =
  List.length honey - island_size * num_islands in
init_state honey cells_to_eat
|&gt; runT (find_board ())</code></pre>
<p>end</p>
<p>module HoneyL = HoneyIslands (ListM) let find_to_eat a b c d =
ListM.run (HoneyL.find_to_eat a b c d)</p>
<pre><code>
### 8.13 Probabilistic Programming

Using a random number generator, we can define procedures that produce various outputs. This is **not functional** in the mathematical sense -- mathematical functions have deterministic results for fixed arguments.

Just as we can &quot;simulate&quot; mutable variables with the state monad and non-determinism with the list monad, we can &quot;simulate&quot; random computation with a **probability monad**. But the probability monad is more than just randomized computation -- it lets us *reason* about probabilities. We can ask questions like &quot;what is the probability of this outcome?&quot; or &quot;what is the distribution of possible results?&quot;

Different monad implementations make different tradeoffs:
- **Exact distribution**: Track all possible outcomes and their probabilities precisely
- **Sampling (Monte Carlo)**: Approximate probabilities by running many random trials

#### The Probability Monad

The essential functions for the probability monad class are `choose` (for making probabilistic choices) and `distrib` (for extracting the probability distribution). Other operations could be defined in terms of these but are provided by each instance for efficiency.

**Inside-monad operations** (building probabilistic computations):

- `choose : float -&gt; &#39;a monad -&gt; &#39;a monad -&gt; &#39;a monad`: `choose p a b` represents an event which is `a` with probability $p$ and `b` with probability $1-p$.
- `pick : (&#39;a * float) list -&gt; &#39;a monad`: Draw a result from a given probability distribution. The argument must be a valid distribution: positive probabilities summing to 1.
- `uniform : &#39;a list -&gt; &#39;a monad`: Uniform distribution -- each element equally likely.
- `flip : float -&gt; bool monad`: A biased coin: `true` with probability `p`, `false` otherwise.
- `coin : bool monad`: A fair coin: `flip 0.5`.

**Outside-monad operations** (querying probabilistic computations):

- `prob : (&#39;a -&gt; bool) -&gt; &#39;a monad -&gt; float`: Returns the probability that a predicate holds.
- `distrib : &#39;a monad -&gt; (&#39;a * float) list`: Returns the full distribution of probabilities over outcomes.
- `access : &#39;a monad -&gt; &#39;a`: Samples a random result from the distribution -- this is **non-functional** behavior (different calls may return different results).

```ocaml env=ch8
module type PROBABILITY = sig
  include MONAD_OPS
  val choose : float -&gt; &#39;a monad -&gt; &#39;a monad -&gt; &#39;a monad
  val pick : (&#39;a * float) list -&gt; &#39;a monad
  val uniform : &#39;a list -&gt; &#39;a monad
  val coin : bool monad
  val flip : float -&gt; bool monad
  val prob : (&#39;a -&gt; bool) -&gt; &#39;a monad -&gt; float
  val distrib : &#39;a monad -&gt; (&#39;a * float) list
  val access : &#39;a monad -&gt; &#39;a
end</code></pre>
<p>Helper functions:</p>
<p>```ocaml skip let total dist = List.fold_left (fun a (_,b) -&gt; a +.
b) 0. dist</p>
<p>let merge dist = map_reduce (fun x -&gt; x) (+.) 0. dist (* Merge
repeating elements *)</p>
<p>let normalize dist = (* Normalize a measure into a distribution *)
let tot = total dist in if tot = 0. then dist else List.map (fun (e,w)
-&gt; e, w /. tot) dist</p>
<p>let roulette dist = (* Roulette wheel from a distribution/measure *)
let tot = total dist in let rec aux r = function | [] -&gt; assert false
| (e, w)::_ when w &lt;= r -&gt; e | (_, w)::tl -&gt; aux (r -. w) tl in
aux (Random.float tot) dist</p>
<pre><code>
#### Exact Distribution Monad

```ocaml skip
module DistribM : PROBABILITY = struct
  module M = struct           (* Exact probability distribution -- naive implementation *)
    type &#39;a t = (&#39;a * float) list
    let bind a b = merge             (* x w.p. p and then y w.p. q happens = *)
      (List.concat_map (fun (x, p) -&gt;
        List.map (fun (y, q) -&gt; (y, q *. p)) (b x)) a)  (* y results w.p. p*q *)
    let return a = [a, 1.]           (* Certainly a *)
  end
  include M
  include MonadOps (M)
  let choose p a b =
    List.map (fun (e,w) -&gt; e, p *. w) a @
      List.map (fun (e,w) -&gt; e, (1. -. p) *. w) b
  let pick dist = dist
  let uniform elems = normalize
    (List.map (fun e -&gt; e, 1.) elems)
  let coin = [true, 0.5; false, 0.5]
  let flip p = [true, p; false, 1. -. p]
  let prob p m = m
    |&gt; List.filter (fun (e,_) -&gt; p e)    (* All cases where p holds, *)
    |&gt; List.map snd |&gt; List.fold_left (+.) 0.  (* add up *)
  let distrib m = m
  let access m = roulette m
end</code></pre>
<h4 id="sampling-monad">Sampling Monad</h4>
<p><code>ocaml skip module SamplingM (S : sig val samples : int end) : PROBABILITY = struct   module M = struct                      (* Parameterized by how many samples *)     type 'a t = unit -&gt; 'a               (* used to approximate prob or distrib *)     let bind a b () = b (a ()) ()        (* Randomized computation -- each call a() *)     let return a = fun () -&gt; a           (* is an independent sample. Always a. *)   end   include M   include MonadOps (M)   let choose p a b () =     if Random.float 1. &lt;= p then a () else b ()   let pick dist = fun () -&gt; roulette dist   let uniform elems =     let n = List.length elems in     fun () -&gt; List.nth elems (Random.int n)   let coin = Random.bool   let flip p = choose p (return true) (return false)   let prob p m =     let count = ref 0 in     for i = 1 to S.samples do       if p (m ()) then incr count     done;     float_of_int !count /. float_of_int S.samples   let distrib m =     let dist = ref [] in     for i = 1 to S.samples do       dist := (m (), 1.) :: !dist done;     normalize (merge !dist)   let access m = m () end</code></p>
<h4 id="example-the-monty-hall-problem">Example: The Monty Hall
Problem</h4>
<p>The Monty Hall problem is a famous probability puzzle. In search of a
new car, the player picks a door, say 1. The game host (who knows what
is behind each door) then opens one of the other doors, say 3, to reveal
a goat and offers to let the player switch to door 2 instead of door 1.
Should the player switch?</p>
<p>Most people’s intuition says it does not matter, but let us compute
the actual probabilities:</p>
<p>```ocaml skip module MontyHall (P : PROBABILITY) = struct open P type
door = A | B | C let doors = [A; B; C]</p>
<p>let monty_win switch = let* prize = uniform doors in let* chosen =
uniform doors in let* opened = uniform (list_diff doors [prize; chosen])
in let final = if switch then List.hd (list_diff doors [opened; chosen])
else chosen in return (final = prize) end</p>
<p>module MontyExact = MontyHall (DistribM) module Sampling1000 =
SamplingM (struct let samples = 1000 end) module MontySimul = MontyHall
(Sampling1000)</p>
<p>(* DistribM.distrib (MontyExact.monty_win false);; - : (bool * float)
list = [(true, 0.333…); (false, 0.666…)]</p>
<p>DistribM.distrib (MontyExact.monty_win true);; - : (bool * float)
list = [(true, 0.666…); (false, 0.333…)] *)</p>
<pre><code>
The famous result: switching doubles your chances of winning! Counter-intuitively, the host&#39;s choice of which door to open gives you information -- by switching, you are betting that your initial choice was wrong (which it is 2/3 of the time).

#### Conditional Probabilities

So far we have computed unconditional probabilities. But what if we want to answer questions like &quot;given that X happened, what is the probability of Y?&quot; This is a conditional probability $P(Y|X)$.

Wouldn&#39;t it be nice to have a monad-plus rather than just a monad? Then we could use `guard` for conditional probabilities!

To compute $P(A|B)$:
1. Compute what is needed for both $A$ and $B$
2. Guard $B$
3. Return $A$

For the exact distribution monad, we allow intermediate distributions to be *unnormalized* (probabilities sum to less than 1) and normalize at the end. For the sampling monad, we use *rejection sampling*: generate samples and discard those that do not satisfy the condition (though `mplus` has no straightforward correct implementation in this approach).

```ocaml skip
module type COND_PROBAB = sig
  include PROBABILITY
  include MONAD_PLUS_OPS with type &#39;a monad := &#39;a monad
end

module DistribMP : COND_PROBAB = struct
  module MP = struct
    type &#39;a t = (&#39;a * float) list      (* Measures no longer restricted to *)
    let bind a b = merge               (* probability distributions *)
      (List.concat_map (fun (x, p) -&gt;
        List.map (fun (y, q) -&gt; (y, q *. p)) (b x)) a)
    let return a = [a, 1.]
    let mzero = []                     (* Measure equal 0 everywhere is OK *)
    let mplus = List.append
  end
  include MP
  include MonadPlusOps (MP)
  let choose p a b =                   (* It isn&#39;t a w.p. p &amp; b w.p. (1-p) since a and b *)
    List.map (fun (e,w) -&gt; e, p *. w) a @  (* are not normalized! *)
      List.map (fun (e,w) -&gt; e, (1. -. p) *. w) b
  let pick dist = dist
  let uniform elems = normalize
    (List.map (fun e -&gt; e, 1.) elems)
  let coin = [true, 0.5; false, 0.5]
  let flip p = [true, p; false, 1. -. p]
  let prob p m = normalize m           (* Final normalization step *)
    |&gt; List.filter (fun (e,_) -&gt; p e)
    |&gt; List.map snd |&gt; List.fold_left (+.) 0.
  let distrib m = normalize m
  let access m = roulette m
end

module SamplingMP (S : sig val samples : int end) : COND_PROBAB = struct
  exception Rejected                   (* For rejecting current sample *)
  module MP = struct                   (* Monad operations are exactly as for SamplingM *)
    type &#39;a t = unit -&gt; &#39;a
    let bind a b () = b (a ()) ()
    let return a = fun () -&gt; a
    let mzero = fun () -&gt; raise Rejected  (* but now we can fail *)
    let mplus a b = fun () -&gt;
      failwith &quot;SamplingMP.mplus not implemented&quot;
  end
  include MP
  include MonadPlusOps (MP)
  let choose p a b () =                (* Inside-monad operations don&#39;t change *)
    if Random.float 1. &lt;= p then a () else b ()
  let pick dist = fun () -&gt; roulette dist
  let uniform elems =
    let n = List.length elems in
    fun () -&gt; List.nth elems (Random.int n)
  let coin = Random.bool
  let flip p = choose p (return true) (return false)
  let prob p m =                       (* Getting out of monad: handle rejected samples *)
    let count = ref 0 and tot = ref 0 in
    while !tot &lt; S.samples do          (* Count up to the required *)
      try                              (* number of samples *)
        if p (m ()) then incr count;   (* m() can fail *)
        incr tot                       (* But if we got here it hasn&#39;t *)
      with Rejected -&gt; ()              (* Rejected, keep sampling *)
    done;
    float_of_int !count /. float_of_int S.samples
  let distrib m =
    let dist = ref [] and tot = ref 0 in
    while !tot &lt; S.samples do
      try
        dist := (m (), 1.) :: !dist;
        incr tot
      with Rejected -&gt; ()
    done;
    normalize (merge !dist)
  let rec access m =
    try m () with Rejected -&gt; access m
end</code></pre>
<h4 id="burglary-example-encoding-a-bayes-net">Burglary Example:
Encoding a Bayes Net</h4>
<p>Consider a problem with this dependency structure:</p>
<ul>
<li>An alarm can be due to either a burglary or an earthquake</li>
<li>You are on vacation and have asked neighbors John and Mary to call
if the alarm rings</li>
<li>Mary only calls when she is really sure about the alarm, but John
has better hearing</li>
<li>Earthquakes are twice as probable as burglaries</li>
<li>The alarm has about 30% chance of going off during an
earthquake</li>
<li>You can check on the radio if there was an earthquake, but you might
miss the news</li>
</ul>
<p>Probability tables:</p>
<ul>
<li><span class="math inline">P(\text{Burglary}) = 0.001</span></li>
<li><span class="math inline">P(\text{Earthquake}) = 0.002</span></li>
<li><span class="math inline">P(\text{Alarm}|\text{B}, \text{E})</span>
varies (0.001 for FF, 0.29 for FT, 0.94 for TF, 0.95 for TT)</li>
<li><span class="math inline">P(\text{John calls}|\text{Alarm})</span>
is 0.9 if alarm, 0.05 otherwise</li>
<li><span class="math inline">P(\text{Mary calls}|\text{Alarm})</span>
is 0.7 if alarm, 0.01 otherwise</li>
</ul>
<p>```ocaml skip module Burglary (P : COND_PROBAB) = struct open P type
what_happened = | Safe | Burgl | Earthq | Burgl_n_earthq</p>
<p>let check ~john_called ~mary_called ~radio = let* earthquake = flip
0.002 in let* () = guard (radio = None || radio = Some earthquake) in
let* burglary = flip 0.001 in let alarm_p = match burglary, earthquake
with | false, false -&gt; 0.001 | false, true -&gt; 0.29 | true, false
-&gt; 0.94 | true, true -&gt; 0.95 in let* alarm = flip alarm_p in let
john_p = if alarm then 0.9 else 0.05 in let* john_calls = flip john_p in
let* () = guard (john_calls = john_called) in let mary_p = if alarm then
0.7 else 0.01 in let* mary_calls = flip mary_p in let* () = guard
(mary_calls = mary_called) in match burglary, earthquake with | false,
false -&gt; return Safe | true, false -&gt; return Burgl | false, true
-&gt; return Earthq | true, true -&gt; return Burgl_n_earthq end</p>
<p>module BurglaryExact = Burglary (DistribMP) module Sampling2000 =
SamplingMP (struct let samples = 2000 end) module BurglarySimul =
Burglary (Sampling2000)</p>
<p>(* DistribMP.distrib (BurglaryExact.check ~john_called:true
~mary_called:true ~radio:None);; - : (BurglaryExact.what_happened *
float) list = [(Burgl_n_earthq, 0.000574…); (Earthq, 0.175…); (Burgl,
0.283…); (Safe, 0.540…)] *)</p>
<pre><code>
### 8.14 Lightweight Cooperative Threads

Running multiple tasks asynchronously can hide I/O latency and utilize multi-core architectures. Traditional operating system threads are &quot;heavyweight&quot; -- they have significant overhead for context switching and memory. **Lightweight threads** are managed by the application rather than the OS, allowing many concurrent tasks with lower overhead.

Lightweight threads can be:
- **Preemptive**: The scheduler interrupts running threads to switch between them
- **Cooperative**: Threads voluntarily give up control at specific points (like I/O operations)

**Lwt** is a popular OCaml library for lightweight cooperative threads, implemented as a monad. The monadic structure ensures that thread switching happens at well-defined points (whenever you use `let*`), making the code easier to reason about.

The `bind` operation is inherently sequential: `bind a (fun x -&gt; b)` computes `a`, and only resumes computing `b` once the result `x` is known.

For concurrency, we need to &quot;suppress&quot; this sequentiality. We introduce a parallel bind:
</code></pre>
<p>parallel : ’a monad -&gt; ’b monad -&gt; (’a -&gt; ’b -&gt; ’c monad)
-&gt; ’c monad</p>
<pre><code>
With `parallel a b (fun x y -&gt; c)`, computations `a` and `b` can proceed concurrently. The continuation `c` runs once both results are available.

If the monad starts computing right away (as in the Lwt library), `parallel ea eb c` is equivalent to:
</code></pre>
<p>let a = ea in let b = eb in let* x = a in let* y = b in c x y</p>
<pre><code>
#### Fine-Grained vs. Coarse-Grained Concurrency

There are two approaches to when threads switch:

**Fine-grained** concurrency suspends at every `bind`. The scheduler runs other threads and comes back to complete the `bind` before running threads created since the suspension. This gives maximum interleaving but has higher overhead.

**Coarse-grained** concurrency only suspends when explicitly requested via a `suspend` (often called `yield`) operation. Library operations that need to wait for I/O should call `suspend` internally. This is more efficient but requires careful placement of suspension points.

#### Thread Monad Signatures

The thread monad extends the basic monad with parallel composition:

```ocaml env=ch8
module type THREADS = sig
  include MONAD
  val parallel :
    &#39;a t -&gt; &#39;b t -&gt; (&#39;a -&gt; &#39;b -&gt; &#39;c t) -&gt; &#39;c t
end

module type THREAD_OPS = sig
  include MONAD_OPS
  include THREADS with type &#39;a t := &#39;a monad
  val parallel_map :
    &#39;a list -&gt; (&#39;a -&gt; &#39;b monad) -&gt; &#39;b list monad
  val (&gt;||=) :
    &#39;a monad -&gt; &#39;b monad -&gt; (&#39;a -&gt; &#39;b -&gt; &#39;c monad) -&gt; &#39;c monad
  val (&gt;||) :
    &#39;a monad -&gt; &#39;b monad -&gt; (unit -&gt; &#39;c monad) -&gt; &#39;c monad
end

module type THREADSYS = sig
  include THREADS
  val access : &#39;a t -&gt; &#39;a
  val kill_threads : unit -&gt; unit
end

module ThreadOps (M : THREADS) = struct
  open M
  include MonadOps (M)
  let parallel_map l f =
    List.fold_right (fun a bs -&gt;
      parallel (f a) bs
        (fun a bs -&gt; return (a::bs))) l (return [])
  let (&gt;||=) = parallel
  let (&gt;||) a b c = parallel a b (fun _ _ -&gt; c ())
end

module Threads (M : THREADSYS) : sig
  include THREAD_OPS
  val access : &#39;a monad -&gt; &#39;a
  val kill_threads : unit -&gt; unit
end = struct
  include M
  include ThreadOps(M)
end</code></pre>
<h4 id="cooperative-thread-implementation">Cooperative Thread
Implementation</h4>
<p>The implementation uses a mutable state to track thread progress.
Each thread is in one of three states: completed (<code>Return</code>),
waiting (<code>Sleep</code> with a list of callbacks to invoke when
done), or forwarded to another thread (<code>Link</code>):</p>
<p>```ocaml skip module Cooperative = Threads(struct type ’a state = |
Return of ’a (* The thread has returned <em>) | Sleep of (’a -&gt; unit)
list (</em> When thread returns, wake up waiters <em>) | Link of ’a t
(</em> A link to the actual thread <em>) and ’a t = {mutable state : ’a
state} (</em> State of the thread can change <em>) (</em> – it can
return, or more waiters added <em>) let rec find t = (</em> Union-find
style link chasing *) match t.state with | Link t -&gt; find t | _ -&gt;
t</p>
<p>let jobs = Queue.create () (* Work queue – will store unit -&gt; unit
procedures *)</p>
<p>let wakeup m a = (* Thread m has actually finished – <em>) let m =
find m in (</em> updating its state <em>) match m.state with | Return _
-&gt; assert false | Sleep waiters -&gt; m.state &lt;- Return a; (</em>
Set the state, and only then <em>) List.iter ((|&gt;) a) waiters (</em>
wake up the waiters *) | Link _ -&gt; assert false</p>
<p>let return a = {state = Return a}</p>
<p>let connect t t’ = (* t was a placeholder for t’ <em>) let t’ = find
t’ in match t’.state with | Sleep waiters’ -&gt; let t = find t in
(match t.state with | Sleep waiters -&gt; (</em> If both sleep, collect
their waiters <em>) t.state &lt;- Sleep (waiters’ @ waiters); t’.state
&lt;- Link t (</em> and link one to the other <em>) | _ -&gt; assert
false) | Return x -&gt; wakeup t x (</em> If t’ returned, wake up the
placeholder *) | Link _ -&gt; assert false</p>
<p>let rec bind a b = let a = find a in let m = {state = Sleep []} in (*
The resulting monad <em>) (match a.state with | Return x -&gt; (</em> If
a returned, we suspend further work <em>) let job () = connect m (b x)
in (</em> (In exercise 11, this should <em>) Queue.push job jobs (</em>
only happen after suspend) <em>) | Sleep waiters -&gt; (</em> If a
sleeps, we wait for it to return *) let job x = connect m (b x) in
a.state &lt;- Sleep (job::waiters) | Link _ -&gt; assert false); m</p>
<p>let parallel a b c = (* Since in our implementation <em>) bind a (fun
x -&gt; (</em> the threads run as soon as they are created, <em>) bind b
(fun y -&gt; (</em> parallel is redundant *) c x y))</p>
<p>let rec access m = (* Accessing not only gets the result of m, <em>)
let m = find m in (</em> but spins the thread loop till m terminates
<em>) match m.state with | Return x -&gt; x (</em> No further work <em>)
| Sleep _ -&gt; (try Queue.pop jobs () (</em> Perform suspended work *)
with Queue.Empty -&gt; failwith “access: result not available”); access
m | Link _ -&gt; assert false</p>
<p>let kill_threads () = Queue.clear jobs (* Remove pending work *)
end)</p>
<pre><code>
#### Testing the Thread Implementation

Let us test the implementation with two threads that each print a sequence of numbers:

```ocaml skip
module TTest (T : THREAD_OPS) = struct
  open T
  let rec loop s n =
    let* () = return (Printf.printf &quot;-- %s(%d)\n%!&quot; s n) in
    if n &gt; 0 then loop s (n-1)         (* We cannot use whenM because the thread *)
    else return ()                     (* would be created regardless of condition *)
end

module TT = TTest (Cooperative)

let test =
  Cooperative.kill_threads ();         (* Clean-up after previous tests *)
  let thread1 = TT.loop &quot;A&quot; 5 in
  let thread2 = TT.loop &quot;B&quot; 4 in
  Cooperative.access thread1;          (* We ensure threads finish computing *)
  Cooperative.access thread2           (* before we proceed *)

(* Output:
   -- A(5)
   -- B(4)
   -- A(4)
   -- B(3)
   -- A(3)
   -- B(2)
   -- A(2)
   -- B(1)
   -- A(1)
   -- B(0)
   -- A(0)
   val test : unit = () *)</code></pre>
<p>The output shows that the threads interleave their execution
beautifully: A(5), B(4), A(4), B(3), and so on. Each <code>bind</code>
(the <code>let*</code>) causes a context switch to the other thread.
This is fine-grained concurrency in action.</p>
<p>The key insight is that monadic structure gives us precise control
over concurrency. Every <code>let*</code> is a potential suspension
point, making the code’s behavior predictable and debuggable – a
significant advantage over preemptive threading where context switches
can happen anywhere.</p>
<h3 id="exercises-6">8.15 Exercises</h3>
<p><strong>Exercise 1.</strong> (Puzzle via Oleg Kiselyov)</p>
<p>“U2” has a concert that starts in 17 minutes and they must all cross
a bridge to get there. All four men begin on the same side of the
bridge. It is night. There is one flashlight. A maximum of two people
can cross at one time. Any party who crosses, either 1 or 2 people, must
have the flashlight with them. The flashlight must be walked back and
forth, it cannot be thrown, etc. Each band member walks at a different
speed. A pair must walk together at the rate of the slower man’s
pace:</p>
<ul>
<li>Bono: 1 minute to cross</li>
<li>Edge: 2 minutes to cross</li>
<li>Adam: 5 minutes to cross</li>
<li>Larry: 10 minutes to cross</li>
</ul>
<p>For example: if Bono and Larry walk across first, 10 minutes have
elapsed when they get to the other side of the bridge. If Larry then
returns with the flashlight, a total of 20 minutes have passed and you
have failed the mission.</p>
<p>Find all answers to the puzzle using a list comprehension. The
comprehension will be a bit long but recursion is not needed.</p>
<p><strong>Exercise 2.</strong> Assume <code>concat_map</code> as
defined in lecture 6 and the binding operators defined above. What will
the following expressions return? Why?</p>
<ol type="1">
<li><code>let* _ = return 5 in return 7</code></li>
<li><code>let guard p = if p then [()] else [] in let* () = guard false in return 7</code></li>
<li><code>let* _ = return 5 in let* () = guard false in return 7</code></li>
</ol>
<p><strong>Exercise 3.</strong> Define <code>bind</code> in terms of
<code>lift</code> and <code>join</code>.</p>
<p><strong>Exercise 4.</strong> Define a monad-plus implementation based
on binary trees, with constant-time <code>mzero</code> and
<code>mplus</code>. Starter code:</p>
<p>```ocaml skip type ’a tree = Empty | Leaf of ’a | T of ’a tree * ’a
tree</p>
<p>module TreeM = MonadPlus (struct type ’a t = ’a tree let bind a b =
(* TODO <em>) let return a = (</em> TODO <em>) let mzero = (</em> TODO
<em>) let mplus a b = (</em> TODO *) end)</p>
<pre><code>
**Exercise 5.** Show the monad-plus laws for one of:
1. `TreeM` from your solution of exercise 4
2. `ListM` from lecture

**Exercise 6.** Why is the following monad-plus not lazy enough?

```ocaml skip
let rec badappend l1 l2 =
  match l1 with lazy LazNil -&gt; l2
  | lazy (LazCons (hd, tl)) -&gt;
      lazy (LazCons (hd, badappend tl l2))

let rec badconcatmap f = function
  | lazy LazNil -&gt; lazy LazNil
  | lazy (LazCons (a, l)) -&gt;
      badappend (f a) (badconcatmap f l)

module BadyListM = MonadPlus (struct
  type &#39;a t = &#39;a lazylist
  let bind a b = badconcatmap b a
  let return a = lazy (LazCons (a, lazy LazNil))
  let mzero = lazy LazNil
  let mplus = badappend
end)</code></pre>
<p><strong>Exercise 7.</strong> Convert a “rectangular” list of lists of
strings, representing a matrix with inner lists being rows, into a
string, where elements are column-aligned. (Exercise not related to
monads.)</p>
<p><strong>Exercise 8.</strong> Recall the enriched monad signature with
<code>('s, 'a) t</code> type. Design the signatures for the exception
monad operations to provide more flexibility than our exception monad.
Does the implementation need to change?</p>
<p><strong>Exercise 9.</strong> Implement the following constructs for
<em>all</em> monads:</p>
<ol type="1">
<li><code>for...to...</code></li>
<li><code>for...downto...</code></li>
<li><code>while...do...</code></li>
<li><code>do...while...</code></li>
<li><code>repeat...until...</code></li>
</ol>
<p>Explain how, when your implementation is instantiated with the StateM
monad, we get the solution to exercise 2 from lecture 4.</p>
<p><strong>Exercise 10.</strong> A canonical example of a probabilistic
model is that of a lawn whose grass may be wet because it rained,
because the sprinkler was on, or for some other reason. The probability
tables are:</p>
<p><span class="math display">
\begin{aligned}
P(\text{cloudy}) &amp;= 0.5 \\
P(\text{rain}|\text{cloudy}) &amp;= 0.8 \\
P(\text{rain}|\neg\text{cloudy}) &amp;= 0.2 \\
P(\text{sprinkler}|\text{cloudy}) &amp;= 0.1 \\
P(\text{sprinkler}|\neg\text{cloudy}) &amp;= 0.5 \\
P(\text{wet\_roof}|\neg\text{rain}) &amp;= 0 \\
P(\text{wet\_roof}|\text{rain}) &amp;= 0.7 \\
P(\text{wet\_grass}|\text{rain} \land \neg\text{sprinkler}) &amp;= 0.9
\\
P(\text{wet\_grass}|\text{sprinkler} \land \neg\text{rain}) &amp;= 0.9
\end{aligned}
</span></p>
<p>We observe whether the grass is wet and whether the roof is wet. What
is the probability that it rained?</p>
<p><strong>Exercise 11.</strong> Implement the coarse-grained
concurrency model:</p>
<ul>
<li>Modify <code>bind</code> to compute the resulting monad straight
away if the input monad has returned.</li>
<li>Introduce <code>suspend</code> to do what in the fine-grained model
was the effect of <code>bind (return a) b</code>, i.e., suspend the work
although it could already be started.</li>
<li>One possibility is to introduce <code>suspend</code> of type
<code>unit monad</code>, introduce a “dummy” monadic value
<code>Suspend</code> (besides <code>Return</code> and
<code>Sleep</code>), and define <code>bind suspend b</code> to do what
<code>bind (return ()) b</code> would formerly do.</li>
</ul>
<h2 id="chapter-9-algebraic-effects">Chapter 9: Algebraic Effects</h2>
<p>This chapter replaces the chapter <em>Compilation, Runtime,
Optimization, and Parsing</em> from the old lectures.</p>
<p>TODO</p>
<h2 id="chapter-10-functional-reactive-programming">Chapter 10:
Functional Reactive Programming</h2>
<p>How do we deal with change and interaction in functional programming?
This is one of the most challenging questions in the field, and over the
years programmers have developed increasingly sophisticated answers.
This chapter explores a progression of techniques: we begin with
<em>zippers</em>, a clever data structure for navigating and modifying
positions within larger structures. We then advance to <em>adaptive
programming</em> (also known as incremental computing), which
automatically propagates changes through computations. Finally, we
arrive at <em>Functional Reactive Programming</em> (FRP), a declarative
approach to handling time-varying values and event streams. We conclude
with practical examples including graphical user interfaces.</p>
<p><strong>Recommended Reading:</strong></p>
<ul>
<li><em>“Zipper”</em> in Haskell Wikibook and <em>“The Zipper”</em> by
Gerard Huet</li>
<li><em>“How <code>froc</code> works”</em> by Jacob Donham</li>
<li><em>“The Haskell School of Expression”</em> by Paul Hudak</li>
<li><em>“Deprecating the Observer Pattern with
<code>Scala.React</code>”</em> by Ingo Maier, Martin Odersky</li>
</ul>
<h3 id="zippers">10.1 Zippers</h3>
<p>Imagine you are editing a document, a tree structure, or navigating
through a file system. You need to keep track of where you are, easily
access and modify the data at that location, and move around
efficiently. This is exactly the problem that zippers solve.</p>
<p>Recall from earlier chapters how we defined <em>context types</em>
for datatypes – types that represent a data structure with one of its
elements missing. We discovered that taking the derivative of an
algebraic datatype gives us exactly this context type. Now we will put
this theory to practical use.</p>
<p>Consider binary trees:</p>
<p><code>ocaml skip type btree = Tip | Node of int * btree * btree</code></p>
<p>Using our algebraic datatype calculus, where <span
class="math inline">T</span> represents the tree type:</p>
<p><span class="math display">
\begin{matrix}
T &amp; = &amp; 1 + xT^2 \\
\frac{\partial T}{\partial x} &amp; = &amp; 0 + T^2 + 2xT\frac{\partial
T}{\partial x} = TT + 2xT\frac{\partial T}{\partial x}
\end{matrix}
</span></p>
<p>This derivative gives us the context type:</p>
<p><code>ocaml skip type btree_dir = LeftBranch | RightBranch type btree_deriv =   | Here of btree * btree   | Below of btree_dir * int * btree * btree_deriv</code></p>
<p>The key insight is that <strong>Location = context +
subtree</strong>! A location in a data structure consists of two parts:
the context (everything around the focused element) and the subtree
(what we are currently looking at).</p>
<p>However, there is a problem with the representation above: we cannot
easily move the location if <code>Here</code> is at the bottom of our
context representation. Think about it: if we want to move up from our
current position, we need to access the innermost layer of the context
first. The part closest to the location should be on top, not buried at
the bottom.</p>
<h4 id="revisiting-the-equations">Revisiting the Equations</h4>
<p>Let us revisit the equations for trees and lists:</p>
<p><span class="math display">
\begin{matrix}
T &amp; = &amp; 1 + xT^2 \\
\frac{\partial T}{\partial x} &amp; = &amp; 0 + T^2 + 2xT\frac{\partial
T}{\partial x} \\
\frac{\partial T}{\partial x} &amp; = &amp; \frac{T^2}{1 - 2xT} \\
L(y) &amp; = &amp; 1 + yL(y) \\
L(y) &amp; = &amp; \frac{1}{1 - y} \\
\frac{\partial T}{\partial x} &amp; = &amp; T^2 L(2xT)
\end{matrix}
</span></p>
<p>This algebraic manipulation reveals something beautiful: the context
can be stored as a list with the root as the last node. The <span
class="math inline">L(2xT)</span> factor tells us that we have a list
where each element consists of <span class="math inline">2xT</span> –
that is, a direction indicator (left or right, hence the factor of 2),
the element at that node (<span class="math inline">x</span>), and the
sibling subtree (<span class="math inline">T</span>).</p>
<p>It does not matter whether we use built-in OCaml lists or define a
custom type with <code>Above</code> and <code>Root</code> variants – the
structure is the same.</p>
<p>In practice, contexts of subtrees are more useful than contexts of
single elements. Rather than tracking where a single value lives, we
track the position of an entire subtree within the larger structure:</p>
<p>```ocaml skip type ’a tree = Tip | Node of ’a tree * ’a * ’a tree
type tree_dir = Left_br | Right_br type ’a context = (tree_dir * ’a * ’a
tree) list type ’a location = {sub: ’a tree; ctx: ’a context}</p>
<p>let access {sub} = sub (* Get the current subtree <em>) let change
{ctx} sub = {sub; ctx} (</em> Replace the subtree, keep context <em>)
let modify f {sub; ctx} = {sub = f sub; ctx} (</em> Transform the
subtree *)</p>
<pre><code>
There is a wonderful visual intuition for zippers: imagine taking a tree and pinning it at one of its nodes, then letting it hang down under gravity. The pinned node becomes &quot;the current focus,&quot; and all the other parts of the tree dangle from it. This mental picture helps understand how movement works: moving to a child means letting a new node become the pin point, with the old parent now hanging above. For excellent visualizations, see http://en.wikibooks.org/wiki/Haskell/Zippers.

#### Moving Around

Navigation functions allow us to traverse the structure. Each movement operation restructures the zipper: what was context becomes part of the subtree, and vice versa. Watch how ascending rebuilds a parent node from the context, while descending breaks apart a node to create new context:

```ocaml skip
let ascend loc =
  match loc.ctx with
  | [] -&gt; loc  (* At root already, or raise exception *)
  | (Left_br, n, l) :: up_ctx -&gt;
    (* We were in the right subtree; rebuild the parent node *)
    {sub = Node (l, n, loc.sub); ctx = up_ctx}
  | (Right_br, n, r) :: up_ctx -&gt;
    (* We were in the left subtree; rebuild the parent node *)
    {sub = Node (loc.sub, n, r); ctx = up_ctx}

let desc_left loc =
  match loc.sub with
  | Tip -&gt; loc  (* Cannot descend into a tip, or raise exception *)
  | Node (l, n, r) -&gt;
    (* Focus on left child; right sibling goes into context *)
    {sub = l; ctx = (Right_br, n, r) :: loc.ctx}

let desc_right loc =
  match loc.sub with
  | Tip -&gt; loc  (* Cannot descend into a tip, or raise exception *)
  | Node (l, n, r) -&gt;
    (* Focus on right child; left sibling goes into context *)
    {sub = r; ctx = (Left_br, n, l) :: loc.ctx}</code></pre>
<h4 id="trees-with-arbitrary-branching">Trees with Arbitrary
Branching</h4>
<p>Following <em>The Zipper</em> by Gerard Huet, let us look at a tree
with an arbitrary number of branches. This is particularly useful for
representing document structures where a group can contain any number of
children:</p>
<p><code>ocaml skip type doc = Text of string | Line | Group of doc list type context = (doc list * doc list) list  (* left siblings, right siblings *) type location = {sub: doc; ctx: context}</code></p>
<p>In this design, the context at each level stores two lists: the
siblings to the left of our current position (in reverse order for
efficient access) and the siblings to the right. This allows us to move
not just up and down, but also left and right among siblings.</p>
<p>The navigation functions for this more complex structure show how we
reconstruct the parent when going up, and how we split the sibling list
when going down:</p>
<p>```ocaml skip let go_up loc = match loc.ctx with | [] -&gt;
invalid_arg “go_up: at top” | (left, right) :: up_ctx -&gt; (*
Reconstruct the Group: reverse left siblings, add current, then right *)
{sub = Group (List.rev left @ loc.sub :: right); ctx = up_ctx}</p>
<p>let go_left loc = match loc.ctx with | [] -&gt; invalid_arg “go_left:
at top” | (l :: left, right) :: up_ctx -&gt; (* Move to left sibling;
current element moves to right siblings *) {sub = l; ctx = (left,
loc.sub :: right) :: up_ctx} | ([], <em>) :: </em> -&gt; invalid_arg
“go_left: at first”</p>
<p>let go_right loc = match loc.ctx with | [] -&gt; invalid_arg
“go_right: at top” | (left, r :: right) :: up_ctx -&gt; (* Move to right
sibling; current element moves to left siblings *) {sub = r; ctx =
(loc.sub :: left, right) :: up_ctx} | (<em>, []) :: </em> -&gt;
invalid_arg “go_right: at last”</p>
<p>let go_down loc = (* Go to the first (i.e. leftmost) subdocument
<em>) match loc.sub with | Text _ -&gt; invalid_arg “go_down: at text” |
Line -&gt; invalid_arg “go_down: at line” | Group [] -&gt; invalid_arg
“go_down: at empty” | Group (doc :: docs) -&gt; (</em> First child
becomes focus; rest become right siblings *) {sub = doc; ctx = ([],
docs) :: loc.ctx}</p>
<pre><code>
### 10.2 Example: Context Rewriting

Let us put zippers to work on a real problem. Imagine a friend working on string theory asks us for help simplifying equations. The task is to pull out particular subexpressions as far to the left as possible, while changing the whole expression as little as possible. This kind of algebraic manipulation is common in symbolic computation.

We can illustrate our algorithm using mathematical notation. Let:
- $x$ be the thing we pull out
- $C[e]$ and $D[e]$ be big expressions with subexpression $e$
- operator $\circ$ stand for one of: $*, +$

The rewriting rules are:

$$
\begin{matrix}
D[(C[x] \circ e_1) \circ e_2] &amp; \Rightarrow &amp; D[C[x] \circ (e_1 \circ e_2)] \\
D[e_2 \circ (C[x] \circ e_1)] &amp; \Rightarrow &amp; D[C[x] \circ (e_1 \circ e_2)] \\
D[(C[x] + e_1) e_2] &amp; \Rightarrow &amp; D[C[x] e_2 + e_1 e_2] \\
D[e_2 (C[x] + e_1)] &amp; \Rightarrow &amp; D[C[x] e_2 + e_1 e_2] \\
D[e \circ C[x]] &amp; \Rightarrow &amp; D[C[x] \circ e]
\end{matrix}
$$

These rules encode the algebraic properties we need: associativity (first two rules), distributivity of multiplication over addition (third and fourth rules), and commutativity (last rule, which lets us swap operands). The key insight is that we can implement these transformations efficiently using a zipper, since each rule only needs to look at a small neighborhood of the current position.

First, the groundwork. We define expression types and a zipper for navigating them:

```ocaml skip
type op = Add | Mul
type expr = Val of int | Var of string | App of expr * op * expr
type expr_dir = Left_arg | Right_arg
type context = (expr_dir * op * expr) list
type location = {sub: expr; ctx: context}</code></pre>
<p>To locate the subexpression described by predicate <code>p</code>, we
search the expression tree and build up the context as we go. Notice
that we build the context in reverse order during the search, then
reverse it at the end so the innermost context comes first (as required
for efficient navigation):</p>
<p>```ocaml skip let rec find_aux p e = if p e then Some (e, []) else
match e with | Val _ | Var _ -&gt; None | App (l, op, r) -&gt; match
find_aux p l with | Some (sub, up_ctx) -&gt; Some (sub, (Right_arg, op,
r) :: up_ctx) | None -&gt; match find_aux p r with | Some (sub, up_ctx)
-&gt; Some (sub, (Left_arg, op, l) :: up_ctx) | None -&gt; None</p>
<p>let find p e = match find_aux p e with | None -&gt; None | Some (sub,
ctx) -&gt; Some {sub; ctx = List.rev ctx}</p>
<pre><code>
Now we can implement the pull-out transformation. This is where the zipper shines: we pattern match on the context to decide which rewriting rule to apply, then modify the context directly. The function recursively moves the target subexpression outward until it reaches the root:

```ocaml skip
let rec pull_out loc =
  match loc.ctx with
  | [] -&gt; loc  (* Done: reached the root *)
  | (Left_arg, op, l) :: up_ctx -&gt;
    (* D[e . C[x]] =&gt; D[C[x] . e] -- use commutativity to swap sides *)
    pull_out {loc with ctx = (Right_arg, op, l) :: up_ctx}
  | (Right_arg, op1, e1) :: (_, op2, e2) :: up_ctx
      when op1 = op2 -&gt;
    (* D[(C[x] . e1) . e2] =&gt; D[C[x] . (e1 . e2)] -- associativity *)
    pull_out {loc with ctx = (Right_arg, op1, App(e1, op1, e2)) :: up_ctx}
  | (Right_arg, Add, e1) :: (_, Mul, e2) :: up_ctx -&gt;
    (* D[(C[x] + e1) * e2] =&gt; D[C[x] * e2 + e1 * e2] -- distributivity *)
    pull_out {loc with ctx =
        (Right_arg, Mul, e2) ::
          (Right_arg, Add, App(e1, Mul, e2)) :: up_ctx}
  | (Right_arg, op, r) :: up_ctx -&gt;
    (* No rule applies: move up by incorporating current context *)
    pull_out {sub = App(loc.sub, op, r); ctx = up_ctx}</code></pre>
<p>Since we assume operators are commutative, we can ignore the
direction for the second piece of context above – both
<code>(C[x] . e1) . e2</code> and <code>e2 . (C[x] . e1)</code> are
handled by the same associativity rule.</p>
<p>Let us test the implementation with a concrete example:</p>
<p>```ocaml skip let (+) a b = App (a, Add, b) (* Convenient syntax for
building expressions <em>) let ( </em> ) a b = App (a, Mul, b) let (!) a
= Val a let x = Var “x” let y = Var “y”</p>
<p>(* Original: 5 + y * (7 + x) * (3 + y) – we want to pull x to the
front <em>) let ex = !5 + y </em> (!7 + x) * (!3 + y) let loc = find
(fun e -&gt; e = x) ex let sol = match loc with | None -&gt; raise
Not_found | Some loc -&gt; pull_out loc (* Result:
“(((x<em>y)</em>(3+y))+(((7<em>y)</em>(3+y))+5))” <em>) (</em> The x has
been pulled out to the leftmost position! *)</p>
<pre><code>
The transformation successfully pulled `x` from deep inside the expression to the outermost left position. For best results on complex expressions, we can iterate the `pull_out` function until a fixpoint is reached, ensuring all instances of the target are pulled out as far as possible.

### 10.3 Adaptive Programming (Incremental Computing)

While zippers are elegant for navigating and modifying data structures, they are somewhat unnatural for general-purpose programming. The fundamental problem is this: once we change something using a zipper, how do we propagate those changes through all the computations that depend on the modified data? We would need to rewrite all our algorithms to explicitly work with context changes, which defeats the purpose of clean functional programming.

*Adaptive Programming*, also known as *incremental computation* or *self-adjusting computation*, offers a more elegant solution. The idea is beautifully simple: we write programs in a straightforward functional manner, but the runtime system tracks dependencies between computations. When we later modify any input data, only the minimal amount of work required to update the results is performed -- everything else is reused from before.

The functional description of computation lives within a monad. We can change monadic values -- for example, parts of input -- from outside the computation, and the changes automatically propagate to all dependent results. In the *Froc* library by Jake Donham, the monadic *changeables* are represented by type `&#39;a Froc_sa.t`, and the ability to modify them from outside is exposed by type `&#39;a Froc_sa.u` -- the *writeables*.

#### Dependency Graphs

The key to making incremental computation work is tracking *how* a result was computed, not just *what* the result is. The monadic value `&#39;a changeable` stores the *dependency graph* of the computation of the represented value `&#39;a`.

Consider a simple computation:
</code></pre>
<p>let u = v / w + x * y + z</p>
<pre><code>
This creates a dependency graph where `u` depends on intermediate results (let us call them `n0 = v/w`, `n1 = x*y`, `n2 = n0+n1`), which in turn depend on the input variables. When we modify inputs -- say, both `v` and `z` simultaneously -- the runtime needs to update intermediate nodes in the correct order. Since `n2` depends on `n0`, we must update `n0` before `n2`, and both must be updated before `u`.

The order in which the computation was originally performed determines the order of updates. We record timestamps for each computation, and updates follow this timestamp order. Similar to `parallel` in the concurrency monad from Chapter 8, we provide `bind2`, `bind3`, etc., and corresponding `lift2`, `lift3`, etc., to introduce nodes that depend on several children simultaneously:
</code></pre>
<p>let n0 = bind2 v w (fun v w -&gt; return (v / w)) let n1 = bind2 x y
(fun x y -&gt; return (x * y)) let n2 = bind2 n0 n1 (fun n0 n1 -&gt;
return (n0 + n1)) let u = bind2 n2 z (fun n2 z -&gt; return (n2 +
z))</p>
<pre><code>
The beauty of lifting is that we can make our code look almost identical to ordinary arithmetic. Do-notation is not necessary to have readable expressions:
</code></pre>
<p>let (/) = lift2 (/) let ( * ) = lift2 ( * ) let (+) = lift2 (+) let u
= v / w + x * y + z (* Looks like normal code, but tracks dependencies!
*)</p>
<pre><code>
As in other monads, we can decrease overhead by combining multiple operations into bigger chunks. Instead of creating a dependency node for every single operation, we can batch several operations together:
</code></pre>
<p>let n0 = blift2 v w (fun v w -&gt; v / w) let n2 = blift3 n0 x y (fun
n0 x y -&gt; n0 + x * y) let u = blift2 n2 z (fun n2 z -&gt; n2 + z)</p>
<pre><code>
#### Handling Conditional Dependencies

There is a subtlety that arises with conditionals. Consider this example:
</code></pre>
<p>let b = x &gt;&gt;= fun x -&gt; return (x = 0) let n0 = x &gt;&gt;=
fun x -&gt; return (100 / x) let y = bind2 b n0 (fun b n0 -&gt; if b
then return 0 else n0)</p>
<pre><code>
If we blindly recompute all nodes in their original order when `x` changes, we have a problem. If `x` becomes 0, we would compute `n0 = 100 / 0` and crash -- even though the conditional in `y` would never use that result!

The solution is to use *time intervals* rather than single timestamps. Each computation records when it began and when it ended. When updating the `y` node, we first *detach* all nodes in its time range (let us say 4-9) from the graph. The conditional is then recomputed, and it will re-attach only the nodes it actually needs. If `b` is true, the `n0` computation is never re-attached and thus never re-executed.

What if the value of `b` does not change? Then we can skip updating `y` entirely and proceed directly to updating `n0`. Since `y` contains a link to the value of `n0`, the final result of `y` will still reflect any changes to `n0`.

We also need *memoization* to efficiently re-attach the same nodes when they do not need updating. When should a detached node be considered up-to-date? When the update process has progressed past that node&#39;s timestamp range, it is safe to re-attach it unchanged.

#### Example Using Froc

Let us see adaptive programming in action with a concrete example: incrementally growing and displaying a tree. The `Froc_sa` module (for *self-adjusting*) exports the monadic type `t` for changeable computation, and a handle type `u` for updating the computation from outside.

We define a binary tree where each node stores its screen location. Crucially, the children are wrapped in the `t` type, making them changeable:

```ocaml skip
open Froc_sa

type tree =
  | Leaf of int * int              (* A leaf stores its x,y position *)
  | Node of int * int * tree t * tree t  (* Children are changeable! *)</code></pre>
<p>Displaying the tree is itself a changeable effect. Whenever the tree
changes, the display will be automatically updated. The key insight is
that only <em>new</em> nodes will be drawn after an update – unchanged
parts of the tree do not trigger any drawing:</p>
<p><code>ocaml skip let rec display px py t =  (* px, py = parent position for drawing line *)   match t with   | Leaf (x, y) -&gt;     return       (Graphics.draw_poly_line [|px, py; x, y|];  (* Draw line to parent *)        Graphics.draw_circle x y 3)  (* Draw the leaf node *)   | Node (x, y, l, r) -&gt;     return (Graphics.draw_poly_line [|px, py; x, y|])     &gt;&gt;= fun _ -&gt; l &gt;&gt;= display x y  (* Recursively display left child *)     &gt;&gt;= fun _ -&gt; r &gt;&gt;= display x y  (* Recursively display right child *)</code></p>
<p>Now the interesting part: growing the tree. The <code>grow_at</code>
function replaces a leaf with a new internal node that has two leaf
children. The crucial operations are <code>changeable</code> (which
creates a new changeable value with a writeable handle) and
<code>write</code> (which updates a changeable from outside):</p>
<p><code>ocaml skip let grow_at (x, depth, upd) =   (* Calculate positions for left and right children *)   let x_l = x - f2i (width *. (2.0 ** (~-. (i2f (depth + 1))))) in   let l, upd_l = changeable (Leaf (x_l, (depth + 1) * 20)) in   let x_r = x + f2i (width *. (2.0 ** (~-. (i2f (depth + 1))))) in   let r, upd_r = changeable (Leaf (x_r, (depth + 1) * 20)) in   (* Replace the old leaf with a new internal node *)   write upd (Node (x, depth * 20, l, r));   propagate ();  (* Trigger update propagation! *)   (* Return handles for future growth at the new leaves *)   [x_l, depth + 1, upd_l; x_r, depth + 1, upd_r]</code></p>
<p>The main loop grows the tree level by level, calling
<code>grow_at</code> for every leaf at the current frontier:</p>
<p>```ocaml skip let rec loop t subts steps = if steps &lt;= 0 then ()
else loop t (concat_map grow_at subts) (steps - 1)</p>
<p>let incremental steps () = Graphics.open_graph ” 1024x600”; let t, u
= changeable (Leaf (512, 20)) in (* Set up the display ONCE – it will
update automatically! <em>) let d = t &gt;&gt;= display (f2i (width /.
2.)) 0 in loop t [512, 1, u] steps; (</em> New nodes will be drawn
automatically *) Graphics.close_graph ()</p>
<pre><code>
Notice the elegance: we set up the display computation once, and then as we grow the tree by writing to changeable leaves, the display automatically updates to show only the new nodes. The dependency tracking ensures that only the affected parts of the display computation are re-executed.

However, there is a practical caveat: the overhead of incremental computation is quite large. Comparing byte code execution times for growing and displaying trees of various depths:

| depth | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 |
|-------|-----|-----|-----|-----|-----|-----|-----|------|------|
| incremental | 0.66s | 1s | 2.2s | 4.4s | 9.3s | 21s | 50s | 140s | 255s |
| rebuilding | 0.5s | 0.63s | 1.3s | 3s | 5.3s | 13s | 39s | 190s | -- |

Rebuilding the entire tree from scratch is actually faster for smaller depths! Incremental computation only wins when changes are small relative to the total computation. The moral: use incremental computation when you expect to make many small updates to a large structure, not when building something from scratch.

### 10.4 Functional Reactive Programming

We have seen how zippers let us navigate structures and how adaptive programming propagates changes. But what about programs that must respond to *time* itself -- animations, games, interactive applications? This is the domain of *Functional Reactive Programming* (FRP).

FRP is an attempt to declaratively deal with time. The key insight is to distinguish two kinds of time-varying values:

- *Behaviors* are continuous functions of time. A behavior has a specific value at every instant. Think of a mouse position, window size, or the current frame of an animation.

- *Events* are discrete occurrences. An event is a set of (time, value) pairs, organized into streams of actions. Think of mouse clicks, key presses, or timer ticks.

Two fundamental problems arise in FRP:

1. **Causality**: Behaviors and events must be well-defined, which means they cannot depend on future values. A behavior at time $t$ can only depend on events that have already occurred.

2. **Efficiency**: We need to minimize the overhead of tracking time and dependencies, especially for real-time applications like games.

FRP is *synchronous*: it is possible to set up multiple events to happen at exactly the same time, and the system handles this correctly. It is also *continuous*: behaviors can have details at arbitrary time resolution. Although the actual results are *sampled* at discrete moments, there is no fixed (minimal) time step for specifying behavior -- you describe what the behavior *should be* at any time, and the system samples it as needed.

(Note: &quot;Asynchrony&quot; in reactive programming refers to various different ideas depending on context, so always ask what people mean when they use the term.)

#### Idealized Definitions

Let us start with the idealized, mathematical definitions and then see how practical considerations force us to refine them.

In the purest form, we would define:

```ocaml skip
type time = float
type &#39;a behavior = time -&gt; &#39;a  (* Arbitrary function of time *)
type &#39;a event = (&#39;a, time) stream  (* Stream of values at increasing time instants *)</code></pre>
<p>This is mathematically elegant: a behavior is literally a function
from time to values, and events are a lazy stream of timestamped
occurrences. Forcing the stream would block until the next event
arrives.</p>
<p>But this idealized view has problems. Behaviors need to react to
external events – the position of a paddle should follow the mouse, not
just be a predetermined function of time:</p>
<p>```ocaml skip type user_action = | Key of char * bool | Button of int
* int * bool * bool | MouseMove of int * int | Resize of int * int</p>
<p>type ’a behavior = user_action event -&gt; time -&gt; ’a</p>
<pre><code>
Now a behavior takes both the event history and the current time. But this leads to an efficiency problem: every time we evaluate a behavior, we would need to scan through all events from the beginning of time up to the current moment. This is wasteful in both time and space.

The solution is to turn behaviors into stream transformers. Instead of a function that answers &quot;what is the value at time $t$?&quot;, we produce a stream of values, one for each sampling time. This allows us to forget about events that are already in the past:

```ocaml skip
type &#39;a behavior =
  user_action event -&gt; time stream -&gt; &#39;a stream</code></pre>
<p>The next optimization is to combine the user actions and sampling
times into a single stream. At each sampling moment, we either have a
user action or nothing happened:</p>
<p><code>ocaml skip type 'a behavior =   (user_action option * time) stream -&gt; 'a stream</code></p>
<p>The <code>None</code> action corresponds to a sampling moment when
nothing happened – we still need to produce a value for the behavior at
that time, even if no event triggered it.</p>
<p>This transformation from functions-of-time to stream transformers is
analogous to a classic algorithm optimization: computing the
intersection of two sorted lists. The naive approach checks every pair,
giving <span class="math inline">O(mn)</span> time. The smart approach
walks through both lists simultaneously, giving <span
class="math inline">O(m + n)</span> time. Similarly, our stream-based
behaviors process time and events together in a single pass.</p>
<p>With behaviors as stream transformers, we can elegantly define events
in terms of behaviors:</p>
<p><code>ocaml skip type 'a event = 'a option behavior</code></p>
<p>An event is simply a behavior that produces <code>None</code> at most
sampling times and <code>Some value</code> when the event actually
occurs. This unifies our treatment of behaviors and events, although it
somewhat betrays the discrete character of events (they conceptually
happen at points in time, not vary over intervals).</p>
<p>We have now arrived at something very close to the <em>stream
processing</em> we discussed in Chapter 7. Recall the incremental
pretty-printing example that could “react” to more input being added.
The stream combinators we developed there, along with <em>fork</em>
(from the exercises) and a corresponding <em>merge</em>, turn stream
processing into <em>synchronous discrete reactive programming</em>. FRP
is, in a sense, stream processing with explicit time.</p>
<h4 id="behaviors-as-monads">Behaviors as Monads</h4>
<p>Behaviors form a monad – at least in the original, idealized
specification. Looking at the simple definition
<code>type 'a behavior = time -&gt; 'a</code>, we can define:</p>
<p>```ocaml skip type ’a behavior = time -&gt; ’a</p>
<p>val return : ’a -&gt; ’a behavior let return a = fun _ -&gt; a (*
Constant behavior: same value at all times *)</p>
<p>val bind : ‘a behavior -&gt; (’a -&gt; ’b behavior) -&gt; ’b behavior
let bind a f = fun t -&gt; f (a t) t (* Sample ’a’ at time t, then
sample the result *)</p>
<pre><code>
The `return` function creates a constant behavior that has the same value at all times. The `bind` function samples the first behavior at the current time, uses that value to select a second behavior, and samples *that* at the current time.

In practice, as we saw with changeables, we mostly use *lifting* rather than full monadic bind. In the Haskell world, behaviors are often called *applicative* rather than monadic. We can build our own lifting functions from the applicative `ap` combinator:
</code></pre>
<p>val ap : (’a -&gt; ’b) monad -&gt; ’a monad -&gt; ’b monad let ap fm
am = let* f = fm in let* a = am in return (f a)</p>
<pre><code>
A word of caution: for changeables and other incremental systems, this naive implementation of `ap` will introduce unnecessary dependencies in the computation graph. If `fm` changes, we would unnecessarily recompute everything even if only `am` matters for the result. Good FRP and incremental computing libraries provide optimized variants that track dependencies more precisely. This is analogous to how we needed `parallel` (rather than sequential bind) for concurrent computing in Chapter 8.

#### Converting Between Events and Behaviors

One of the most important operations in FRP is converting between events and behaviors. Going from events to behaviors, the key combinators `until` and `switch` have type:
</code></pre>
<p>’a behavior -&gt; ’a behavior event -&gt; ’a behavior</p>
<pre><code>
while `step` has type:
</code></pre>
<p>’a -&gt; ’a event -&gt; ’a behavior</p>
<pre><code>
Here is what each does:

- `until b es` behaves as `b` until the first event in `es` occurs, then permanently switches to behaving as the behavior carried by that event. This is &quot;one-shot&quot; switching.

- `switch b es` behaves as the behavior from the *most recent* event in `es` (prior to current time), if any event has occurred, otherwise it behaves as `b`. Unlike `until`, this keeps switching whenever a new event arrives.

- `step a es` is the simplest: it starts as a constant behavior returning `a`, and then switches to returning the value of the most recent event in `es`. This creates a *step function* -- a behavior that jumps from value to value at discrete times.

We will use the term &quot;*signal*&quot; to refer to either a behavior or an event. Be aware that terminology varies across FRP libraries: some use &quot;signal&quot; to mean specifically what we call a behavior. Always check the documentation when working with a new FRP library.

### 10.5 Reactivity by Stream Processing

Now let us implement FRP using the stream processing techniques from Chapter 7. The infrastructure should be familiar:

```ocaml skip
type &#39;a stream = &#39;a stream_ Lazy.t
and &#39;a stream_ = Cons of &#39;a * &#39;a stream

let rec lmap f l = lazy (
  let Cons (x, xs) = Lazy.force l in
  Cons (f x, lmap f xs))

let rec liter (f : &#39;a -&gt; unit) (l : &#39;a stream) : unit =
  let Cons (x, xs) = Lazy.force l in
  f x; liter f xs

let rec lmap2 f xs ys = lazy (
  let Cons (x, xs) = Lazy.force xs in
  let Cons (y, ys) = Lazy.force ys in
  Cons (f x y, lmap2 f xs ys))

let rec lmap3 f xs ys zs = lazy (
  let Cons (x, xs) = Lazy.force xs in
  let Cons (y, ys) = Lazy.force ys in
  let Cons (z, zs) = Lazy.force zs in
  Cons (f x y z, lmap3 f xs ys zs))

let rec lfold acc f (l : &#39;a stream) = lazy (
  let Cons (x, xs) = Lazy.force l in  (* Fold a function over the stream *)
  let acc = f acc x in  (* producing a stream of partial results *)
  Cons (acc, lfold acc f xs))</code></pre>
<p>Since a behavior is a function from the input stream to an output
stream, we face a subtle sharing problem: if we apply the same behavior
function twice to the “same” input, we might create two separate streams
that diverge. We need to ensure that for any actual input stream, each
behavior creates exactly one output stream. This requires
memoization:</p>
<p>```ocaml skip type (’a, ’b) memo1 = {memo_f : ’a -&gt; ’b; mutable
memo_r : (’a * ’b) option}</p>
<p>let memo1 f = {memo_f = f; memo_r = None}</p>
<p>let memo1_app f x = match f.memo_r with | Some (y, res) when x == y
-&gt; res (* Physical equality check <em>) | _ -&gt; let res = f.memo_f
x in f.memo_r &lt;- Some (x, res); (</em> Cache for next call *) res</p>
<p>let ($) = memo1_app (* Convenient infix for memoized application
*)</p>
<p>type ’a behavior = ((user_action option * time) stream, ’a stream)
memo1</p>
<pre><code>
We use physical equality (`==`) rather than structural equality (`=`) because the external input stream is a single physical object -- if we see the same pointer, we know it is the same stream. During debugging, we can verify that `memo_r` is `None` before the first call and `Some` afterwards.

#### Building Complex Behaviors

Now we can build the monadic/applicative functions for composing behaviors. A practical tip: when working with these higher-order types, type annotations are essential. If you do not provide type annotations in `.ml` files, work together with an `.mli` interface file to catch type problems early.

```ocaml skip
(* A constant behavior: returns the same value at all times *)
let returnB x : &#39;a behavior =
  let rec xs = lazy (Cons (x, xs)) in  (* Infinite stream of x *)
  memo1 (fun _ -&gt; xs)

let ( !* ) = returnB  (* Convenient prefix operator for constants *)

(* Lift a unary function to work on behaviors *)
let liftB f fb = memo1 (fun uts -&gt; lmap f (fb $ uts))

(* Lift binary and ternary functions similarly *)
let liftB2 f fb1 fb2 = memo1
  (fun uts -&gt; lmap2 f (fb1 $ uts) (fb2 $ uts))

let liftB3 f fb1 fb2 fb3 = memo1
  (fun uts -&gt; lmap3 f (fb1 $ uts) (fb2 $ uts) (fb3 $ uts))

(* Lift a function to work on events (None -&gt; None, Some e -&gt; Some (f e)) *)
let liftE f (fe : &#39;a event) : &#39;b event = memo1
  (fun uts -&gt; lmap
    (function Some e -&gt; Some (f e) | None -&gt; None)
    (fe $ uts))

let (=&gt;&gt;) fe f = liftE f fe  (* Map over events, infix style *)
let (-&gt;&gt;) e v = e =&gt;&gt; fun _ -&gt; v  (* Replace event value with constant *)</code></pre>
<p>We also need to create events from behaviors and vice versa. Creating
events out of behaviors:</p>
<p>```ocaml skip (* whileB: produces an event at every moment the
behavior is true *) let whileB (fb : bool behavior) : unit event = memo1
(fun uts -&gt; lmap (function true -&gt; Some () | false -&gt; None) (fb
$ uts))</p>
<p>(* unique: filters out duplicate consecutive events <em>) let unique
fe : ’a event = memo1 (fun uts -&gt; let xs = fe $ uts in lmap2 (fun x y
-&gt; if x = y then None else y) (lazy (Cons (None, xs))) xs) (</em>
Compare with previous value *)</p>
<p>(* whenB: produces an event when the behavior becomes true (edge
detection) *) let whenB fb = memo1 (fun uts -&gt; unique (whileB fb) $
uts)</p>
<p>(* snapshot: when an event occurs, capture both the event value and
current behavior value <em>) let snapshot fe fb : (’a </em> ’b) event =
memo1 (fun uts -&gt; lmap2 (fun x -&gt; function Some y -&gt; Some (y,
x) | None -&gt; None) (fb $ uts) (fe $ uts))</p>
<pre><code>
Creating behaviors out of events:

```ocaml skip
(* step: holds the value of the most recent event, starting with &#39;acc&#39; *)
let step acc fe =
  memo1 (fun uts -&gt; lfold acc
    (fun acc -&gt; function None -&gt; acc | Some v -&gt; v)
    (fe $ uts))

(* step_accum: accumulates by applying functions from events to current value *)
let step_accum acc ff =
  memo1 (fun uts -&gt;
    lfold acc (fun acc -&gt; function
      | None -&gt; acc | Some f -&gt; f acc)
      (ff $ uts))</code></pre>
<p>For physics simulations like our upcoming paddle game, we need to
integrate behaviors over time. This requires access to the sampling
timestamps:</p>
<p><code>ocaml skip let integral fb =   let rec loop t0 acc uts bs =     let Cons ((_, t1), uts) = Lazy.force uts in     let Cons (b, bs) = Lazy.force bs in     (* Rectangle rule: b is fb(t1), acc approximates integral up to t0 *)     let acc = acc +. (t1 -. t0) *. b in     Cons (acc, lazy (loop t1 acc uts bs)) in   memo1 (fun uts -&gt; lazy (     let Cons ((_, t), uts') = Lazy.force uts in     Cons (0., lazy (loop t 0. uts' (fb $ uts)))))</code></p>
<p>In our upcoming <em>paddle game</em> example, we will express
position and velocity in a mutually recursive manner – position is the
integral of velocity, but velocity changes when position hits a wall.
This seems paradoxical: how can we define position in terms of velocity
if velocity depends on position?</p>
<p>The trick is the same as we saw in Chapter 7: integration introduces
one step of delay. The integral at time <span
class="math inline">t</span> depends on velocities at times
<em>before</em> <span class="math inline">t</span>, while the bounce
detection at time <span class="math inline">t</span> uses the position
at time <span class="math inline">t</span>. This breaks the cyclic
dependency and makes the recursion well-founded.</p>
<p>We define behaviors for user actions by extracting them from the
input stream:</p>
<p>```ocaml skip (* Left button press event *) let lbp : unit event =
memo1 (fun uts -&gt; lmap (function Some(Button(<em>,</em>)), _ -&gt;
Some() | _ -&gt; None) uts)</p>
<p>(* Mouse movement event (carries coordinates) <em>) let mm : (int
</em> int) event = memo1 (fun uts -&gt; lmap (function Some(MouseMove(x,
y)), _ -&gt; Some(x, y) | _ -&gt; None) uts)</p>
<p>(* Window resize event <em>) let screen : (int </em> int) event =
memo1 (fun uts -&gt; lmap (function Some(Resize(x, y)), _ -&gt; Some(x,
y) | _ -&gt; None) uts)</p>
<p>(* Behaviors derived from events using step <em>) let mouse_x : int
behavior = step 0 (liftE fst mm) (</em> Current mouse X <em>) let
mouse_y : int behavior = step 0 (liftE snd mm) (</em> Current mouse Y
<em>) let width : int behavior = step 640 (liftE fst screen) (</em>
Window width <em>) let height : int behavior = step 512 (liftE snd
screen) (</em> Window height *)</p>
<pre><code>
#### The Paddle Game Example

Now let us put all these pieces together to build a classic paddle game (similar to Pong). A ball bounces around the screen, and the player controls a paddle at the bottom to prevent the ball from falling.

First, we define a *scene graph*, a data structure that represents a &quot;world&quot; which can be drawn on screen:

```ocaml skip
type scene =
  | Rect of int * int * int * int  (* position, width, height *)
  | Circle of int * int * int  (* position, radius *)
  | Group of scene list
  | Color of Graphics.color * scene  (* color of subscene objects *)
  | Translate of float * float * scene  (* additional offset of origin *)</code></pre>
<p>The drawing function interprets the scene graph, accumulating
translations as it traverses:</p>
<p><code>ocaml skip let draw sc =   let f2i = int_of_float in   let open Graphics in   let rec aux t_x t_y = function  (* t_x, t_y accumulate translations *)     | Rect (x, y, w, h) -&gt;       fill_rect (f2i t_x + x) (f2i t_y + y) w h     | Circle (x, y, r) -&gt;       fill_circle (f2i t_x + x) (f2i t_y + y) r     | Group scs -&gt;       List.iter (aux t_x t_y) scs     | Color (c, sc) -&gt;       set_color c; aux t_x t_y sc  (* Set color, then draw *)     | Translate (x, y, sc) -&gt;       aux (t_x +. x) (t_y +. y) sc in  (* Add to accumulated offset *)   clear_graph ();  (* Clear the back buffer *)   aux 0. 0. sc;   synchronize ()  (* Swap buffers -- this avoids flickering *)</code></p>
<p>An <em>animation</em> is simply a scene behavior – a time-varying
scene. The <code>reactimate</code> function runs the animation loop: it
creates the input stream (user actions paired with sampling times),
feeds it to the scene behavior to get a stream of scenes, and draws each
scene. We use double buffering to avoid flickering.</p>
<p>For the game logic, we define lifted operators so we can write
behavior expressions naturally:</p>
<p><code>ocaml skip let (+*) = liftB2 (+)    (* Addition on behaviors *) let (-*) = liftB2 (-)    (* Subtraction on behaviors *) let ( *** ) = liftB2 ( * )  (* Multiplication on behaviors *) let (/*) = liftB2 (/)    (* Division on behaviors *) let (&amp;&amp;*) = liftB2 (&amp;&amp;)  (* Logical AND on behaviors *) let (||*) = liftB2 (||)  (* Logical OR on behaviors *) let (&lt;*) = liftB2 (&lt;)    (* Less-than on behaviors *) let (&gt;*) = liftB2 (&gt;)    (* Greater-than on behaviors *)</code></p>
<p>Now we can define the game elements. The walls are drawn on the left,
top and right borders of the window:</p>
<p><code>ocaml skip let walls =   liftB2 (fun w h -&gt; Color (Graphics.blue, Group     [Rect (0, 0, 20, h-1); Rect (0, h-21, w-1, 20);      Rect (w-21, 0, 20, h-1)]))     width height</code></p>
<p>The paddle is tied to the mouse at the bottom border of the
window:</p>
<p><code>ocaml skip let paddle = liftB (fun mx -&gt;   Color (Graphics.black, Rect (mx, 0, 50, 10))) mouse_x</code></p>
<p>The ball has a velocity in pixels per second and bounces from the
walls. Unfortunately, OCaml being an eager language does not let us
encode mutually recursive behaviors as elegantly as we might in a lazy
language like Haskell. We need to unpack behaviors and events as
explicit functions of the input stream and tie the knot manually using
mutable record fields.</p>
<p>The key ideas in the ball implementation:</p>
<ul>
<li><p><code>xbounce -&gt;&gt; (~-.)</code> – When an
<code>xbounce</code> event fires, emit the negation function
<code>(~-.)</code>. This will be used to flip the velocity
sign.</p></li>
<li><p><code>step_accum vel (xbounce -&gt;&gt; (~-.))</code> – Start
with velocity <code>vel</code>, and whenever a bounce event occurs,
apply the negation function to flip the sign. This creates a velocity
that bounces back and forth.</p></li>
<li><p><code>liftB int_of_float (integral xvel) +* width /* !*2</code> –
Integrate velocity to get position (as a float), truncate to integers,
and offset to center the ball in the window.</p></li>
<li><p><code>whenB ((xpos &gt;* width -* !*27) ||* (xpos &lt;* !*27))</code>
– Fire an event the <em>first</em> time the position exceeds the wall
boundaries (27 pixels from edges, accounting for wall thickness and ball
radius). The <code>whenB</code> combinator produces an event only on the
<em>transition</em> from false to true, ensuring we do not keep bouncing
while inside the wall.</p></li>
</ul>
<h3 id="reactivity-by-incremental-computing">10.6 Reactivity by
Incremental Computing</h3>
<p>In the previous section, we implemented FRP using lazy streams. An
alternative approach is to use the incremental computing infrastructure
from Section 10.3. The <em>Froc</em> library takes this approach.</p>
<p>In <em>Froc</em>, both behaviors and events are implemented as
changeables, but they have different lifetimes. Behaviors
<em>persist</em> – they always have a current value. Events are
<em>instantaneous</em> – they fire, propagate their values, and then are
removed from the dependency graph. This captures an intuitive
distinction: a behavior like “current mouse position” always exists,
while an event like “mouse button pressed” happens at a moment and is
gone.</p>
<p>Behaviors are composed out of constants and prior events, capturing
the “changeable” aspect. Events capture the “writeable” aspect – they
are how external inputs enter the system. Together, events and behaviors
are called <em>signals</em>.</p>
<p>One important design choice in <em>Froc</em>: it does not explicitly
represent time. Instead, it provides the function
<code>changes : 'a behavior -&gt; 'a event</code>, which fires an event
whenever a behavior changes. This violates the continuous semantics we
discussed earlier – it breaks the illusion that behaviors vary
continuously rather than at discrete points. But it simplifies the
implementation by avoiding the need to synchronize global time samples
with events. The result is “less continuous but more dense” in the sense
that updates happen exactly when needed, not at fixed intervals.</p>
<p>Sending an event using <code>send</code> starts an <em>update
cycle</em>. During an update cycle, all dependent signals are brought up
to date. Signals themselves cannot call <code>send</code> (that would
create unpredictable cascades), but they can call
<code>send_deferred</code>, which schedules an event for the
<em>next</em> update cycle. Things that happen in the same update cycle
are considered <em>simultaneous</em>.</p>
<p><em>Froc</em> provides <code>fix_b</code> and <code>fix_e</code>
functions to define signals recursively. The “current value” in a
recursive definition refers to the value from the <em>previous</em>
update cycle, and each recursive step is deferred to the next cycle,
until values converge.</p>
<p>Update cycles can happen “back-to-back” via
<code>send_deferred</code> and <code>fix_b</code>/<code>fix_e</code>, or
can be triggered from outside <em>Froc</em> by sending events at
arbitrary times. With a <code>time</code> behavior that tracks a clock
event, events from back-to-back update cycles can have the same clock
time even though they are not simultaneous in the FRP sense. This
architecture prevents <em>glitches</em>, where an outdated signal value
is accidentally used before it has been updated.</p>
<h4 id="pure-vs.-impure-style">Pure vs. Impure Style</h4>
<p><em>Froc</em> supports two programming styles. A behavior is written
in <em>pure style</em> when its definition does not use
<code>send</code>, <code>send_deferred</code>, <code>notify_e</code>,
<code>notify_b</code>, or <code>sample</code>. In pure style:</p>
<ul>
<li><code>sample</code>, <code>notify_e</code>, <code>notify_b</code>
are used only from <em>outside</em> the behavior (from its
“environment”) – analogous to observing the result of a function after
it completes</li>
<li><code>send</code>, <code>send_deferred</code> are used only from
outside – analogous to providing input to a function before it runs</li>
</ul>
<p>In <em>impure style</em>, we can freely mix signal definitions with
imperative notifications and samples. This is more flexible but has an
important pitfall: we must ensure that all pieces of our behavior are
<em>referred to</em> from somewhere, otherwise the garbage collector
will reclaim them and our behavior will mysteriously stop working!</p>
<p>A value is “referred to” when it has a name in the global
environment, or is stored as part of a larger value that is referred to.
Signals are also referred to when they are part of the dependency graph.
If you define a signal, attach a notification to it, but do not keep the
signal itself alive, the notification may stop working when the signal
is garbage collected.</p>
<h4 id="reimplementing-the-paddle-game-example">Reimplementing the
Paddle Game Example</h4>
<p>Let us reimplement the paddle game using <em>Froc</em> instead of
lazy streams. We will follow the same structure as our stream-based FRP
example: a scene behavior that represents the complete game state at
each moment.</p>
<p>First, we introduce time explicitly (since <em>Froc</em> does not
track it automatically):</p>
<p><code>ocaml skip open Froc let clock, tick = make_event ()  (* clock event, tick to send it *) let time = hold (Unix.gettimeofday ()) clock  (* Behavior: current time *)</code></p>
<p>The main loop will call <code>send tick current_time</code> at each
frame. Now we can define integration. Note the use of
<code>sample</code> to read the current value of a behavior – this is
the impure style:</p>
<p><code>ocaml skip let integral fb =   let aux (sum, t0) t1 =     sum +. (t1 -. t0) *. sample fb, t1 in   collect_b aux (0., sample time) clock</code></p>
<p>For convenience, the integral remembers the current upper limit of
integration. It will be useful to get the integer part:</p>
<p><code>ocaml skip let integ_res fb =   lift (fun (v, _) -&gt; int_of_float v) (integral fb)</code></p>
<p>We can also define integration in <em>pure style</em>, which avoids
calling <code>sample</code> inside the behavior definition:</p>
<p>```ocaml skip let pair fa fb = lift2 (fun x y -&gt; x, y) fa fb</p>
<p>let integral_nice fb = let samples = changes (pair fb time) in (*
Event when either changes <em>) let aux (sum, t0) (fv, t1) = sum +. (t1
-. t0) </em>. fv, t1 in collect_b aux (0., sample time) samples</p>
<pre><code>
The initial value `(0., sample time)` uses `sample`, but this is evaluated *once* when setting up the behavior, not inside the behavior definition itself, so it does not spoil the pure style.

### 10.7 Direct Control

The declarative style of FRP is elegant for continuous behaviors, but real-world interactions are often *state machines* that proceed through distinct stages. Consider a recipe: *1. Preheat the oven. 2. Put flour, sugar, eggs into a bowl. 3. Mix well. 4. Pour into pan.* Each step must complete before the next begins. How do we express this kind of sequential, staged behavior in FRP?

We want a *flow* that can proceed through events in sequence: when the first event arrives, we remember its result, and then wait for the next event. Crucially, we *ignore* any further occurrences of the first event after we have moved on. Standard FRP constructs like mapping events or attaching notifications do not give us this &quot;move forward and never look back&quot; semantics.

We also want to be able to *repeat* or *loop* a flow. But the loop should restart from the notification of the first event that arrives *after* the previous iteration completed -- not from events that happened during the previous iteration.

The key primitive is `next e`, an event that propagates only the *first* occurrence of `e` and then goes silent. This will be the basis of our `await` function.

Additionally, the whole flow should be *cancellable* from outside at any time -- for instance, when the user quits the application.

If this sounds familiar, it should: a flow is essentially a *lightweight thread* as we discussed at the end of Chapter 8. We will make it a monad. Unlike general threads, a flow only &quot;stores&quot; a non-unit value when it is suspended waiting for an event (via `await`). But it has a primitive to `emit` values. We are actually implementing *coarse-grained* threads (Chapter 8 exercise 11), with `await` playing the role of `suspend`.

We build a module `Flow` with monadic type `(&#39;a, &#39;b) flow`. The type has two parameters: `&#39;a` is the type of values we emit (output), and `&#39;b` is the type of values we store (the result of awaited events):

```ocaml skip
type (&#39;a, &#39;b) flow
type cancellable  (* Handle to cancel a flow and stop further computation *)

val noop_flow : (&#39;a, unit) flow  (* Do nothing, same as return () *)
val return : &#39;b -&gt; (&#39;a, &#39;b) flow  (* Immediately completed flow with result &#39;b *)
val await : &#39;b Froc.event -&gt; (&#39;a, &#39;b) flow  (* Suspend until event fires *)
val bind :   (* Sequential composition of flows *)
  (&#39;a, &#39;b) flow -&gt; (&#39;b -&gt; (&#39;a, &#39;c) flow) -&gt; (&#39;a, &#39;c) flow
val emit : &#39;a -&gt; (&#39;a, unit) flow  (* Output a value *)
val cancel : cancellable -&gt; unit  (* Cancel a running flow *)
val repeat :  (* Loop until the &#39;until&#39; event fires; return that event&#39;s value *)
  ?until:&#39;a Froc.event -&gt; (&#39;b, unit) flow -&gt; (&#39;b, &#39;a) flow
val event_flow :   (* Turn a flow into an event that fires on each emit *)
  (&#39;a, unit) flow -&gt; &#39;a Froc.event * cancellable
val behavior_flow :  (* Turn a flow into a behavior; initial value + flow to update *)
  &#39;a -&gt; (&#39;a, unit) flow -&gt; &#39;a Froc.behavior * cancellable
val is_cancelled : cancellable -&gt; bool  (* Check if flow was cancelled *)</code></pre>
<h4 id="implementation-details">Implementation Details</h4>
<p>The implementation follows our lightweight threads from Chapter 8 (or
the <em>Lwt</em> library), adapted for the needs of cancellation:</p>
<p><code>ocaml skip module F = Froc type 'a result =   | Return of 'a  (* Completed with value *)   | Sleep of ('a -&gt; unit) list * F.cancel ref list  (* Waiting for wakeup *)   | Cancelled  (* Flow was cancelled *)   | Link of 'a state  (* Indirection to another state *) and 'a state = {mutable state : 'a result} type cancellable = unit state  (* Handle to check/trigger cancellation *)</code></p>
<p>The <code>Sleep</code> state holds both waiters (callbacks to invoke
when a result arrives) and a list of <em>Froc</em> cancel handles (for
cancelling event notifications if the flow is cancelled).</p>
<p>Functions <code>find</code>, <code>wakeup</code>,
<code>connect</code> are similar to Chapter 8, with the addition that
connecting to a cancelled flow cancels the other flow as well.</p>
<p>The key insight is that our flow monad is actually a <em>reader
monad</em> layered over the state. The reader environment supplies the
<code>emit</code> function:</p>
<p><code>ocaml skip type ('a, 'b) flow = ('a -&gt; unit) -&gt; 'b state</code></p>
<p>The <code>return</code> and <code>bind</code> functions are as in our
lightweight threads, but we need to handle cancelled flows: for
<code>m = bind a b</code>, if <code>a</code> is cancelled then
<code>m</code> is cancelled, and if <code>m</code> is cancelled then we
do not wake up <code>b</code>:</p>
<p><code>ocaml skip let waiter x =   if not (is_cancelled m)   then connect m (b x emit) in   ...</code></p>
<p><code>await</code> is implemented like <code>next</code>, but it
wakes up a flow:</p>
<p><code>ocaml skip let await t = fun emit -&gt;   let c = ref F.no_cancel in   let m = {state = Sleep ([], [c])} in   c :=     F.notify_e_cancel t begin fun r -&gt;       F.cancel !c;       c := F.no_cancel;       wakeup m r     end;   m</code></p>
<p><code>repeat</code> attaches the whole loop as a waiter for the loop
body.</p>
<h4 id="example-drawing-shapes">Example: Drawing Shapes</h4>
<p>Let us see flows in action with a simple drawing program. The user
draws shapes by pressing and dragging the mouse; releasing the mouse
closes the current shape and starts a new one.</p>
<p>The scene is a list of shapes, where the first shape is “open” (still
being drawn) and the rest are closed:</p>
<p>```ocaml skip type scene = (int * int) list list (* First element is
the open shape *)</p>
<p>let draw sc = let open Graphics in clear_graph (); (match sc with |
[] -&gt; () | opn :: cld -&gt; draw_poly_line (Array.of_list opn); (*
Draw open shape as line <em>) List.iter (fill_poly -| Array.of_list)
cld); (</em> Fill closed shapes *) synchronize ()</p>
<pre><code>
Now we build the drawing flow. Notice how naturally we can express the sequential logic: wait for button press, then repeatedly add points until button release, then start over:

```ocaml skip
let painter =
  let cld = ref [] in  (* Accumulated closed shapes *)
  repeat (perform  (* Outer loop: one shape per iteration *)
      await mbutton_pressed;  (* Wait for mouse button down *)
      let opn = ref [] in     (* Points in current shape *)
      repeat (perform  (* Inner loop: points in one shape *)
          mpos &lt;-- await mouse_move;  (* Wait for mouse movement *)
          emit (opn := mpos :: !opn; !opn :: !cld))  (* Emit updated scene *)
        ~until:mbutton_released;  (* Exit inner loop on button release *)
      emit (cld := !opn :: !cld; opn := []; [] :: !cld))  (* Close shape *)

let painter, cancel_painter = behavior_flow [] painter
let () = reactimate painter  (* Run the animation *)</code></pre>
<h4 id="flows-and-state">Flows and State</h4>
<p>Global state and thread-local state can both be used with flows, but
you must pay careful attention to <em>when</em> expressions are
evaluated. The key question is: is this computation <em>inside</em> the
monad (executed when the flow runs), or is it executed <em>while
building</em> the initial monadic value (executed once at setup
time)?</p>
<p>Side effects hidden in <code>return</code> and <code>emit</code>
<em>arguments</em> are evaluated immediately when constructing the flow,
not when the flow runs. This leads to a subtle distinction:</p>
<p>```ocaml skip let f = repeat ( let* () = emit (Printf.printf “[0]%!”;
‘0’) in (* The printf runs NOW <em>) let</em> () = await aas in (*
Suspend until ‘a’ event <em>) let</em> () = emit (Printf.printf “[1]%!”;
‘1’) in (* Printf after resume <em>) let</em> () = await bs in let* () =
emit (Printf.printf “[2]%!”; ‘2’) in let* () = await cs in let* () =
emit (Printf.printf “[3]%!”; ‘3’) in let* () = await ds in emit
(Printf.printf “[4]%!”; ‘4’))</p>
<p>let e, cancel_e = event_flow f let () = F.notify_e e (fun c -&gt;
Printf.printf “flow: %c%!” c); Printf.printf “notification
installed%!”</p>
<p>let () = F.send a (); F.send b (); F.send c (); F.send d (); F.send a
(); F.send b (); F.send c (); F.send d ()</p>
<pre><code>
The output demonstrates this subtle timing:

- `[0]` -- Printed only *once*, when building the loop (not inside the monad!)
- `notification installed` -- Notification set up
- `event: a` -- First event fires
- `[1]` -- Now inside the monad, after first await returns
- `flow: 1` -- Emitted value
- ... continues through the remaining events and loop iterations

The key insight: `[0]` is in the *first line* of the loop before any `await`, so it is evaluated when constructing the `repeat` expression. The `Printf.printf` in subsequent `emit` calls is after a bind (after an `await`), so it runs each time that point in the flow is reached.

### 10.8 Graphical User Interfaces

An in-depth discussion of GUIs is beyond the scope of this course. However, GUIs are a natural application of FRP and flows, so we will cover enough to build a complete example: a calculator.

We demonstrate two OCaml GUI libraries. *LablTk* (based on the Tk toolkit from Tcl) uses optional labelled arguments (discussed in Chapter 2 exercise 2) and polymorphic variants. *LablGTk* (based on GTK+) additionally uses objects. We will learn more about objects and polymorphic variants in the next chapter.

#### Calculator Flow

The calculator is a perfect example of a state machine with sequential stages. We represent its mechanics directly as a flow:

```ocaml skip
let digits, digit = F.make_event ()  (* Events for digit button presses *)
let ops, op = F.make_event ()        (* Events for operator button presses *)
let dots, dot = F.make_event ()      (* Event for decimal point (exercise) *)

let calc =
  (* Two state variables: current number and pending operation *)
  let f = ref (fun x -&gt; x) and now = ref 0.0 in
  repeat (
      (* Phase 1: Enter digits of a number *)
      let* op = repeat (
            let* d = await digits in  (* Wait for digit press *)
            emit (now := 10. *. !now +. d; !now))  (* Build up number *)
        ~until:ops in  (* Until operator button is pressed *)
      (* Phase 2: Apply pending operation, store new operator *)
      let* () = emit (now := !f !now; f := op !now; !now) in
      (* Phase 3: Allow user to change operator before entering next number *)
      let* d = repeat
        (let* op = await ops in return (f := op !now))
        ~until:digits in  (* Until they start entering the next number *)
      (* Phase 4: Reset for the new number *)
      emit (now := d; !now))

let calc_e, cancel_calc = event_flow calc  (* Event notifies display update *)</code></pre>
<p>Notice how the flow structure directly mirrors the user interaction
pattern: enter a number, press an operator, optionally change your mind
about the operator, enter another number, and so on.</p>
<h4 id="tk-labltk">Tk: LablTk</h4>
<p>The <em>Tk</em> widget toolkit originated with the Tcl language and
is known for its simplicity. <em>LablTk</em> provides OCaml bindings
using labelled arguments.</p>
<p>First, we define the layout of our calculator buttons – this part is
the same regardless of which GUI toolkit we use:</p>
<p><code>ocaml skip let layout = [|   [|"7", `Di 7.; "8", `Di 8.; "9", `Di 9.; "+", `O (+.)|];   [|"4", `Di 4.; "5", `Di 5.; "6", `Di 6.; "-", `O (-.)|];   [|"1", `Di 1.; "2", `Di 2.; "3", `Di 3.; "*", `O ( *.)|];   [|"0", `Di 0.; ".", `Dot;   "=",  `O sk; "/", `O (/.)|] |]</code></p>
<p>Each entry is a pair of the button label and its action:
<code>`Di d</code> means send digit <code>d</code>, <code>`O f</code>
means send operator function <code>f</code>, and <code>`Dot</code> means
send the decimal point event (handling this is left as an exercise).</p>
<p>Key GUI concepts in Tk:</p>
<ul>
<li>Every <em>widget</em> (window gadget) has a <em>parent</em> widget
in which it is located</li>
<li><em>Buttons</em> have an action (callback function) invoked when
pressed; <em>labels</em> just display information; <em>entries</em>
(text fields) allow keyboard input</li>
<li>Actions are <em>callback</em> functions passed as the
<code>~command</code> argument</li>
<li><em>Frames</em> group related widgets together</li>
<li>The parent widget is passed as the last argument, after optional
labelled arguments</li>
</ul>
<p>```ocaml skip let top = Tk.openTk () (* Open the main window *)</p>
<p>let btn_frame = Frame.create ~relief:`Groove ~borderwidth:2 top (*
Container for buttons *)</p>
<p>let buttons = Array.map (Array.map (function | text,
<code>Dot -&gt;       Button.create ~text         ~command:(fun () -&gt; F.send dot ()) btn_frame     | text,</code>Di
d -&gt; Button.create ~text ~command:(fun () -&gt; F.send digit d)
btn_frame (* Send digit event <em>) | text, `O f -&gt; Button.create
~text ~command:(fun () -&gt; F.send op f) btn_frame)) (</em> Send
operator event *) layout</p>
<p>let result = Label.create ~text:“0” ~relief:`Sunken top (* Result
display *)</p>
<pre><code>
GUI toolkits provide layout algorithms, so we only specify *which* widgets go together and *how* they should fill space. Tk offers `pack` for sequential layout and `grid` for table-like organization:

Common layout options:

- `~fill:` how the widget fills allocated space: `` `X``, `` `Y``, `` `Both`` or `` `None``
- `~expand:` whether to request extra space (`true`) or only what is needed (`false`)
- `~anchor:` glue the widget to a direction: `` `Center``, `` `E``, `` `Ne``, etc.
- `grid` also supports `~columnspan` and `~rowspan` for multi-cell widgets
- `configure` functions change existing widgets using the same arguments as `create`

```ocaml skip
let () =
  Wm.title_set top &quot;Calculator&quot;;
  Tk.pack [result] ~side:`Top ~fill:`X;  (* Result at top, fills width *)
  Tk.pack [btn_frame] ~side:`Bottom ~expand:true;  (* Buttons below *)
  Array.iteri (fun column -&gt; Array.iteri (fun row button -&gt;
    Tk.grid ~column ~row [button])) buttons;  (* Grid layout for buttons *)
  Wm.geometry_set top &quot;200x200&quot;;
  (* Connect Froc event to update the display *)
  F.notify_e calc_e
    (fun now -&gt;
      Label.configure ~text:(string_of_float now) result);
  Tk.mainLoop ()  (* Enter the GUI event loop *)</code></pre>
<h4 id="gtk-lablgtk">GTk+: LablGTk</h4>
<p><em>LablGTk</em> provides OCaml bindings for the <em>GTk+</em>
library (written in C). Unlike LablTk, it uses an object-oriented
interface: widgets are objects, and operations are method calls.</p>
<p>In OCaml’s object system, fields are only visible to the object’s own
methods, and methods are called with <code>#</code> syntax: e.g.,
<code>window#show ()</code>.</p>
<p>GTk+ has its own reactive event system (confusingly, GTk+ uses
“signal” where we say “event”):</p>
<ul>
<li>Registering a callback is called <em>connecting a signal
handler</em>: <code>button#connect#clicked ~callback:hello</code> takes
<code>~callback:(unit -&gt; unit)</code> and returns a
<code>GtkSignal.id</code></li>
<li>Multiple handlers can be attached to the same signal, just like
<em>Froc</em> notifications</li>
<li>GTk+ <em>events</em> (note: different from signals) relate to
window-system events:
<code>window#event#connect#delete ~callback:delete_event</code></li>
<li>Event callbacks receive more information:
<code>~callback:(event -&gt; unit)</code> for some event type</li>
</ul>
<p>GTk+ layout is simpler than Tk’s:</p>
<ul>
<li>Only horizontal (<code>hbox</code>) and vertical (<code>vbox</code>)
boxes are available</li>
<li>Grid layout is called <code>table</code>, with <code>~fill</code>
and <code>~expand</code> taking <code>`X</code>, <code>`Y</code>,
<code>`BOTH</code>, <code>`NONE</code></li>
</ul>
<p>A few API differences: <code>coerce</code> is a method that casts
widget types (Tk uses a <code>coe</code> function). Labels do not have a
dedicated module. Widget properties are set via
<code>widget#set_X</code> methods rather than a single
<code>configure</code> function.</p>
<p>Here is the GTk+ version of our calculator. First, setting up the
window and layout:</p>
<p><code>ocaml skip let _ = GtkMain.Main.init ()  (* Initialize GTk+ *) let window =   GWindow.window ~width:200 ~height:200 ~title:"Calculator" () let top = GPack.vbox ~packing:window#add ()  (* Vertical box container *) let result = GMisc.label ~text:"0" ~packing:top#add ()  (* Result display *) let btn_frame =   GPack.table ~rows:(Array.length layout)    ~columns:(Array.length layout.(0)) ~packing:top#add ()  (* Button grid *)</code></p>
<p>Creating the buttons and connecting their click handlers to
<em>Froc</em> events:</p>
<p><code>ocaml skip let buttons =   Array.map (Array.map (function     | label, `Dot -&gt;       let b = GButton.button ~label () in       let _ = b#connect#clicked         ~callback:(fun () -&gt; F.send dot ()) in b     | label, `Di d -&gt;       let b = GButton.button ~label () in       let _ = b#connect#clicked         ~callback:(fun () -&gt; F.send digit d) in b     | label, `O f -&gt;       let b = GButton.button ~label () in       let _ = b#connect#clicked         ~callback:(fun () -&gt; F.send op f) in b)) layout</code></p>
<p>Finally, we attach buttons to the grid, connect the result
notification, and start the application:</p>
<p>```ocaml skip let delete_event _ = GMain.Main.quit (); false (*
Handle window close *)</p>
<p>let () = let _ = window#event#connect#delete ~callback:delete_event
in Array.iteri (fun column -&gt; Array.iteri (fun row button -&gt;
btn_frame#attach ~left:column ~top:row
~fill:<code>BOTH ~expand:</code>BOTH (button#coerce)) (* Attach to grid
<em>) ) buttons; (</em> Connect Froc event to update the display <em>)
F.notify_e calc_e (fun now -&gt; result#set_label (string_of_float
now)); window#show (); (</em> Make window visible <em>) GMain.Main.main
() (</em> Enter the GTk+ event loop *)</p>
<pre><code>
### 10.9 Exercises

**Exercise 1:** Introduce operators $-, /$ into the context rewriting &quot;pull out subexpression&quot; example. Remember that they are not commutative.

**Exercise 2:** Add to the *paddle game* example:
1. game restart,
2. score keeping,
3. game quitting (in more-or-less elegant way).

**Exercise 3:** Our numerical integration function roughly corresponds to the rectangle rule. Modify the rule and write a test for the accuracy of:
1. the trapezoidal rule;
2. the Simpson&#39;s rule. See http://en.wikipedia.org/wiki/Simpson%27s_rule

**Exercise 4:** Explain the recursive behavior of integration:
1. In *paddle game* implemented by stream processing (`Lec10b.ml`), do we look at past velocity to determine current position, at past position to determine current velocity, both, or neither?
2. What is the difference between `integral` and `integral_nice` in `Lec10c.ml`, what happens when we replace the former with the latter in the `pbal` function? How about after rewriting `pbal` into pure style as in the following exercise?

**Exercise 5:** Reimplement the *Froc* based paddle ball example in a pure style: rewrite the `pbal` function to not use `notify_e`.

**Exercise 6:** Our implementation of flows is a bit heavy. One alternative approach is to use continuations, as in `Scala.React`. OCaml has a continuations library *Delimcc*; for how it can cooperate with *Froc*, see http://ambassadortothecomputers.blogspot.com/2010/08/mixing-monadic-and-direct-style-code.html

**Exercise 7:** Implement `parallel` for flows, retaining coarse-grained implementation and using the event queue from *Froc* somehow (instead of introducing a new job queue).

**Exercise 8:** Add quitting, e.g. via a `&#39;q&#39;` key press, to the *painter* example. Use the `is_cancelled` function.

**Exercise 9:** Our calculator example is not finished. Implement entering decimal fractions: add handling of the `dots` event.

**Exercise 10:** The Flow module has reader monad functions that have not been discussed in this chapter:
</code></pre>
<p>let local f m = fun emit -&gt; m (fun x -&gt; emit (f x)) let
local_opt f m = fun emit -&gt; m (fun x -&gt; match f x with None -&gt;
() | Some y -&gt; emit y)</p>
<p>val local : (’a -&gt; ’b) -&gt; (’a, ’c) flow -&gt; (’b, ’c) flow val
local_opt : (’a -&gt; ’b option) -&gt; (’a, ’c) flow -&gt; (’b, ’c)
flow</p>
<pre><code>
Implement an example that uses this compositionality-increasing capability.


## Chapter 11: The Expression Problem

This chapter explores **the expression problem**, a classic challenge in software engineering that addresses how to design systems that can be extended with both new data variants and new operations without modifying existing code, while maintaining static type safety. The expression problem lies at the heart of code organization, extensibility, and reuse, so understanding the various solutions helps us write more maintainable and flexible software.

We will examine multiple approaches in OCaml, ranging from algebraic data types through object-oriented programming to polymorphic variants with recursive modules. Each approach has different trade-offs in terms of type safety, code organization, and ease of use. The chapter concludes with a practical application: parser combinators with dynamic code loading, demonstrating how these techniques apply to real-world problems.

### 11.1 The Expression Problem: Definition

The **Expression Problem** concerns the design of an implementation for expressions where:

- **Datatype extensibility**: New variants of expressions can be added
- **Functional extensibility**: New operations on expressions can be added

By *extensibility* we mean three conditions:

1. **Code-level modularization**: The new datatype variants and new operations are in separate files
2. **Separate compilation**: The files can be compiled and distributed separately
3. **Static type safety**: We do not lose type checking help and guarantees

The name comes from a classic example: extending a language of expressions with new constructs. Consider two sub-languages:

- **Lambda calculus**: variables `Var`, $\lambda$-abstractions `Abs`, function applications `App`
- **Arithmetic**: variables `Var`, constants `Num`, addition `Add`, multiplication `Mult`

And operations we want to support:

- Evaluation `eval`
- Pretty-printing to strings `string_of`
- Free variables computation `free_vars`

The challenge is to combine these sub-languages and add new operations without breaking existing code or sacrificing type safety. This is a fundamental tension in programming language design: functional languages typically make it easy to add new operations (just write a new function with pattern matching), while object-oriented languages typically make it easy to add new data variants (just add a new subclass). Finding a solution that provides both kinds of extensibility simultaneously, with static type safety and separate compilation, is the essence of the expression problem.

#### References

- Ralf Lammel lectures on MSDN&#39;s Channel 9: [The Expression Problem](http://channel9.msdn.com/Shows/Going+Deep/C9-Lectures-Dr-Ralf-Laemmel-Advanced-Functional-Programming-The-Expression-Problem), [Haskell&#39;s Type Classes](http://channel9.msdn.com/Shows/Going+Deep/C9-Lectures-Dr-Ralf-Lmmel-Advanced-Functional-Programming-Type-Classes)
- The book *Developing Applications with Objective Caml*: [Comparison of Modules and Objects](http://caml.inria.fr/pub/docs/oreilly-book/html/book-ora153.html), [Extending Components](http://caml.inria.fr/pub/docs/oreilly-book/html/book-ora154.html)
- *Real World OCaml*: [Chapter 11: Objects](https://realworldocaml.org/v1/en/html/objects.html), [Chapter 12: Classes](https://realworldocaml.org/v1/en/html/classes.html)
- Jacques Garrigue&#39;s [Code reuse through polymorphic variants](http://www.math.nagoya-u.ac.jp/~garrigue/papers/variant-reuse.ps.gz), and [Recursive Modules for Programming](http://www.math.nagoya-u.ac.jp/~garrigue/papers/nakata-icfp2006.pdf) with Keiko Nakata
- [Extensible variant types](http://caml.inria.fr/pub/docs/manual-ocaml/extn.html#sec246)
- Graham Hutton&#39;s and Erik Meijer&#39;s [Monadic Parser Combinators](https://www.cs.nott.ac.uk/~gmh/monparsing.pdf)

### 11.2 Functional Programming Non-Solution: Ordinary Algebraic Datatypes

Pattern matching makes **functional extensibility** easy in functional programming. When we want to add a new operation, we simply write a new function that pattern-matches on the existing datatype. However, ensuring **datatype extensibility** is complicated when using standard variant types, because adding a new variant requires modifying the type definition and all functions that pattern-match on it.

For brevity, we place examples in a single file, but the component type and function definitions are not mutually recursive, so they can be put in separate modules for separate compilation.

**Non-solution penalty points:**

- Functions implemented for a broader language (e.g., `lexpr_t`) cannot be used with a value from a narrower language (e.g., `expr_t`). This breaks the intuition that a smaller language should be usable wherever a larger one is expected.
- Significant memory (and some time) overhead due to *tagging*: the work of the `wrap` and `unwrap` functions, adding tags such as `Lambda` and `Expr` to distinguish which sub-language an expression belongs to.
- Some code bloat due to tagging. For example, deep pattern matching needs to be manually unrolled and interspersed with calls to `unwrap`, making the code harder to read and maintain.

**Verdict:** Non-solution, but better than the extensible variant types-based approach and the direct OOP approach.

Here is the implementation. Note how we use type parameters and wrap/unwrap functions to achieve a form of extensibility:

```ocaml env=sol1
type var = string  (* Variables constitute a sub-language of its own *)
                   (* We treat this sub-language slightly differently --
                      no need for a dedicated variant *)

let eval_var wrap sub (s : var) =
  try List.assoc s sub with Not_found -&gt; wrap s

type &#39;a lambda =  (* Here we define the sub-language of lambda-expressions *)
  VarL of var | Abs of string * &#39;a | App of &#39;a * &#39;a

(* During evaluation, we need to freshen variables to avoid capture *)
(* (mistaking distinct variables with the same name) *)
let gensym = let n = ref 0 in fun () -&gt; incr n; &quot;_&quot; ^ string_of_int !n

let eval_lambda eval_rec wrap unwrap subst e =
  match unwrap e with  (* Alternatively, unwrapping could use an exception *)
  | Some (VarL v) -&gt; eval_var (fun v -&gt; wrap (VarL v)) subst v
  | Some (App (l1, l2)) -&gt;  (* but we use the option type as it is safer *)
    let l1&#39; = eval_rec subst l1  (* and more flexible in this context *)
    and l2&#39; = eval_rec subst l2 in  (* Recursive processing function returns expression *)
    (match unwrap l1&#39; with  (* of the completed language, we need *)
    | Some (Abs (s, body)) -&gt;  (* to unwrap it into the current sub-language *)
      eval_rec [s, l2&#39;] body  (* The recursive call is already wrapped *)
    | _ -&gt; wrap (App (l1&#39;, l2&#39;)))  (* Wrap into the completed language *)
  | Some (Abs (s, l1)) -&gt;
    let s&#39; = gensym () in  (* Rename variable to avoid capture (alpha-equivalence) *)
    wrap (Abs (s&#39;, eval_rec ((s, wrap (VarL s&#39;))::subst) l1))
  | None -&gt; e  (* Falling-through when not in the current sub-language *)

type lambda_t = Lambda_t of lambda_t lambda  (* Defining lambdas as the completed language *)

let rec eval1 subst =  (* and the corresponding eval function *)
  eval_lambda eval1
    (fun e -&gt; Lambda_t e) (fun (Lambda_t e) -&gt; Some e) subst</code></pre>
<p>Now we define the arithmetic sub-language:</p>
<p>```ocaml env=sol1 type ’a expr = (* The sub-language of arithmetic
expressions <em>) VarE of var | Num of int | Add of ’a </em> ’a | Mult
of ’a * ’a</p>
<p>let eval_expr eval_rec wrap unwrap subst e = match unwrap e with |
Some (Num <em>) -&gt; e | Some (VarE v) -&gt; eval_var (fun x -&gt; wrap
(VarE x)) subst v | Some (Add (m, n)) -&gt; let m’ = eval_rec subst m
and n’ = eval_rec subst n in (match unwrap m’, unwrap n’ with (*
Unwrapping to check if the subexpressions <em>) | Some (Num m’), Some
(Num n’) -&gt; (</em> got computed to values <em>) wrap (Num (m’ + n’))
| _ -&gt; wrap (Add (m’, n’))) (</em> Here m’ and n’ are wrapped <em>) |
Some (Mult (m, n)) -&gt; let m’ = eval_rec subst m and n’ = eval_rec
subst n in (match unwrap m’, unwrap n’ with | Some (Num m’), Some (Num
n’) -&gt; wrap (Num (m’ </em> n’)) | </em> -&gt; wrap (Mult (m’, n’))) |
None -&gt; e</p>
<p>type expr_t = Expr_t of expr_t expr (* Defining arithmetic as the
completed language *)</p>
<p>let rec eval2 subst = (* aka “tying the recursive knot” *) eval_expr
eval2 (fun e -&gt; Expr_t e) (fun (Expr_t e) -&gt; Some e) subst</p>
<pre><code>
Finally, we merge the two sub-languages. The key insight is that we can compose evaluators by using the &quot;fall-through&quot; property: when one evaluator does not recognize an expression (returning it unchanged via the `None` case), we pass it to the next evaluator:

```ocaml env=sol1
type &#39;a lexpr =  (* The language merging lambda-expressions and arithmetic expressions *)
  Lambda of &#39;a lambda | Expr of &#39;a expr  (* can also be used in further extensions *)

let eval_lexpr eval_rec wrap unwrap subst e =
  eval_lambda eval_rec
    (fun e -&gt; wrap (Lambda e))
    (fun e -&gt;
      match unwrap e with
      | Some (Lambda e) -&gt; Some e
      | _ -&gt; None)
    subst
    (eval_expr eval_rec  (* We use the &quot;fall-through&quot; property of eval_expr *)
       (fun e -&gt; wrap (Expr e))  (* to combine the evaluators *)
       (fun e -&gt;
         match unwrap e with
         | Some (Expr e) -&gt; Some e
         | _ -&gt; None)
       subst e)

type lexpr_t = LExpr_t of lexpr_t lexpr  (* Tying the recursive knot one last time *)

let rec eval3 subst =
  eval_lexpr eval3
    (fun e -&gt; LExpr_t e)
    (fun (LExpr_t e) -&gt; Some e) subst</code></pre>
<h3 id="lightweight-fp-non-solution-extensible-variant-types">11.3
Lightweight FP Non-Solution: Extensible Variant Types</h3>
<p>Exceptions have always formed an extensible variant type in OCaml,
whose pattern matching is done using the <code>try...with</code> syntax.
Since recently, new extensible variant types can be defined using the
<code>type t = ..</code> syntax. This augments the normal function
extensibility of FP with straightforward data extensibility, providing a
seemingly elegant solution.</p>
<p>The syntax is simple: <code>type expr = ..</code> declares an
extensible type, and <code>type expr += Var of string</code> adds a new
variant case to it. This mirrors how exceptions work in OCaml, but for
arbitrary types.</p>
<p><strong>Non-solution penalty points:</strong></p>
<ul>
<li><strong>Giving up exhaustivity checking</strong>, which is an
important aspect of static type safety. The compiler cannot warn you
when you forget to handle a case, because new cases can be added at any
time.</li>
<li>More natural with “single inheritance” extension chains, although
merging is possible and demonstrated in our example. The sub-languages
are not differentiated by types, which is a significant
shortcoming.</li>
<li>Requires “tying the recursive knot” for functions, similar to the
previous approach.</li>
</ul>
<p><strong>Verdict:</strong> Pleasant-looking, but arguably the worst
approach because of possible bugginess. The loss of exhaustivity
checking means that bugs from unhandled cases will only be discovered at
runtime. However, if bug-proneness is not a concern (e.g., for rapid
prototyping), this is actually the most concise approach.</p>
<p>```ocaml env=sol2 type expr = .. (* This is how extensible variant
types are defined *)</p>
<p>type var_name = string type expr += Var of string (* We add a variant
case *)</p>
<p>let eval_var sub = function | Var s as v -&gt; (try List.assoc s sub
with Not_found -&gt; v) | e -&gt; e</p>
<p>let gensym = let n = ref 0 in fun () -&gt; incr n; “_” ^
string_of_int !n</p>
<p>type expr += Abs of string * expr | App of expr * expr (* The
sub-languages are not differentiated by types, a shortcoming of this
non-solution *)</p>
<p>let eval_lambda eval_rec subst = function | Var _ as v -&gt; eval_var
subst v | App (l1, l2) -&gt; let l2’ = eval_rec subst l2 in (match
eval_rec subst l1 with | Abs (s, body) -&gt; eval_rec [s, l2’] body |
l1’ -&gt; App (l1’, l2’)) | Abs (s, l1) -&gt; let s’ = gensym () in Abs
(s’, eval_rec ((s, Var s’)::subst) l1) | e -&gt; e</p>
<p>let freevars_lambda freevars_rec = function | Var v -&gt; [v] | App
(l1, l2) -&gt; freevars_rec l1 @ freevars_rec l2 | Abs (s, l1) -&gt;
List.filter (fun v -&gt; v &lt;&gt; s) (freevars_rec l1) | _ -&gt;
[]</p>
<p>let rec eval1 subst e = eval_lambda eval1 subst e let rec freevars1 e
= freevars_lambda freevars1 e</p>
<p>let test1 = App (Abs (“x”, Var “x”), Var “y”) let e_test = eval1 []
test1 let fv_test = freevars1 test1</p>
<pre><code>
Now we extend with arithmetic:

```ocaml env=sol2
type expr += Num of int | Add of expr * expr | Mult of expr * expr

let map_expr f = function
  | Add (e1, e2) -&gt; Add (f e1, f e2)
  | Mult (e1, e2) -&gt; Mult (f e1, f e2)
  | e -&gt; e

let eval_expr eval_rec subst e =
  match map_expr (eval_rec subst) e with
  | Add (Num m, Num n) -&gt; Num (m + n)
  | Mult (Num m, Num n) -&gt; Num (m * n)
  | (Num _ | Add _ | Mult _) as e -&gt; e
  | e -&gt; e

let freevars_expr freevars_rec = function
  | Num _ -&gt; []
  | Add (e1, e2) | Mult (e1, e2) -&gt; freevars_rec e1 @ freevars_rec e2
  | _ -&gt; []

let rec eval2 subst e = eval_expr eval2 subst e
let rec freevars2 e = freevars_expr freevars2 e

let test2 = Add (Mult (Num 3, Var &quot;x&quot;), Num 1)
let e_test2 = eval2 [] test2
let fv_test2 = freevars2 test2</code></pre>
<p>Merging the sub-languages:</p>
<p>```ocaml env=sol2 let eval_lexpr eval_rec subst e = eval_expr
eval_rec subst (eval_lambda eval_rec subst e)</p>
<p>let freevars_lexpr freevars_rec e = freevars_lambda freevars_rec e @
freevars_expr freevars_rec e</p>
<p>let rec eval3 subst e = eval_lexpr eval3 subst e let rec freevars3 e
= freevars_lexpr freevars3 e</p>
<p>let test3 = App (Abs (“x”, Add (Mult (Num 3, Var “x”), Num 1)), Num
2) let e_test3 = eval3 [] test3 let fv_test3 = freevars3 test3</p>
<pre><code>
### 11.4 Object-Oriented Programming: Subtyping

Before examining OOP solutions to the expression problem, let us understand OCaml&#39;s object system.

OCaml&#39;s **objects** are values, somewhat similar to records. Viewed from the outside, an OCaml object has only **methods**, identifying the code with which to respond to messages (method invocations). All methods are **late-bound**; the object determines what code is run (i.e., *virtual* in C++ parlance). This is in contrast to records, where field access is resolved at compile time.

**Subtyping** determines if an object can be used in some context. OCaml has **structural subtyping**: the content of the types concerned (the methods they provide) decides if an object can be used, not the name of the type or class. Parametric polymorphism can be used to infer if an object has the required methods.

```ocaml env=oop_intro
let f x = x#m  (* Method invocation: object#method *)
(* val f : &lt; m : &#39;a; .. &gt; -&gt; &#39;a *)
(* Type polymorphic in two ways: &#39;a is the method type, *)
(* .. means that objects with more methods will be accepted *)</code></pre>
<p>Methods are computed when they are invoked, even if they do not take
arguments (unlike record fields, which are computed once when the record
is created). We define objects inside <code>object...end</code>
(compare: records <code>{...}</code>) using keywords:</p>
<ul>
<li><code>method</code> for methods (always late-bound)</li>
<li><code>val</code> for constant fields (only accessible within the
object)</li>
<li><code>val mutable</code> for mutable fields</li>
</ul>
<p>Constructor arguments can often be used instead of constant fields.
Here is a simple example:</p>
<p><code>ocaml env=oop_intro let square w = object   method area = float_of_int (w * w)   method width = w end</code></p>
<p>Subtyping often needs to be explicit: we write
<code>(object :&gt; supertype)</code> or in more complex cases
<code>(object : type :&gt; supertype)</code>.</p>
<p>Technically speaking, subtyping in OCaml always is explicit, and
<em>open types</em>, containing <code>..</code>, use <strong>row
polymorphism</strong> rather than subtyping.</p>
<p>```ocaml env=oop_intro let a = object method m = 7 method x = “a” end
(* Toy example: object types <em>) let b = object method m = 42 method y
= “b” end (</em> share some but not all methods *)</p>
<p>(* let l = [a; b] – Error: the exact types of the objects do not
agree <em>) (</em> Error: This expression has type &lt; m : int; y :
string &gt; but an expression was expected of type &lt; m : int; x :
string &gt; The second object type has no method y *)</p>
<p>let l = [(a :&gt; &lt;m : ’a&gt;); (b :&gt; &lt;m : ’a&gt;)] (* But
the types share a supertype <em>) (</em> val l : &lt; m : int &gt; list
*)</p>
<pre><code>
#### Object-Oriented Programming: Inheritance

The system of object classes in OCaml is similar to the module system. Object classes are not types; rather, classes are a way to build object *constructors*, which are functions that return objects. Classes have their types, called class types (compare: modules and signatures).

In OCaml parlance:

- **Late binding** is not called anything special, since all methods are late-bound (called *virtual* in C++)
- A method or field declared to be defined in sub-classes is called **virtual** (called *abstract* in C++); classes that use virtual methods or fields are also called virtual
- A method that is only visible in sub-classes is called **private** (called *protected* in C++)
- A method not visible outside the class is achieved by omitting it from the class type (called *private* in C++) -- you provide the type for the class and omit the method in the class type, similar to module signatures and `.mli` files

OCaml allows **multiple inheritance**, which can be used to implement *mixins* as virtual/abstract classes. Inheritance works somewhat similarly to textual inclusion: the inherited class&#39;s methods and fields are copied into the inheriting class, but with late binding preserved.

The `{&lt; ... &gt;}` syntax creates a *clone* of the current object with some fields changed. This is essential for functional-style object programming, where we create new objects rather than mutating existing ones.

### 11.5 Direct Object-Oriented Non-Solution

It turns out that although object-oriented programming was designed with data extensibility in mind, it is a bad fit for recursive types like those in the expression problem. Below is an attempt at solving our problem using classes.

We can try to solve the expression problem using objects directly. However, adding new functionality still requires modifying old code, so this approach does not fully solve the expression problem.

**Non-solution penalty points:**

- No way to add functionality without modifying old code (in particular, the abstract class and all concrete classes must be extended with new methods)
- Functions implemented for a broader language cannot handle values from a narrower one
- No deep pattern matching: we cannot examine the structure of nested expressions

**Verdict:** Non-solution, and probably the worst approach.

Here is an implementation using objects. The abstract class `evaluable` defines the interface that all expression objects must implement. For lambda calculus, we need helper methods: `rename` for renaming free variables (needed for alpha-conversion), and `apply` for beta-reduction when possible:

```ocaml env=sol3
type var_name = string

let gensym = let n = ref 0 in fun () -&gt; incr n; &quot;_&quot; ^ string_of_int !n

class virtual [&#39;lang] evaluable =
object
  method virtual eval : (var_name * &#39;lang) list -&gt; &#39;lang
  method virtual rename : var_name -&gt; var_name -&gt; &#39;lang
  method apply (_arg : &#39;lang)
    (fallback : unit -&gt; &#39;lang) (_subst : (var_name * &#39;lang) list) =
    fallback ()
end

class [&#39;lang] var (v : var_name) =
object (self)  (* We name the current object `self` for later reference *)
  inherit [&#39;lang] evaluable
  val v = v
  method eval subst =
    try List.assoc v subst with Not_found -&gt; self
  method rename v1 v2 =  (* Renaming a variable: *)
    if v = v1 then {&lt; v = v2 &gt;} else self  (* clone with new name if matched *)
end

class [&#39;lang] abs (v : var_name) (body : &#39;lang) =
object (self)
  inherit [&#39;lang] evaluable
  val v = v
  val body = body
  method eval subst =  (* We do alpha-conversion prior to evaluation *)
    let v&#39; = gensym () in  (* Generate fresh name to avoid capture *)
    {&lt; v = v&#39;; body = (body#rename v v&#39;)#eval subst &gt;}
  method rename v1 v2 =  (* Renaming the free variable v1 *)
    if v = v1 then self  (* If v=v1, then v1 is bound here, not free -- no work *)
    else {&lt; body = body#rename v1 v2 &gt;}
  method apply arg _ subst =  (* Beta-reduction: substitute arg for v in body *)
    body#eval ((v, arg)::subst)
end

class [&#39;lang] app (f : &#39;lang) (arg : &#39;lang) =
object (self)
  inherit [&#39;lang] evaluable
  val f = f
  val arg = arg
  method eval subst =  (* We use `apply` to differentiate between f=abs *)
    let arg&#39; = arg#eval subst in  (* (beta-redexes) and f&lt;&gt;abs *)
    f#apply arg&#39; (fun () -&gt; {&lt; f = f#eval subst; arg = arg&#39; &gt;}) subst
  method rename v1 v2 =  (* Cloning ensures result is subtype of &#39;lang *)
    {&lt; f = f#rename v1 v2; arg = arg#rename v1 v2 &gt;}  (* not just &#39;lang app *)
end

type evaluable_t = evaluable_t evaluable
let new_var1 v : evaluable_t = new var v
let new_abs1 v (body : evaluable_t) : evaluable_t = new abs v body
let new_app1 (arg1 : evaluable_t) (arg2 : evaluable_t) : evaluable_t =
  new app arg1 arg2

let test1 = new_app1 (new_abs1 &quot;x&quot; (new_var1 &quot;x&quot;)) (new_var1 &quot;y&quot;)
let e_test1 = test1#eval []</code></pre>
<p>Extending with arithmetic requires additional mixins. To use
lambda-expressions together with arithmetic expressions, we need to
upgrade them with a helper method <code>compute</code> that returns the
numeric value if one exists:</p>
<p>```ocaml env=sol3 class virtual compute_mixin = object method compute
: int option = None end</p>
<p>class [’lang] var_c v = object inherit [’lang] var v inherit
compute_mixin end</p>
<p>class [’lang] abs_c v body = object inherit [’lang] abs v body
inherit compute_mixin end</p>
<p>class [’lang] app_c f arg = object inherit [’lang] app f arg inherit
compute_mixin end</p>
<p>class [’lang] num (i : int) = object (self) inherit [’lang] evaluable
val i = i method eval <em>subst = self method rename </em> _ = self
method compute = Some i end</p>
<p>class virtual [’lang] operation (num_inst : int -&gt; ‘lang) (n1 :
’lang) (n2 : ’lang) = object (self) inherit [’lang] evaluable val n1 =
n1 val n2 = n2 method eval subst = let self’ = {&lt; n1 = n1#eval subst;
n2 = n2#eval subst &gt;} in match self’#compute with | Some i -&gt;
num_inst i | _ -&gt; self’ method rename v1 v2 = {&lt; n1 = n1#rename v1
v2; n2 = n2#rename v1 v2 &gt;} end</p>
<p>class [’lang] add num_inst n1 n2 = object (self) inherit [’lang]
operation num_inst n1 n2 method compute = match n1#compute, n2#compute
with | Some i1, Some i2 -&gt; Some (i1 + i2) | _ -&gt; None end</p>
<p>class [’lang] mult num_inst n1 n2 = object (self) inherit [’lang]
operation num_inst n1 n2 method compute = match n1#compute, n2#compute
with | Some i1, Some i2 -&gt; Some (i1 * i2) | _ -&gt; None end</p>
<p>class virtual [’lang] computable = object inherit [’lang] evaluable
inherit compute_mixin end</p>
<p>type computable_t = computable_t computable let new_var2 v :
computable_t = new var_c v let new_abs2 v (body : computable_t) :
computable_t = new abs_c v body let new_app2 v (body : computable_t) :
computable_t = new app_c v body let new_num2 i : computable_t = new num
i let new_add2 (n1 : computable_t) (n2 : computable_t) : computable_t =
new add new_num2 n1 n2 let new_mult2 (n1 : computable_t) (n2 :
computable_t) : computable_t = new mult new_num2 n1 n2</p>
<p>let test2 = new_app2 (new_abs2 “x” (new_add2 (new_mult2 (new_num2 3)
(new_var2 “x”)) (new_num2 1))) (new_num2 2) let e_test2 = test2#eval
[]</p>
<pre><code>
### 11.6 OOP Non-Solution: The Visitor Pattern

The **visitor pattern** is an object-oriented programming pattern for turning objects into variants with shallow pattern-matching (i.e., dispatch based on which variant a value is). It effectively replaces data extensibility with operation extensibility: instead of being able to add new data variants easily, we can add new operations easily.

The key idea is that each data variant has an `accept` method that takes a visitor object and calls the appropriate `visit` method on it. This inverts the usual pattern matching: instead of the function choosing which branch to take based on the data, the data chooses which method to call on the visitor.

**Non-solution penalty points:**

- Adding new functionality requires modifying old code (the abstract visitor class must declare new `visit` methods)
- Heavy code bloat compared to pattern matching
- No deep pattern matching: we can only dispatch on the outermost constructor
- Side-effects appear to be required for returning results (we store computation results in mutable fields because keeping the visitor polymorphic while having the result type depend on the visitor is difficult)

**Verdict:** Poor solution, better than approaches we considered so far, and worse than approaches we consider next.

```ocaml env=sol4
type &#39;visitor visitable = &lt; accept : &#39;visitor -&gt; unit &gt;
(* The variants need be visitable *)
(* We store the computation as side effect because of the difficulty *)
(* to keep the visitor polymorphic but have the result type depend on the visitor *)

type var_name = string

class [&#39;visitor] var (v : var_name) =
object (self)  (* The &#39;visitor will determine the (sub)language *)
               (* to which a given var variant belongs *)
  method v = v
  method accept : &#39;visitor -&gt; unit =  (* The visitor pattern inverts the way *)
    fun visitor -&gt; visitor#visitVar self  (* pattern matching proceeds: the variant *)
end  (* selects the computation *)
let new_var v = (new var v :&gt; &#39;a visitable)

class [&#39;visitor] abs (v : var_name) (body : &#39;visitor visitable) =
object (self)
  method v = v
  method body = body
  method accept : &#39;visitor -&gt; unit =
    fun visitor -&gt; visitor#visitAbs self
end
let new_abs v body = (new abs v body :&gt; &#39;a visitable)

class [&#39;visitor] app (f : &#39;visitor visitable) (arg : &#39;visitor visitable) =
object (self)
  method f = f
  method arg = arg
  method accept : &#39;visitor -&gt; unit =
    fun visitor -&gt; visitor#visitApp self
end
let new_app f arg = (new app f arg :&gt; &#39;a visitable)

class virtual [&#39;visitor] lambda_visit =
object
  method virtual visitVar : &#39;visitor var -&gt; unit
  method virtual visitAbs : &#39;visitor abs -&gt; unit
  method virtual visitApp : &#39;visitor app -&gt; unit
end

let gensym = let n = ref 0 in fun () -&gt; incr n; &quot;_&quot; ^ string_of_int !n

class [&#39;visitor] eval_lambda
  (subst : (var_name * &#39;visitor visitable) list)
  (result : &#39;visitor visitable ref) =
object (self)
  inherit [&#39;visitor] lambda_visit
  val mutable subst = subst
  val mutable beta_redex : (var_name * &#39;visitor visitable) option = None
  method visitVar var =
    beta_redex &lt;- None;
    try result := List.assoc var#v subst
    with Not_found -&gt; result := (var :&gt; &#39;visitor visitable)
  method visitAbs abs =
    let v&#39; = gensym () in
    let orig_subst = subst in
    subst &lt;- (abs#v, new_var v&#39;)::subst;
    (abs#body)#accept self;
    let body&#39; = !result in
    subst &lt;- orig_subst;
    beta_redex &lt;- Some (v&#39;, body&#39;);
    result := new_abs v&#39; body&#39;
  method visitApp app =
    app#arg#accept self;
    let arg&#39; = !result in
    app#f#accept self;
    let f&#39; = !result in
    match beta_redex with
    | Some (v&#39;, body&#39;) -&gt;
      beta_redex &lt;- None;
      let orig_subst = subst in
      subst &lt;- (v&#39;, arg&#39;)::subst;
      body&#39;#accept self;
      subst &lt;- orig_subst
    | None -&gt; result := new_app f&#39; arg&#39;
end

class [&#39;visitor] freevars_lambda (result : var_name list ref) =
object (self)
  inherit [&#39;visitor] lambda_visit
  method visitVar var =
    result := var#v :: !result
  method visitAbs abs =
    (abs#body)#accept self;
    result := List.filter (fun v&#39; -&gt; v&#39; &lt;&gt; abs#v) !result
  method visitApp app =
    app#arg#accept self; app#f#accept self
end

type lambda_visit_t = lambda_visit_t lambda_visit
type lambda_t = lambda_visit_t visitable

let eval1 (e : lambda_t) subst : lambda_t =
  let result = ref (new_var &quot;&quot;) in
  e#accept (new eval_lambda subst result :&gt; lambda_visit_t);
  !result

let freevars1 (e : lambda_t) =
  let result = ref [] in
  e#accept (new freevars_lambda result);
  !result

let test1 =
  (new_app (new_abs &quot;x&quot; (new_var &quot;x&quot;)) (new_var &quot;y&quot;) :&gt; lambda_t)
let e_test = eval1 test1 []
let fv_test = freevars1 test1</code></pre>
<p>Extending with arithmetic expressions follows a similar pattern, and
the merged language visitor inherits from both <code>lambda_visit</code>
and <code>expr_visit</code>.</p>
<h3 id="polymorphic-variants">11.7 Polymorphic Variants</h3>
<p><strong>Polymorphic variants</strong> provide a flexible alternative
to standard variants. They are to ordinary variants as objects are to
records: both enable <em>open types</em> and subtyping, both allow
different types to share the same components.</p>
<p>Interestingly, they are <em>dual</em> concepts: if we replace
“product” of records/objects by “sum” (as we discussed in earlier
chapters), we get variants/polymorphic variants. This duality implies
many behaviors are opposite. For example:</p>
<ul>
<li>While object subtypes have <em>more</em> methods, polymorphic
variant subtypes have <em>fewer</em> tags</li>
<li>The <code>&gt;</code> sign means “these tags or more” (open for
adding tags)</li>
<li>The <code>&lt;</code> sign means “these tags or less” (closed to
these tags only)</li>
<li>No sign means a closed type</li>
</ul>
<p>Because distinct polymorphic variant types can share the same tags,
the solution to the Expression Problem becomes straightforward: we can
define sub-languages with overlapping tags and compose them.</p>
<p><strong>Penalty points:</strong></p>
<ul>
<li>Requires explicit type annotations more often than regular
variants</li>
<li>Requires “tying the recursive knots” for types, e.g.,
<code>type lambda_t = lambda_t lambda</code></li>
<li>The need to tie the recursive knot separately at both the type level
and the function level. At the function level, an eta-expansion is
sometimes required due to the <em>value recursion</em> problem</li>
<li>There can be a slight time cost compared to the visitor pattern:
additional dispatch at each level of type aggregation (i.e., merging
sub-languages)</li>
</ul>
<p><strong>Verdict:</strong> A flexible and concise solution,
second-best place overall.</p>
<p>``<code>ocaml env=sol5 type var = [</code>Var of string]</p>
<p>let eval_var sub (`Var s as v : var) = try List.assoc s sub with
Not_found -&gt; v</p>
<p>type ’a lambda = [<code>Var of string |</code>Abs of string * ’a |
`App of ’a * ’a]</p>
<p>let gensym = let n = ref 0 in fun () -&gt; incr n; “_” ^
string_of_int !n</p>
<p>let eval_lambda eval_rec subst : ’a lambda -&gt; ’a = function | #var
as v -&gt; eval_var subst v (* We could also leave the type open *) |
<code>App (l1, l2) -&gt;               (* rather than closing it to</code>lambda<code>*)     let l2' = eval_rec subst l2 in     (match eval_rec subst l1 with     |</code>Abs
(s, body) -&gt; eval_rec [s, l2’] body | l1’ -&gt;
<code>App (l1', l2'))   |</code>Abs (s, l1) -&gt; let s’ = gensym () in
<code>Abs (s', eval_rec ((s,</code>Var s’)::subst) l1)</p>
<p>let freevars_lambda freevars_rec : ’a lambda -&gt; ’b = function |
<code>Var v -&gt; [v]   |</code>App (l1, l2) -&gt; freevars_rec l1 @
freevars_rec l2 | `Abs (s, l1) -&gt; List.filter (fun v -&gt; v &lt;&gt;
s) (freevars_rec l1)</p>
<p>type lambda_t = lambda_t lambda</p>
<p>let rec eval1 subst e : lambda_t = eval_lambda eval1 subst e let rec
freevars1 (e : lambda_t) = freevars_lambda freevars1 e</p>
<p>let test1 = (<code>App (</code>Abs (“x”, <code>Var "x"),</code>Var
“y”) :&gt; lambda_t) let e_test = eval1 [] test1 let fv_test = freevars1
test1</p>
<pre><code>
The arithmetic expression sub-language:

```ocaml env=sol5
type &#39;a expr =
  [`Var of string | `Num of int | `Add of &#39;a * &#39;a | `Mult of &#39;a * &#39;a]

let map_expr (f : _ -&gt; &#39;a) : &#39;a expr -&gt; &#39;a = function
  | #var as v -&gt; v
  | `Num _ as n -&gt; n
  | `Add (e1, e2) -&gt; `Add (f e1, f e2)
  | `Mult (e1, e2) -&gt; `Mult (f e1, f e2)

let eval_expr eval_rec subst (e : &#39;a expr) : &#39;a =
  match map_expr (eval_rec subst) e with
  | #var as v -&gt; eval_var subst v  (* Here and elsewhere, we could also *)
  | `Add (`Num m, `Num n) -&gt; `Num (m + n)  (* factor-out the sub-language *)
  | `Mult (`Num m, `Num n) -&gt; `Num (m * n)  (* of variables *)
  | e -&gt; e

let freevars_expr freevars_rec : &#39;a expr -&gt; &#39;b = function
  | `Var v -&gt; [v]
  | `Num _ -&gt; []
  | `Add (e1, e2) | `Mult (e1, e2) -&gt; freevars_rec e1 @ freevars_rec e2

type expr_t = expr_t expr

let rec eval2 subst e : expr_t = eval_expr eval2 subst e
let rec freevars2 (e : expr_t) = freevars_expr freevars2 e

let test2 = (`Add (`Mult (`Num 3, `Var &quot;x&quot;), `Num 1) : expr_t)
let e_test2 = eval2 [&quot;x&quot;, `Num 2] test2
let fv_test2 = freevars2 test2</code></pre>
<p>Merging the sub-languages:</p>
<p>```ocaml env=sol5 type ’a lexpr = [’a lambda | ’a expr]</p>
<p>let eval_lexpr eval_rec subst : ’a lexpr -&gt; ’a = function |
#lambda as x -&gt; eval_lambda eval_rec subst x | #expr as x -&gt;
eval_expr eval_rec subst x</p>
<p>let freevars_lexpr freevars_rec : ’a lexpr -&gt; ’b = function |
#lambda as x -&gt; freevars_lambda freevars_rec x | #expr as x -&gt;
freevars_expr freevars_rec x</p>
<p>type lexpr_t = lexpr_t lexpr</p>
<p>let rec eval3 subst e : lexpr_t = eval_lexpr eval3 subst e let rec
freevars3 (e : lexpr_t) = freevars_lexpr freevars3 e</p>
<p>let test3 = (<code>App (</code>Abs (“x”, <code>Add (</code>Mult
(<code>Num 3,</code>Var “x”), <code>Num 1)),</code>Num 2) : lexpr_t) let
e_test3 = eval3 [] test3 let fv_test3 = freevars3 test3 let e_old_test =
eval3 [] (test2 :&gt; lexpr_t) let fv_old_test = freevars3 (test2 :&gt;
lexpr_t)</p>
<pre><code>
### 11.8 Polymorphic Variants with Recursive Modules

Using recursive modules, we can clean up the confusing or cluttering aspects of tying the recursive knots: type variables and recursive call arguments. The module system handles the recursion for us, making the code cleaner and more modular.

We need **private types**, which for objects and polymorphic variants means *private rows*. We can conceive of open row types, e.g., `[&gt; \`Int of int | \`String of string]` as using a *row variable*, e.g., `&#39;a`:
</code></pre>
<p>[<code>Int of int |</code>String of string | ’a]</p>
<pre><code>
and then of private row types as abstracting the row variable:
</code></pre>
<p>type ’row t = [<code>Int of int |</code>String of string | ’row]</p>
<pre><code>
But the actual formalization of private row types is more complex. The key point is that private row types allow us to specify that a type is &quot;at least&quot; a certain set of variants, while still being extensible.

**Penalty points:**

- We still need to tie the recursive knots for types, for example `private [&gt; &#39;a lambda] as &#39;a`
- There can be slight time costs due to the use of functors and dispatch on merging of sub-languages

**Verdict:** A clean solution, best place. The recursive module approach is the most elegant solution we have seen so far.

```ocaml env=sol6
type var = [`Var of string]

let eval_var subst (`Var s as v : var) =
  try List.assoc s subst with Not_found -&gt; v

type &#39;a lambda =
  [`Var of string | `Abs of string * &#39;a | `App of &#39;a * &#39;a]

module type Eval =
sig type exp val eval : (string * exp) list -&gt; exp -&gt; exp end

module LF(X : Eval with type exp = private [&gt; &#39;a lambda] as &#39;a) =
struct
  type exp = X.exp lambda

  let gensym = let n = ref 0 in fun () -&gt; incr n; &quot;_&quot; ^ string_of_int !n

  let eval subst : exp -&gt; X.exp = function
    | #var as v -&gt; eval_var subst v
    | `App (l1, l2) -&gt;
      let l2&#39; = X.eval subst l2 in
      (match X.eval subst l1 with
      | `Abs (s, body) -&gt;
        X.eval [s, l2&#39;] body
      | l1&#39; -&gt; `App (l1&#39;, l2&#39;))
    | `Abs (s, l1) -&gt;
      let s&#39; = gensym () in
      `Abs (s&#39;, X.eval ((s, `Var s&#39;)::subst) l1)
end
module rec Lambda : (Eval with type exp = Lambda.exp lambda) =
  LF(Lambda)

module type FreeVars =
sig type exp val freevars : exp -&gt; string list end

module LFVF(X : FreeVars with type exp = private [&gt; &#39;a lambda] as &#39;a) =
struct
  type exp = X.exp lambda

  let freevars : exp -&gt; &#39;b = function
    | `Var v -&gt; [v]
    | `App (l1, l2) -&gt; X.freevars l1 @ X.freevars l2
    | `Abs (s, l1) -&gt;
      List.filter (fun v -&gt; v &lt;&gt; s) (X.freevars l1)
end
module rec LambdaFV : (FreeVars with type exp = LambdaFV.exp lambda) =
  LFVF(LambdaFV)

let test1 = (`App (`Abs (&quot;x&quot;, `Var &quot;x&quot;), `Var &quot;y&quot;) : Lambda.exp)
let e_test = Lambda.eval [] test1
let fv_test = LambdaFV.freevars test1</code></pre>
<p>The arithmetic expression sub-language:</p>
<p>``<code>ocaml env=sol6 type 'a expr =   [</code>Var of string |
<code>Num of int |</code>Add of ’a * ’a | `Mult of ’a * ’a]</p>
<p>module type Operations = sig include Eval include FreeVars with type
exp := exp end</p>
<p>module EF(X : Operations with type exp = private [&gt; ’a expr] as
’a) = struct type exp = X.exp expr</p>
<p>let map_expr f = function | #var as v -&gt; v |
<code>Num _ as n -&gt; n     |</code>Add (e1, e2) -&gt;
<code>Add (f e1, f e2)     |</code>Mult (e1, e2) -&gt; `Mult (f e1, f
e2)</p>
<p>let eval subst (e : exp) : X.exp = match map_expr (X.eval subst) e
with | #var as v -&gt; eval_var subst v | <code>Add (</code>Num m,
<code>Num n) -&gt;</code>Num (m + n) | <code>Mult (</code>Num m,
<code>Num n) -&gt;</code>Num (m * n) | e -&gt; e</p>
<p>let freevars : exp -&gt; ’b = function |
<code>Var v -&gt; [v]     |</code>Num _ -&gt; [] |
<code>Add (e1, e2) |</code>Mult (e1, e2) -&gt; X.freevars e1 @
X.freevars e2 end module rec Expr : (Operations with type exp = Expr.exp
expr) = EF(Expr)</p>
<p>let test2 = (<code>Add (</code>Mult (<code>Num 3,</code>Var “x”),
<code>Num 1) : Expr.exp) let e_test2 = Expr.eval ["x",</code>Num 2]
test2 let fvs_test2 = Expr.freevars test2</p>
<pre><code>
Merging the sub-languages:

```ocaml env=sol6
type &#39;a lexpr = [&#39;a lambda | &#39;a expr]

module LEF(X : Operations with type exp = private [&gt; &#39;a lexpr] as &#39;a) =
struct
  type exp = X.exp lexpr
  module LambdaX = LF(X)
  module LambdaFVX = LFVF(X)
  module ExprX = EF(X)

  let eval subst : exp -&gt; X.exp = function
    | #LambdaX.exp as x -&gt; LambdaX.eval subst x
    | #ExprX.exp as x -&gt; ExprX.eval subst x

  let freevars : exp -&gt; &#39;b = function
    | #lambda as x -&gt; LambdaFVX.freevars x  (* Either of #lambda or #LambdaX.exp is fine *)
    | #expr as x -&gt; ExprX.freevars x  (* Either of #expr or #ExprX.exp is fine *)
end
module rec LExpr : (Operations with type exp = LExpr.exp lexpr) =
  LEF(LExpr)

let test3 =
  (`App (`Abs (&quot;x&quot;, `Add (`Mult (`Num 3, `Var &quot;x&quot;), `Num 1)),
         `Num 2) : LExpr.exp)
let e_test3 = LExpr.eval [] test3
let fv_test3 = LExpr.freevars test3
let e_old_test = LExpr.eval [] (test2 :&gt; LExpr.exp)
let fv_old_test = LExpr.freevars (test2 :&gt; LExpr.exp)</code></pre>
<h3 id="parser-combinators">11.9 Parser Combinators</h3>
<p>We now turn to an application that demonstrates the extensibility
concepts we have been discussing. Large-scale parsing in OCaml is
typically done using external languages like OCamlLex and Menhir, which
generate efficient parsers from grammar specifications. But it is often
convenient to have parsers written directly in OCaml, especially for
smaller grammars or when we want to extend the parser dynamically.</p>
<p>Language <strong>combinators</strong> are ways of defining languages
by composing definitions of smaller languages. This is exactly the kind
of compositional, extensible design we have been exploring with the
expression problem. For example, the combinators of the <strong>Extended
Backus-Naur Form</strong> notation are:</p>
<ul>
<li><strong>Concatenation</strong>: <span class="math inline">S = A,
B</span> stands for <span class="math inline">S = \{ ab \mid a \in A, b
\in B \}</span></li>
<li><strong>Alternation</strong>: <span class="math inline">S = A \mid
B</span> stands for <span class="math inline">S = \{ a \mid a \in A \vee
a \in B \}</span></li>
<li><strong>Option</strong>: <span class="math inline">S = [A]</span>
stands for <span class="math inline">S = \{ \epsilon \} \cup A</span>,
where <span class="math inline">\epsilon</span> is an empty string</li>
<li><strong>Repetition</strong>: <span class="math inline">S = \{ A
\}</span> stands for <span class="math inline">S = \{ \epsilon \} \cup
\{ as \mid a \in A, s \in S \}</span></li>
<li><strong>Terminal string</strong>: <span class="math inline">S =
``a&quot;</span> stands for <span class="math inline">S = \{ a
\}</span></li>
</ul>
<p>Parsers implemented directly in a functional programming paradigm are
functions from character streams to the parsed values. Algorithmically
they are <strong>recursive descent parsers</strong>.</p>
<p><strong>Parser combinators</strong> approach builds parsers as
<strong>monad plus</strong> values:</p>
<ul>
<li><strong>Bind</strong>:
<code>val (&gt;&gt;=) : 'a parser -&gt; ('a -&gt; 'b parser) -&gt; 'b parser</code>
<ul>
<li><code>p &gt;&gt;= f</code> is a parser that first parses
<code>p</code>, and makes the result available for parsing
<code>f</code></li>
</ul></li>
<li><strong>Return</strong>:
<code>val return : 'a -&gt; 'a parser</code>
<ul>
<li><code>return x</code> parses an empty string, symbolically <span
class="math inline">S = \{ \epsilon \}</span>, and returns
<code>x</code></li>
</ul></li>
<li><strong>MZero</strong>: <code>val fail : 'a parser</code>
<ul>
<li><code>fail</code> fails to parse anything, symbolically <span
class="math inline">S = \varnothing = \{ \}</span></li>
</ul></li>
<li><strong>MPlus</strong>:
<code>val (&lt;|&gt;) : 'a parser -&gt; 'a parser -&gt; 'a parser</code>
<ul>
<li><code>p &lt;|&gt; q</code> tries <code>p</code>, and if
<code>p</code> succeeds, its result is returned, otherwise the parser
<code>q</code> is used</li>
</ul></li>
</ul>
<p>The only non-monad-plus operation that has to be built into the monad
is some way to consume a single character from the input stream, for
example:</p>
<ul>
<li><code>val satisfy : (char -&gt; bool) -&gt; char parser</code>
<ul>
<li><code>satisfy (fun c -&gt; c = 'a')</code> consumes the character
“a” from the input stream and returns it; if the input stream starts
with a different character, this parser fails</li>
</ul></li>
</ul>
<p>Ordinary monadic recursive descent parsers <strong>do not
allow</strong> <em>left-recursion</em>: if a cycle of calls not
consuming any character can be entered when a parse failure should
occur, the cycle will keep repeating indefinitely.</p>
<p>For example, if we define numbers <span class="math inline">N := D
\mid N D</span>, where <span class="math inline">D</span> stands for
digits, then a stack of uses of the rule <span class="math inline">N
\rightarrow N D</span> will build up when the next character is not a
digit. The parser will try to match <span class="math inline">N</span>,
which requires matching <span class="math inline">N D</span>, which
requires matching <span class="math inline">N</span> again, leading to
infinite recursion.</p>
<p>On the other hand, rules can share common prefixes, and the
backtracking monad will handle trying alternatives correctly.</p>
<h3 id="parser-combinators-implementation">11.10 Parser Combinators:
Implementation</h3>
<p>The parser monad is actually a composition of two monads:</p>
<ul>
<li>The <strong>state monad</strong> for storing the stream of
characters that remain to be parsed (specifically, the current position
in the input string)</li>
<li>The <strong>backtracking monad</strong> for handling parse failures
and ambiguities (allowing us to try alternatives when one parse
fails)</li>
</ul>
<p>Alternatively, one can split the state monad into a reader monad with
the parsed string, and a state monad with the parsing position. This is
the approach we take here.</p>
<p>We experiment with a different approach to monad-plus:
<strong>lazy-monad-plus</strong>. The difference from regular monad-plus
is that the second argument to <code>mplus</code> is lazy:</p>
<pre><code>val mplus : &#39;a monad -&gt; &#39;a monad Lazy.t -&gt; &#39;a monad</code></pre>
<p>This laziness prevents the second alternative from being evaluated
until it is actually needed, which is important for avoiding infinite
recursion in some parsing scenarios.</p>
<h4 id="implementation-of-lazy-monad-plus">Implementation of
lazy-monad-plus</h4>
<p>First a brief reminder about monads with backtracking. Starting with
an operation from <code>MonadPlusOps</code>:</p>
<p><code>ocaml skip let msum_map f l =   List.fold_left  (* Folding left reverses the apparent order of composition *)     (fun acc a -&gt; mplus acc (lazy (f a))) mzero l  (* order from l is preserved *)</code></p>
<p>The implementation of the lazy-monad-plus using lazy lists:</p>
<p>```ocaml env=parsec type ’a llist = LNil | LCons of ’a * ’a llist
Lazy.t</p>
<p>let rec ltake n = function | LCons (a, l) when n &gt; 1 -&gt;
a::(ltake (n-1) (Lazy.force l)) | LCons (a, l) when n = 1 -&gt; [a] (*
Avoid forcing the tail if not needed *) | _ -&gt; []</p>
<p>let rec lappend l1 l2 = match l1 with LNil -&gt; Lazy.force l2 |
LCons (hd, tl) -&gt; LCons (hd, lazy (lappend (Lazy.force tl) l2))</p>
<p>let rec lconcat_map f = function | LNil -&gt; LNil | LCons (a, l)
-&gt; lappend (f a) (lazy (lconcat_map f (Lazy.force l)))</p>
<p>module LListM = MonadPlus (struct type ’a t = ’a llist let bind a b =
lconcat_map b a let return a = LCons (a, lazy LNil) let mzero = LNil let
mplus = lappend end)</p>
<pre><code>
#### The Parsec Monad

File `Parsec.ml`:

```ocaml env=parsec
module type PARSE = sig
  type &#39;a backtracking_monad  (* Name for the underlying monad-plus *)
  type &#39;a parsing_state = int -&gt; (&#39;a * int) backtracking_monad  (* State: position *)
  type &#39;a t = string -&gt; &#39;a parsing_state  (* Reader for the parsed text *)
  include MONAD_PLUS_OPS
  val (&lt;|&gt;) : &#39;a monad -&gt; &#39;a monad Lazy.t -&gt; &#39;a monad  (* A synonym for mplus *)
  val run : &#39;a monad -&gt; &#39;a t
  val runT : &#39;a monad -&gt; string -&gt; int -&gt; &#39;a backtracking_monad
  val satisfy : (char -&gt; bool) -&gt; char monad  (* Consume a character of the class *)
  val end_of_text : unit monad  (* Check for end of the processed text *)
end

module ParseT (MP : MONAD_PLUS_OPS) :
  PARSE with type &#39;a backtracking_monad := &#39;a MP.monad =
struct
  type &#39;a backtracking_monad = &#39;a MP.monad
  type &#39;a parsing_state = int -&gt; (&#39;a * int) MP.monad
  module M = struct
    type &#39;a t = string -&gt; &#39;a parsing_state
    let return a = fun s p -&gt; MP.return (a, p)
    let bind m b = fun s p -&gt;
      MP.bind (m s p) (fun (a, p&#39;) -&gt; b a s p&#39;)
    let mzero = fun _ p -&gt; MP.mzero
    let mplus ma mb = fun s p -&gt;
      MP.mplus (ma s p) (lazy (Lazy.force mb s p))
  end
  include M
  include MonadPlusOps(M)
  let (&lt;|&gt;) ma mb = mplus ma mb
  let runT m s p = MP.lift fst (m s p)
  let satisfy f s p =
    if p &lt; String.length s &amp;&amp; f s.[p]  (* Consuming a character means accessing it *)
    then MP.return (s.[p], p + 1) else MP.mzero  (* and advancing the parsing position *)
  let end_of_text s p =
    if p &gt;= String.length s then MP.return ((), p) else MP.mzero
end</code></pre>
<h4 id="additional-parser-operations">Additional Parser Operations</h4>
<p>```ocaml env=parsec module type PARSE_OPS = sig include PARSE val
many : ’a monad -&gt; ’a list monad val opt : ’a monad -&gt; ’a option
monad val (?|) : ’a monad -&gt; ’a option monad val seq : ’a monad -&gt;
’b monad Lazy.t -&gt; (’a * ’b) monad (* Exercise: why lazy here? <em>)
val (&lt;</em>&gt;) : ’a monad -&gt; ’b monad Lazy.t -&gt; (’a * ’b)
monad (* Synonym for seq <em>) val lowercase : char monad val uppercase
: char monad val digit : char monad val alpha : char monad val alphanum
: char monad val literal : string -&gt; unit monad (</em> Consume
characters of the given string <em>) val (&lt;&lt;&gt;) : string -&gt;
’a monad -&gt; ’a monad (</em> Prefix and postfix keywords *) val
(&lt;&gt;&gt;) : ’a monad -&gt; string -&gt; ’a monad end</p>
<p>module ParseOps (R : MONAD_PLUS_OPS) (P : PARSE with type ’a
backtracking_monad := ’a R.monad) : PARSE_OPS with type ’a
backtracking_monad := ’a R.monad = struct include P let rec many p =
(let* r = p in let* rs = many p in return (r::rs)) ++ lazy (return [])
let opt p = (let* x = p in return (Some x)) ++ lazy (return None) let
(?|) p = opt p let seq p q = let* x = p in let* y = Lazy.force q in
return (x, y) let (&lt;<em>&gt;) p q = seq p q let lowercase = satisfy
(fun c -&gt; c &gt;= ‘a’ &amp;&amp; c &lt;= ‘z’) let uppercase = satisfy
(fun c -&gt; c &gt;= ‘A’ &amp;&amp; c &lt;= ‘Z’) let digit = satisfy
(fun c -&gt; c &gt;= ‘0’ &amp;&amp; c &lt;= ‘9’) let alpha = lowercase
++ lazy uppercase let alphanum = alpha ++ lazy digit let literal l = let
rec loop pos = if pos = String.length l then return () else satisfy (fun
c -&gt; c = l.[pos]) &gt;&gt;- loop (pos + 1) in loop 0 let
(&lt;&lt;&gt;) bra p = literal bra &gt;&gt;- p let (&lt;&gt;&gt;) p ket
= let</em> x = p in literal ket &gt;&gt;- return x end</p>
<pre><code>
### 11.11 Parser Combinators: Tying the Recursive Knot

Now we come to the key insight connecting parser combinators to the expression problem: how do we allow the grammar to be extended dynamically? The answer is to use a mutable reference holding a list of grammar rules, and tie the recursive knot lazily.

File `PluginBase.ml`:

```ocaml env=parsec
module ParseM = ParseOps (LListM) (ParseT (LListM))
open ParseM

let grammar_rules : (int monad -&gt; int monad) list ref = ref []

let get_language () : int monad =
  let rec result =
    lazy
      (List.fold_left
         (fun acc lang -&gt; acc &lt;|&gt; lazy (lang (Lazy.force result)))
          mzero !grammar_rules) in
  let* r = Lazy.force result in
  let* () = end_of_text in return r  (* Ensure we parse the whole text *)</code></pre>
<h3 id="parser-combinators-dynamic-code-loading">11.12 Parser
Combinators: Dynamic Code Loading</h3>
<p>OCaml supports dynamic code loading through the <code>Dynlink</code>
module. This allows us to load compiled modules at runtime, which can
register new grammar rules by mutating the <code>grammar_rules</code>
reference. This is a powerful form of extensibility: we can add new
syntax to our language without recompiling the main program.</p>
<p>File <code>PluginRun.ml</code>:</p>
<p>```ocaml skip let load_plug fname : unit = let fname =
Dynlink.adapt_filename fname in if Sys.file_exists fname then try
Dynlink.loadfile fname with | (Dynlink.Error err) as e -&gt;
Printf.printf “loading plugin: %s%!” (Dynlink.error_message err); raise
e | e -&gt; Printf.printf “error while loading plugin%!” else (
Printf.printf “file %s does not exist%!” fname; exit (-1))</p>
<p>let () = for i = 2 to Array.length Sys.argv - 1 do load_plug
Sys.argv.(i) done; let lang = PluginBase.get_language () in let result =
Monad.LListM.run (PluginBase.ParseM.runT lang Sys.argv.(1) 0) in match
Monad.ltake 1 result with | [] -&gt; Printf.printf “error%!” | r::_
-&gt; Printf.printf “: %d%!” r</p>
<pre><code>
### 11.13 Parser Combinators: Toy Example

Let us see how this works with a concrete example. We will define two plugins: one for parsing numbers and addition, and another for parsing multiplication. Each plugin registers its grammar rules by appending to the `grammar_rules` list.

File `Plugin1.ml`:

```ocaml env=parsec
open ParseM
let digit_of_char d = int_of_char d - int_of_char &#39;0&#39;

let number _ =  (* Numbers: N := D N | D where D is digits *)
  let rec num =  (* Note: we avoid left-recursion by having the digit first *)
    lazy ((let* d = digit in
           let* (n, b) = Lazy.force num in
           return (digit_of_char d * b + n, b * 10))
      &lt;|&gt; lazy (let* d = digit in return (digit_of_char d, 10))) in
  Lazy.force num &gt;&gt;| fst

let addition lang =  (* Addition rule: S -&gt; (S + S) *)
  (* Requiring a parenthesis &#39;(&#39; turns the rule into non-left-recursive *)
  (* because we consume a character before recursing *)
  let* () = literal &quot;(&quot; in
  let* n1 = lang in
  let* () = literal &quot;+&quot; in
  let* n2 = lang in
  let* () = literal &quot;)&quot; in
  return (n1 + n2)

let () = grammar_rules := number :: addition :: !grammar_rules</code></pre>
<p>File <code>Plugin2.ml</code> adds multiplication to the language.
Notice how we can add this functionality without modifying any existing
code:</p>
<p>```ocaml env=parsec open ParseM</p>
<p>let multiplication lang = (* Multiplication rule: S -&gt; (S * S)
<em>) let</em> () = literal “(” in let* n1 = lang in let* () = literal
“<em>” in let</em> n2 = lang in let* () = literal”)” in return (n1 *
n2)</p>
<p>let () = grammar_rules := multiplication :: !grammar_rules ```</p>
<h3 id="exercises-7">11.14 Exercises</h3>
<p>The following exercises will help you deepen your understanding of
the expression problem and the various solutions we have explored. They
range from implementing additional operations to refactoring the code
for better organization.</p>
<p><strong>Exercise 1:</strong> Implement the <code>string_of_</code>
functions or methods, covering all data cases, corresponding to the
<code>eval_</code> functions in at least two examples from the lecture,
including both an object-based example and a variant-based example
(either standard, or polymorphic, or extensible variants). This will
help you understand how functional extensibility works in each
approach.</p>
<p><strong>Exercise 2:</strong> Split at least one of the examples from
the previous exercise into multiple files and demonstrate separate
compilation.</p>
<p><strong>Exercise 3:</strong> Can we drop the tags
<code>Lambda_t</code>, <code>Expr_t</code> and <code>LExpr_t</code> used
in the examples based on standard variants (file
<code>FP_ADT.ml</code>)? When using polymorphic variants, such tags are
not needed.</p>
<p><strong>Exercise 4:</strong> Factor-out the sub-language consisting
only of variables, thus eliminating the duplication of tags
<code>VarL</code>, <code>VarE</code> in the examples based on standard
variants (file <code>FP_ADT.ml</code>).</p>
<p><strong>Exercise 5:</strong> Come up with a scenario where the
extensible variant types-based solution leads to a non-obvious or hard
to locate bug. This exercise illustrates why exhaustivity checking is so
valuable for static type safety.</p>
<p><strong>Exercise 6:</strong> Re-implement the direct object-based
solution to the expression problem (file <code>Objects.ml</code>) to
make it more satisfying. For example, eliminate the need for some of the
<code>rename</code>, <code>apply</code>, <code>compute</code>
methods.</p>
<p><strong>Exercise 7:</strong> Re-implement the visitor pattern-based
solution to the expression problem (file <code>Visitor.ml</code>) in a
functional way, i.e., replace the mutable fields <code>subst</code> and
<code>beta_redex</code> in the <code>eval_lambda</code> class with a
different solution to the problem of treating <code>abs</code> and
non-<code>abs</code> expressions differently.</p>
<p><strong>Exercise 8:</strong> Extend the sub-language
<code>expr_visit</code> with variables, and add to arguments of the
evaluation constructor <code>eval_expr</code> the substitution. Handle
the problem of potentially duplicate fields <code>subst</code>. (One
approach might be to use ideas from exercise 6.)</p>
<p><strong>Exercise 9:</strong> Implement the following modifications to
the example from the file <code>PolyV.ml</code>:</p>
<ol type="1">
<li>Factor-out the sub-language of variables, around the already present
<code>var</code> type.</li>
<li>Open the types of functions <code>eval3</code>,
<code>freevars3</code> and other functions as required, so that explicit
subtyping, e.g., in <code>eval3 [] (test2 :&gt; lexpr_t)</code>, is not
necessary.</li>
<li>Remove the double-dispatch currently in <code>eval_lexpr</code> and
<code>freevars_lexpr</code>, by implementing a cascading design rather
than a “divide-and-conquer” design.</li>
</ol>
<p><strong>Exercise 10:</strong> Streamline the solution
<code>PolyRecM.ml</code> by extending the language of <span
class="math inline">\lambda</span>-expressions with arithmetic
expressions, rather than defining the sub-languages separately and then
merging them. See slide on page 15 of Jacques Garrigue <em>Structural
Types, Recursive Modules, and the Expression Problem</em>.</p>
<p><strong>Exercise 11:</strong> Transform a parser monad, or rewrite
the parser monad transformer, by adding state for the line and column
numbers.</p>
<p><strong>Exercise 12:</strong> Implement <code>_of_string</code>
functions as parser combinators on top of the example
<code>PolyRecM.ml</code>. Sections 4.3 and 6.2 of <em>Monadic Parser
Combinators</em> by Graham Hutton and Erik Meijer might be helpful.
Split the result into multiple files as in Exercise 2 and demonstrate
dynamic loading of code.</p>
<p><strong>Exercise 13:</strong> What are the benefits and drawbacks of
our lazy-monad-plus (built on top of <em>odd lazy lists</em>) approach,
as compared to regular monad-plus built on top of <em>even lazy
lists</em>? To additionally illustrate your answer:</p>
<ol type="1">
<li>Rewrite the parser combinators example to use regular monad-plus and
even lazy lists.</li>
<li>Select one example from Lecture 8 and rewrite it using
lazy-monad-plus and odd lazy lists.</li>
</ol>
<p>(In an “odd” lazy list, the first element is strict and only the tail
is lazy. In an “even” lazy list, the entire list is wrapped in laziness.
The choice affects when computation happens and how infinite structures
are handled.)</p>
</body>
</html>
